#!/usr/bin/env python3
"""
SysArmor Processor - Inference Requests HTTP Sink Job
æ¶ˆè´¹ sysarmor.inference.requests topicï¼Œå¼‚æ­¥å‘é€æ¨ç†è¯·æ±‚åˆ°æ¨ç†æœåŠ¡API
ä½¿ç”¨ Fire-and-forget æ¨¡å¼ï¼Œä¸ç­‰å¾…æ¨ç†ç»“æœå“åº”
"""

import os
import json
import logging
import requests
from typing import Dict, Any
from pyflink.datastream import StreamExecutionEnvironment, CheckpointingMode
from pyflink.datastream.connectors.kafka import FlinkKafkaConsumer
from pyflink.common.serialization import SimpleStringSchema
from pyflink.common.typeinfo import Types
from pyflink.datastream.functions import MapFunction

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class InferenceServiceHttpSink(MapFunction):
    """æ¨ç†æœåŠ¡HTTP Sink - Fire-and-forgetæ¨¡å¼å¼‚æ­¥å‘é€"""
    
    def __init__(self):
        # æ¨ç†æœåŠ¡é…ç½®
        self.inference_url = os.getenv('INFERENCE_SERVICE_URL', 'http://host.docker.internal:9999/predict')
        self.timeout = int(os.getenv('INFERENCE_TIMEOUT', '2'))  # 2ç§’è¶…æ—¶
        self.headers = {'Content-Type': 'application/json'}
        
        logger.info(f"ğŸ¤– åˆå§‹åŒ–æ¨ç†æœåŠ¡HTTP Sink")
        logger.info(f"   URL: {self.inference_url}")
        logger.info(f"   Timeout: {self.timeout}s")
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self.success_count = 0
        self.timeout_count = 0
        self.error_count = 0
        
    def map(self, value):
        """
        å‘é€æ¨ç†è¯·æ±‚åˆ°æ¨ç†æœåŠ¡ï¼ˆFire-and-forgetæ¨¡å¼ï¼‰
        """
        try:
            # è§£ææ¨ç†è¯·æ±‚
            inference_request = json.loads(value)
            collector_id = inference_request.get('collector_id', 'unknown')
            events_count = len(inference_request.get('events', []))
            
            logger.info(f"ğŸ“¤ å‘é€æ¨ç†è¯·æ±‚: collector={collector_id[:8]}, events={events_count}")
            
            # å‘é€HTTP POSTè¯·æ±‚
            try:
                response = requests.post(
                    self.inference_url,
                    json=inference_request,
                    headers=self.headers,
                    timeout=self.timeout
                )
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code in [200, 201, 202]:
                    self.success_count += 1
                    logger.info(f"âœ… æ¨ç†è¯·æ±‚æˆåŠŸ: collector={collector_id[:8]}, status={response.status_code}")
                else:
                    self.error_count += 1
                    logger.warning(f"âš ï¸ æ¨ç†æœåŠ¡å“åº”å¼‚å¸¸: collector={collector_id[:8]}, status={response.status_code}")
                    
            except requests.exceptions.Timeout:
                self.timeout_count += 1
                logger.warning(f"â±ï¸ æ¨ç†è¯·æ±‚è¶…æ—¶: collector={collector_id[:8]} (æ•°æ®å¯èƒ½å·²å‘é€)")
                # è¶…æ—¶ä½†æ•°æ®å¯èƒ½å·²å‘é€ï¼Œä¸è§†ä¸ºé”™è¯¯
                
            except requests.exceptions.ConnectionError as e:
                self.error_count += 1
                logger.error(f"ğŸ”Œ æ¨ç†æœåŠ¡è¿æ¥å¤±è´¥: collector={collector_id[:8]}, error={e}")
                
            except Exception as e:
                self.error_count += 1
                logger.error(f"âŒ æ¨ç†è¯·æ±‚å¼‚å¸¸: collector={collector_id[:8]}, error={e}")
            
            # å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            if (self.success_count + self.timeout_count + self.error_count) % 100 == 0:
                logger.info(f"ğŸ“Š æ¨ç†è¯·æ±‚ç»Ÿè®¡: success={self.success_count}, timeout={self.timeout_count}, error={self.error_count}")
            
            return value
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ æ¨ç†è¯·æ±‚JSONè§£æå¤±è´¥: {e}")
            return value
            
        except Exception as e:
            logger.error(f"âŒ æ¨ç†HTTP Sinkå¼‚å¸¸: {e}")
            return value


def main():
    """ä¸»å‡½æ•°ï¼šåˆ›å»ºæ¨ç†è¯·æ±‚HTTP Sinkä½œä¸š"""
    
    logger.info("ğŸš€ Starting SysArmor Inference Requests HTTP Sink Job")
    logger.info("ğŸ“‹ Consuming inference requests and sending to ML service")
    logger.info("ğŸ“Š Processing: sysarmor.inference.requests â†’ HTTP API")
    
    # ç¯å¢ƒå˜é‡é…ç½®
    kafka_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'middleware-kafka:9092')
    input_topic = 'sysarmor.inference.requests'
    kafka_group_id = 'sysarmor-inference-requests-http-sink'
    
    # æ¨ç†æœåŠ¡é…ç½®
    inference_url = os.getenv('INFERENCE_SERVICE_URL', 'http://host.docker.internal:9999/predict')
    inference_timeout = os.getenv('INFERENCE_TIMEOUT', '2')
    
    logger.info(f"ğŸ“¡ Kafka Servers: {kafka_servers}")
    logger.info(f"ğŸ“¥ Input Topic: {input_topic}")
    logger.info(f"ğŸ‘¥ Consumer Group: {kafka_group_id}")
    logger.info(f"ğŸ¤– Inference Service: {inference_url}")
    logger.info(f"â±ï¸ Inference Timeout: {inference_timeout}s")
    logger.info("")
    
    # åˆ›å»ºæµå¤„ç†ç¯å¢ƒ
    env = StreamExecutionEnvironment.get_execution_environment()
    
    # é…ç½®ç¯å¢ƒ
    env.set_parallelism(2)  # 2ä¸ªå¹¶è¡Œåº¦
    env.enable_checkpointing(30000)  # 30ç§’ checkpoint
    env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)
    
    try:
        # æ·»åŠ  JAR ä¾èµ–
        env.add_jars("file:///opt/flink/lib/flink-sql-connector-kafka-3.1.0-1.18.jar")
        
        # åˆ›å»º Kafka Consumer
        consumer_props = {
            'bootstrap.servers': kafka_servers,
            'group.id': kafka_group_id,
            'auto.offset.reset': 'earliest',  # å¤„ç†æ‰€æœ‰æ¨ç†è¯·æ±‚
            'session.timeout.ms': '30000',
            'heartbeat.interval.ms': '10000',
            'max.poll.interval.ms': '300000'
        }
        
        kafka_consumer = FlinkKafkaConsumer(
            topics=[input_topic],
            deserialization_schema=SimpleStringSchema(),
            properties=consumer_props
        )
        
        logger.info("ğŸ“‹ Creating inference HTTP sink pipeline...")
        
        # æ„å»ºæ•°æ®æµå¤„ç†ç®¡é“
        inference_stream = env.add_source(kafka_consumer)
        
        # å‘é€åˆ°æ¨ç†æœåŠ¡ï¼ˆFire-and-forgetæ¨¡å¼ï¼‰
        inference_stream.map(
            InferenceServiceHttpSink(),
            output_type=Types.STRING()
        )
        
        # ç›‘æ§è¾“å‡º
        inference_stream.map(
            lambda x: f"ğŸ“¤ Sent inference request: collector={json.loads(x).get('collector_id', 'unknown')[:8]}, events={len(json.loads(x).get('events', []))}",
            output_type=Types.STRING()
        ).print()
        
        logger.info("ğŸ”„ Inference HTTP sink pipeline created:")
        logger.info(f"   {input_topic} â†’ HTTP POST â†’ {inference_url}")
        
        # æ‰§è¡Œä½œä¸š
        logger.info("âœ… Starting inference HTTP sink job...")
        
        job_client = env.execute_async("SysArmor-Inference-Requests-HTTP-Sink")
        
        logger.info(f"ğŸ¯ Inference HTTP Sink job submitted successfully!")
        logger.info(f"ğŸ“‹ Job submitted with async execution")
        logger.info(f"ğŸŒ Monitor at: http://localhost:8081")
        logger.info(f"ğŸ“Š Processing: {input_topic} â†’ {inference_url}")
        logger.info(f"ğŸ” View logs: docker logs -f sysarmor-flink-taskmanager-1")
        
        return "async-job-submitted"
        
    except Exception as e:
        logger.error(f"âŒ Inference HTTP Sink job failed: {e}")
        raise


if __name__ == "__main__":
    main()
