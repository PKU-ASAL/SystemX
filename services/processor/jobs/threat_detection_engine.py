#!/usr/bin/env python3
"""
SysArmor Threat Detection Engine
å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“
åŸºäº Falco/Sysdig è§„åˆ™å¼•æ“è®¾è®¡
æ”¯æŒ Falco é£æ ¼çš„æ¡ä»¶å­—ç¬¦ä¸²è§£æã€åˆ—è¡¨å’Œå®ï¼Œå®ç°ç±»å‹ç´¢å¼•ï¼ŒçŸ­è·¯è¯„ä¼°ï¼Œå­—æ®µç¼“å­˜ç­‰ä¼˜åŒ–
"""

import os
import json
import logging
import re
import yaml
import uuid
import time
import fnmatch
from collections import defaultdict, deque
from datetime import datetime
from typing import Dict, List, Optional, Any, Union, Set
from abc import ABC, abstractmethod
from enum import Enum

logger = logging.getLogger(__name__)


# ============================================================================
# åŒ¹é…ç­–ç•¥
# ============================================================================

class RuleMatchStrategy(Enum):
    """è§„åˆ™åŒ¹é…ç­–ç•¥"""
    ALL = "all"           # åŒ¹é…æ‰€æœ‰è§„åˆ™ï¼ˆé»˜è®¤ï¼‰
    FIRST = "first"       # åŒ¹é…ç¬¬ä¸€ä¸ªè§„åˆ™å³åœæ­¢ï¼ˆæœ€å¿«ï¼‰
    HIGHEST = "highest"   # åªè¿”å›æœ€é«˜ä¼˜å…ˆçº§çš„è§„åˆ™


# ============================================================================
# å­—æ®µç¼“å­˜
# ============================================================================

class CachedEventData:
    """å¸¦ç¼“å­˜çš„äº‹ä»¶æ•°æ®åŒ…è£…å™¨
    
    é¿å…åœ¨å¤šä¸ªæ¡ä»¶ä¸­é‡å¤è§£æç›¸åŒå­—æ®µ
    """
    
    def __init__(self, event_data: Dict):
        self.event_data = event_data
        self._field_cache: Dict[str, Any] = {}
    
    def get_field(self, field_path: str, extractor_func) -> Any:
        if field_path in self._field_cache:
            return self._field_cache[field_path]
        
        value = extractor_func(field_path, self.event_data)
        self._field_cache[field_path] = value
        return value


# ============================================================================
# ç»Ÿè®¡ç®¡ç†
# ============================================================================

class RuleStats:
    """è§„åˆ™ç»Ÿè®¡ä¿¡æ¯"""
    
    def __init__(self, rule_id: str):
        self.rule_id = rule_id
        self.matched_count = 0
        self.evaluated_count = 0
        self.total_eval_time_ms = 0.0
        self.last_matched_at: Optional[datetime] = None
    
    @property
    def match_rate(self) -> float:
        """åŒ¹é…ç‡"""
        return self.matched_count / self.evaluated_count if self.evaluated_count > 0 else 0
    
    @property
    def avg_eval_time_ms(self) -> float:
        """å¹³å‡è¯„ä¼°æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        return self.total_eval_time_ms / self.evaluated_count if self.evaluated_count > 0 else 0


class StatsManager:
    """ç»Ÿè®¡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.stats: Dict[str, RuleStats] = {}
        self.global_stats = {
            'total_events': 0,
            'total_alerts': 0,
            'start_time': time.time()
        }
    
    def record_evaluation(self, rule_id: str, matched: bool, eval_time_ms: float):
        """è®°å½•è§„åˆ™è¯„ä¼°"""
        if rule_id not in self.stats:
            self.stats[rule_id] = RuleStats(rule_id)
        
        stats = self.stats[rule_id]
        stats.evaluated_count += 1
        stats.total_eval_time_ms += eval_time_ms
        
        if matched:
            stats.matched_count += 1
            stats.last_matched_at = datetime.utcnow()
    
    def record_event(self, alert_count: int):
        """è®°å½•äº‹ä»¶å¤„ç†"""
        self.global_stats['total_events'] += 1
        self.global_stats['total_alerts'] += alert_count
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        uptime = time.time() - self.global_stats['start_time']
        
        print("\n" + "="*100)
        print("è§„åˆ™å¼•æ“ç»Ÿè®¡ä¿¡æ¯")
        print("="*100)
        print(f"è¿è¡Œæ—¶é—´: {uptime:.2f}s | "
              f"æ€»äº‹ä»¶: {self.global_stats['total_events']} | "
              f"æ€»å‘Šè­¦: {self.global_stats['total_alerts']}")
        print("-"*100)
        print(f"{'è§„åˆ™ID':<40s} | {'åŒ¹é…':<8s} | {'è¯„ä¼°':<8s} | {'åŒ¹é…ç‡':<8s} | {'å¹³å‡è€—æ—¶'}")
        print("-"*100)
        
        for rule_id, stats in sorted(
            self.stats.items(), 
            key=lambda x: x[1].matched_count, 
            reverse=True
        ):
            print(f"{rule_id:<40s} | "
                  f"{stats.matched_count:<8d} | "
                  f"{stats.evaluated_count:<8d} | "
                  f"{stats.match_rate:<8.2%} | "
                  f"{stats.avg_eval_time_ms:.3f}ms")
        
        print("="*100 + "\n")


# ============================================================================
# é™æµå™¨
# ============================================================================

class RateLimiter:
    """è§„åˆ™è§¦å‘é¢‘ç‡é™åˆ¶å™¨"""
    
    def __init__(self, max_alerts_per_minute: int = 100):
        self.max_alerts = max_alerts_per_minute
        self.alert_counts: Dict[str, deque] = defaultdict(deque)
    
    def should_drop_alert(self, rule_id: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¸¢å¼ƒå‘Šè­¦"""
        now = time.time()
        
        # æ¸…ç† 1 åˆ†é’Ÿå‰çš„è®°å½•
        while self.alert_counts[rule_id] and \
              self.alert_counts[rule_id][0] < now - 60:
            self.alert_counts[rule_id].popleft()
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self.alert_counts[rule_id]) >= self.max_alerts:
            logger.warning(f"è§„åˆ™ {rule_id} è§¦å‘é¢‘ç‡è¶…é™ï¼Œä¸¢å¼ƒå‘Šè­¦")
            return True
        
        self.alert_counts[rule_id].append(now)
        return False


# ============================================================================
# AST èŠ‚ç‚¹å®šä¹‰
# ============================================================================

class ASTNode(ABC):
    """AST èŠ‚ç‚¹åŸºç±»"""
    
    @abstractmethod
    def evaluate(self, event_data: Dict) -> bool:
        """è¯„ä¼°èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        pass


class AndNode(ASTNode):
    """é€»è¾‘ä¸èŠ‚ç‚¹"""
    def __init__(self, children: List[ASTNode]):
        self.children = children
    
    def evaluate(self, event_data: Dict) -> bool:
        # çŸ­è·¯è¯„ä¼°ï¼šæ‰€æœ‰å­èŠ‚ç‚¹éƒ½å¿…é¡»ä¸º true
        for child in self.children:
            if not child.evaluate(event_data):
                return False
        return True
    
    def __str__(self) -> str:
        return f"({' and '.join(str(c) for c in self.children)})"


class OrNode(ASTNode):
    """é€»è¾‘æˆ–èŠ‚ç‚¹"""
    def __init__(self, children: List[ASTNode]):
        self.children = children
    
    def evaluate(self, event_data: Dict) -> bool:
        # çŸ­è·¯è¯„ä¼°ï¼šä»»ä¸€å­èŠ‚ç‚¹ä¸º true å³å¯
        for child in self.children:
            if child.evaluate(event_data):
                return True
        return False
    
    def __str__(self) -> str:
        return f"({' or '.join(str(c) for c in self.children)})"


class NotNode(ASTNode):
    """é€»è¾‘éèŠ‚ç‚¹"""
    def __init__(self, child: ASTNode):
        self.child = child
    
    def evaluate(self, event_data: Dict) -> bool:
        return not self.child.evaluate(event_data)
    
    def __str__(self) -> str:
        return f"not {self.child}"


class ComparisonNode(ASTNode):
    """æ¯”è¾ƒèŠ‚ç‚¹"""
    def __init__(self, field: str, operator: str, value: Any):
        self.field = field
        self.operator = operator
        self.value = value
    
    def evaluate(self, event_data: Union[Dict, CachedEventData]) -> bool:
        # æ”¯æŒç¼“å­˜çš„äº‹ä»¶æ•°æ®
        if isinstance(event_data, CachedEventData):
            field_value = event_data.get_field(self.field, self._get_field_value)
        else:
            field_value = self._get_field_value(self.field, event_data)
        
        if field_value is None:
            logger.debug(f"å­—æ®µ {self.field} å€¼ä¸º None")
            return False
        
        # æ‰§è¡Œæ¯”è¾ƒ
        result = self._compare(field_value, self.operator, self.value)
        logger.debug(f"æ¯”è¾ƒ: {self.field}='{field_value}' {self.operator} {self.value} => {result}")
        return result
    
    def _get_field_value(self, field_path: str, event_data: Dict):
        """æ ¹æ®å­—æ®µè·¯å¾„è·å–å€¼ï¼Œæ”¯æŒåµŒå¥—è®¿é—®å’Œç›´æ¥é”®ååŒ¹é…"""
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è®¿é—®å®Œæ•´å­—æ®µåï¼ˆé€‚é… sysdig æ ¼å¼ï¼‰
            if field_path in event_data:
                return event_data[field_path]
            
            # å¦‚æœç›´æ¥è®¿é—®å¤±è´¥ï¼Œå°è¯•åˆ†å±‚è®¿é—®
            parts = field_path.split('.')
            current = event_data
            
            for part in parts:
                if isinstance(current, dict):
                    # å¤„ç†æ•°ç»„ç´¢å¼•ï¼Œå¦‚ proc.aname[1]
                    if '[' in part and ']' in part:
                        field_name = part.split('[')[0]
                        index_str = part.split('[')[1].split(']')[0]
                        try:
                            index = int(index_str)
                            if field_name in current and isinstance(current[field_name], list):
                                if 0 <= index < len(current[field_name]):
                                    current = current[field_name][index]
                                else:
                                    return None
                            else:
                                return None
                        except (ValueError, IndexError):
                            return None
                    else:
                        current = current.get(part)
                else:
                    return None
                
                if current is None:
                    return None
            
            return current
        except Exception as e:
            logger.debug(f"è·å–å­—æ®µå€¼å¤±è´¥: {field_path}, {e}")
            return None
    
    def _compare(self, left: Any, op: str, right: Any) -> bool:
        """æ‰§è¡Œæ¯”è¾ƒæ“ä½œ"""
        try:
            if op == '=' or op == '==':
                return str(left) == str(right)
            elif op == '!=' or op == '<>':
                return str(left) != str(right)
            elif op == '<':
                return left < right
            elif op == '>':
                return left > right
            elif op == '<=':
                return left <= right
            elif op == '>=':
                return left >= right
            elif op == 'contains':
                return str(right) in str(left)
            elif op == 'icontains':
                return str(right).lower() in str(left).lower()
            elif op == 'startswith':
                return str(left).startswith(str(right))
            elif op == 'endswith':
                return str(left).endswith(str(right))
            elif op == 'in':
                if isinstance(right, (list, tuple, set)):
                    result = left in right
                    return result
                return False
            elif op == 'pmatch':  # glob pattern match
                import fnmatch
                return fnmatch.fnmatch(str(left), str(right))
            elif op == 'regex':
                pattern = str(right)
                text = str(left)
                # å¤„ç†è½¬ä¹‰åºåˆ—ï¼šYAMLä¸­çš„åŒåæ–œæ éœ€è¦è½¬æ¢ä¸ºå•åæ–œæ 
                try:
                    pattern = pattern.encode().decode('unicode_escape')
                except Exception:
                    pass  # å¦‚æœè§£ç å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¨¡å¼
                result = re.search(pattern, text, re.IGNORECASE) is not None
                logger.debug(f"regex æ“ä½œ: pattern={repr(pattern)} text={repr(text)} result={result}")
                return result
            else:
                logger.warning(f"æœªçŸ¥æ“ä½œç¬¦: {op}")
                return False
        except Exception as e:
            logger.debug(f"æ¯”è¾ƒå¼‚å¸¸: {e}")
            return False
    
    def __str__(self) -> str:
        if isinstance(self.value, (list, tuple)):
            value_str = f"({', '.join(map(str, self.value))})"
        else:
            value_str = f'"{self.value}"' if isinstance(self.value, str) else str(self.value)
        return f"{self.field} {self.operator} {value_str}"


class MacroNode(ASTNode):
    """å®å¼•ç”¨èŠ‚ç‚¹"""
    def __init__(self, name: str):
        self.name = name
        self.expanded = None
    
    def evaluate(self, event_data: Dict) -> bool:
        if self.expanded:
            return self.expanded.evaluate(event_data)
        raise RuntimeError(f"å® '{self.name}' æœªå±•å¼€")
    
    def __str__(self) -> str:
        return f"<macro:{self.name}>"


# ============================================================================
# è¯æ³•åˆ†æå™¨å’Œè§£æå™¨
# ============================================================================

class Token:
    """è¯æ³•å•å…ƒ"""
    def __init__(self, type: str, value: str, pos: int):
        self.type = type
        self.value = value
        self.pos = pos
    
    def __repr__(self):
        return f"Token({self.type}, '{self.value}', {self.pos})"


class Lexer:
    """è¯æ³•åˆ†æå™¨"""
    
    # è¿ç®—ç¬¦å…³é”®å­—
    OPERATORS = {
        '=', '==', '!=', '<>', '<', '>', '<=', '>=',
        'contains', 'icontains', 'startswith', 'endswith',
        'in', 'pmatch', 'regex'
    }
    
    LOGICAL = {'and', 'or', 'not'}
    
    def __init__(self, text: str):
        self.text = text
        self.pos = 0
        self.tokens = []
    
    def tokenize(self) -> List[Token]:
        """å°†è¾“å…¥æ–‡æœ¬åˆ†è¯"""
        self.tokens = []
        
        while self.pos < len(self.text):
            # è·³è¿‡ç©ºç™½å­—ç¬¦
            if self.text[self.pos].isspace():
                self.pos += 1
                continue
            
            # æ‹¬å·
            if self.text[self.pos] in '()':
                self.tokens.append(Token('PAREN', self.text[self.pos], self.pos))
                self.pos += 1
                continue
            
            # é€—å·
            if self.text[self.pos] == ',':
                self.tokens.append(Token('COMMA', ',', self.pos))
                self.pos += 1
                continue
            
            # å­—ç¬¦ä¸²ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰
            if self.text[self.pos] in '"\'':
                string_val = self._read_string()
                self.tokens.append(Token('STRING', string_val, self.pos))
                continue
            
            # è¿ç®—ç¬¦ï¼ˆå…ˆå°è¯•å¤šå­—ç¬¦è¿ç®—ç¬¦ï¼‰
            if self._try_operator():
                continue
            
            # æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
            word = self._read_word()
            if word:
                word_lower = word.lower()
                if word_lower in self.LOGICAL:
                    self.tokens.append(Token('LOGICAL', word_lower, self.pos))
                elif word_lower in self.OPERATORS:
                    self.tokens.append(Token('OPERATOR', word_lower, self.pos))
                else:
                    # å­—æ®µåæˆ–æ ‡è¯†ç¬¦
                    self.tokens.append(Token('IDENTIFIER', word, self.pos))
        
        return self.tokens
    
    def _try_operator(self) -> bool:
        """åŒ¹é…å¤šå­—ç¬¦è¿ç®—ç¬¦"""
        if self.pos + 1 < len(self.text):
            two_char = self.text[self.pos:self.pos+2]
            if two_char in ['==', '!=', '<=', '>=', '<>']:
                self.tokens.append(Token('OPERATOR', two_char, self.pos))
                self.pos += 2
                return True
        
        # å•å­—ç¬¦è¿ç®—ç¬¦
        if self.text[self.pos] in '=<>':
            self.tokens.append(Token('OPERATOR', self.text[self.pos], self.pos))
            self.pos += 1
            return True
        
        return False
    
    def _read_string(self) -> str:
        """è¯»å–å­—ç¬¦ä¸²å­—é¢é‡ï¼Œå¤„ç†è½¬ä¹‰åºåˆ—"""
        quote = self.text[self.pos]
        self.pos += 1
        result = []
        
        while self.pos < len(self.text) and self.text[self.pos] != quote:
            if self.text[self.pos] == '\\' and self.pos + 1 < len(self.text):
                # å¤„ç†è½¬ä¹‰å­—ç¬¦ - ä¸è¿›è¡Œä»»ä½•è½¬æ¢ï¼Œç›´æ¥ä¿ç•™
                # å› ä¸º YAML å·²ç»å¤„ç†è¿‡ä¸€æ¬¡è½¬ä¹‰äº†
                result.append(self.text[self.pos])  # æ·»åŠ åæ–œæ 
                self.pos += 1
                if self.pos < len(self.text):
                    result.append(self.text[self.pos])  # æ·»åŠ ä¸‹ä¸€ä¸ªå­—ç¬¦
                    self.pos += 1
            else:
                result.append(self.text[self.pos])
                self.pos += 1
        
        if self.pos < len(self.text):
            self.pos += 1  # è·³è¿‡ç»“æŸå¼•å·
        return ''.join(result)
    
    def _read_word(self) -> str:
        """è¯»å–å•è¯ï¼ˆæ ‡è¯†ç¬¦æˆ–è¿ç®—ç¬¦ï¼‰"""
        start = self.pos
        
        # è¯»å–å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€ç‚¹å·
        while self.pos < len(self.text) and (
            self.text[self.pos].isalnum() or 
            self.text[self.pos] in '._'
        ):
            self.pos += 1
        
        return self.text[start:self.pos]


class FalcoConditionParser:
    """Falco æ¡ä»¶è§£æå™¨ - é€’å½’ä¸‹é™è§£æ"""
    
    def __init__(self, text: str):
        self.lexer = Lexer(text)
        self.tokens = self.lexer.tokenize()
        self.pos = 0
    
    def parse(self) -> ASTNode:
        """è§£ææ¡ä»¶è¡¨è¾¾å¼"""
        if not self.tokens:
            raise ValueError("ç©ºæ¡ä»¶è¡¨è¾¾å¼")
        
        result = self._parse_or_expression()
        
        if self.pos < len(self.tokens):
            raise ValueError(f"ä½ç½® {self.pos} å­˜åœ¨æ„å¤–çš„ token: {self.tokens[self.pos]}")
        
        return result
    
    def _current_token(self) -> Optional[Token]:
        """è·å–å½“å‰ token"""
        if self.pos < len(self.tokens):
            return self.tokens[self.pos]
        return None
    
    def _consume(self, expected_type: Optional[str] = None) -> Token:
        """æ¶ˆè´¹å½“å‰ token"""
        token = self._current_token()
        if token is None:
            raise ValueError("æ„å¤–çš„è¡¨è¾¾å¼ç»“æŸ")
        
        if expected_type and token.type != expected_type:
            raise ValueError(f"æœŸæœ› {expected_type}ï¼Œå¾—åˆ° {token.type}")
        
        self.pos += 1
        return token
    
    def _parse_or_expression(self) -> ASTNode:
        """è§£æ OR è¡¨è¾¾å¼ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰"""
        left = self._parse_and_expression()
        
        while self._current_token() and \
              self._current_token().type == 'LOGICAL' and \
              self._current_token().value == 'or':
            self._consume()  # æ¶ˆè´¹ 'or'
            right = self._parse_and_expression()
            left = OrNode([left, right])
        
        return left
    
    def _parse_and_expression(self) -> ASTNode:
        """è§£æ AND è¡¨è¾¾å¼"""
        left = self._parse_not_expression()
        
        while self._current_token() and \
              self._current_token().type == 'LOGICAL' and \
              self._current_token().value == 'and':
            self._consume()  # æ¶ˆè´¹ 'and'
            right = self._parse_not_expression()
            left = AndNode([left, right])
        
        return left
    
    def _parse_not_expression(self) -> ASTNode:
        """è§£æ NOT è¡¨è¾¾å¼"""
        if self._current_token() and \
           self._current_token().type == 'LOGICAL' and \
           self._current_token().value == 'not':
            self._consume()  # æ¶ˆè´¹ 'not'
            child = self._parse_not_expression()
            return NotNode(child)
        
        return self._parse_comparison()
    
    def _parse_comparison(self) -> ASTNode:
        """è§£ææ¯”è¾ƒè¡¨è¾¾å¼"""
        # æ‹¬å·è¡¨è¾¾å¼
        if self._current_token() and \
           self._current_token().type == 'PAREN' and \
           self._current_token().value == '(':
            self._consume()  # æ¶ˆè´¹ '('
            expr = self._parse_or_expression()
            if self._current_token() and self._current_token().type == 'PAREN':
                self._consume()  # æ¶ˆè´¹ ')'
            return expr
        
        # å­—æ®µæˆ–å®
        field_token = self._consume('IDENTIFIER')
        field_or_macro = field_token.value
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå®å¼•ç”¨ï¼ˆæ²¡æœ‰åç»­æ“ä½œç¬¦ï¼‰
        if not self._current_token() or \
           (self._current_token().type == 'LOGICAL') or \
           (self._current_token().type == 'PAREN' and self._current_token().value == ')'):
            # å¯èƒ½æ˜¯å®å¼•ç”¨
            return MacroNode(field_or_macro)
        
        # è¿ç®—ç¬¦
        op_token = self._consume('OPERATOR')
        operator = op_token.value
        
        # å€¼
        value = self._parse_value()
        
        return ComparisonNode(field_or_macro, operator, value)
    
    def _parse_value(self):
        """è§£æå€¼ï¼ˆå­—ç¬¦ä¸²ã€æ•°å­—æˆ–åˆ—è¡¨ï¼‰"""
        token = self._current_token()
        
        if not token:
            raise ValueError("æœŸæœ›å€¼")
        
        # å­—ç¬¦ä¸²
        if token.type == 'STRING':
            self._consume()
            return token.value
        
        # åˆ—è¡¨ (val1, val2, ...)
        if token.type == 'PAREN' and token.value == '(':
            self._consume()  # æ¶ˆè´¹ '('
            values = []
            
            while True:
                val_token = self._consume()
                if val_token.type == 'STRING':
                    values.append(val_token.value)
                elif val_token.type == 'IDENTIFIER':
                    # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                    try:
                        values.append(int(val_token.value))
                    except ValueError:
                        try:
                            values.append(float(val_token.value))
                        except ValueError:
                            values.append(val_token.value)
                
                # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                next_token = self._current_token()
                if next_token and next_token.type == 'PAREN' and next_token.value == ')':
                    self._consume()  # æ¶ˆè´¹ ')'
                    break
                elif next_token and next_token.type == 'COMMA':
                    self._consume()  # æ¶ˆè´¹ ','
                else:
                    raise ValueError("åˆ—è¡¨ä¸­æœŸæœ› ',' æˆ– ')'")
            
            return values
        
        # æ ‡è¯†ç¬¦ï¼ˆå¯èƒ½æ˜¯æ•°å­—ï¼‰
        if token.type == 'IDENTIFIER':
            self._consume()
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—
            try:
                return int(token.value)
            except ValueError:
                try:
                    return float(token.value)
                except ValueError:
                    return token.value
        
        raise ValueError(f"æ„å¤–çš„å€¼ token: {token}")


# ============================================================================
# åˆ—è¡¨å’Œå®ç®¡ç†å™¨
# ============================================================================

class ListManager:
    """åˆ—è¡¨ç®¡ç†å™¨"""
    def __init__(self):
        self.lists: Dict[str, List[str]] = {}
    
    def add_list(self, name: str, items: List[str]):
        """æ·»åŠ åˆ—è¡¨"""
        self.lists[name] = items
        logger.debug(f"æ·»åŠ åˆ—è¡¨: {name} ({len(items)} é¡¹)")
    
    def resolve(self, condition: str) -> str:
        """åœ¨æ¡ä»¶ä¸­æ›¿æ¢åˆ—è¡¨å¼•ç”¨"""
        for name, items in self.lists.items():
            # æŸ¥æ‰¾åˆ—è¡¨å¼•ç”¨ï¼Œä¾‹å¦‚: (list_name)
            pattern = rf'\({name}\)'
            if re.search(pattern, condition):
                # æ›¿æ¢ä¸ºå®é™…å€¼ï¼Œæ•°å­—ä¸åŠ å¼•å·ï¼Œå­—ç¬¦ä¸²åŠ å¼•å·
                formatted_items = []
                for item in items:
                    # å¦‚æœæ˜¯æ•°å­—ï¼Œä¸åŠ å¼•å·
                    if isinstance(item, (int, float)):
                        formatted_items.append(str(item))
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ä½†å†…å®¹æ˜¯æ•°å­—ï¼Œä¹Ÿä¸åŠ å¼•å·
                    elif isinstance(item, str) and item.isdigit():
                        formatted_items.append(item)
                    # å¦åˆ™åŠ å¼•å·
                    else:
                        formatted_items.append(f'"{item}"')
                
                replacement = '(' + ', '.join(formatted_items) + ')'
                condition = re.sub(pattern, replacement, condition)
                logger.debug(f"æ›¿æ¢åˆ—è¡¨ {name}: {pattern} -> {replacement}")
        
        return condition


class MacroManager:
    """å®ç®¡ç†å™¨"""
    def __init__(self):
        self.macros: Dict[str, ASTNode] = {}
    
    def add_macro(self, name: str, ast: ASTNode):
        """æ·»åŠ å®"""
        self.macros[name] = ast
        logger.debug(f"æ·»åŠ å®: {name}")
    
    def expand(self, ast: ASTNode) -> ASTNode:
        """å±•å¼€ AST ä¸­çš„å®å¼•ç”¨"""
        if isinstance(ast, MacroNode):
            # å±•å¼€å®
            if ast.name in self.macros:
                expanded = self.expand(self.macros[ast.name])
                ast.expanded = expanded
                return expanded
            else:
                # ä¸æ˜¯å®ï¼Œå¯èƒ½æ˜¯å­—æ®µå¼•ç”¨ï¼Œä¿æŒåŸæ ·
                logger.debug(f"æœªæ‰¾åˆ°å®: {ast.name}ï¼Œä¿æŒä¸ºæ ‡è¯†ç¬¦")
                return ast
        
        elif isinstance(ast, AndNode):
            ast.children = [self.expand(child) for child in ast.children]
            return ast
        
        elif isinstance(ast, OrNode):
            ast.children = [self.expand(child) for child in ast.children]
            return ast
        
        elif isinstance(ast, NotNode):
            ast.child = self.expand(ast.child)
            return ast
        
        else:
            # æ¯”è¾ƒèŠ‚ç‚¹ï¼Œä¸éœ€è¦å±•å¼€
            return ast


# ============================================================================
# æ¡ä»¶ç¼–è¯‘å™¨ï¼ˆæ•´åˆåˆ—è¡¨ã€å®ã€è§£æï¼‰
# ============================================================================

class ConditionCompiler:
    """æ¡ä»¶ç¼–è¯‘å™¨ - Falco é£æ ¼"""
    def __init__(self):
        self.list_manager = ListManager()
        self.macro_manager = MacroManager()
    
    def add_list(self, name: str, items: List[str]):
        """æ·»åŠ åˆ—è¡¨å®šä¹‰"""
        self.list_manager.add_list(name, items)
    
    def add_macro(self, name: str, condition: str):
        """æ·»åŠ å®å®šä¹‰"""
        # è§£æå®çš„æ¡ä»¶
        resolved_condition = self.list_manager.resolve(condition)
        parser = FalcoConditionParser(resolved_condition)
        ast = parser.parse()
        self.macro_manager.add_macro(name, ast)
    
    def compile(self, condition: str) -> ASTNode:
        """ç¼–è¯‘æ¡ä»¶ä¸º AST"""
        logger.debug(f"ç¼–è¯‘æ¡ä»¶: {condition}")
        
        # 1. æ›¿æ¢åˆ—è¡¨
        resolved_condition = self.list_manager.resolve(condition)
        logger.debug(f"åˆ—è¡¨æ›¿æ¢å: {resolved_condition}")
        
        # 2. è§£æä¸º AST
        parser = FalcoConditionParser(resolved_condition)
        ast = parser.parse()
        logger.debug(f"è§£æ AST: {ast}")
        
        # 3. å±•å¼€å®
        ast = self.macro_manager.expand(ast)
        logger.debug(f"å®å±•å¼€å: {ast}")
        
        return ast


# ============================================================================
# äº‹ä»¶æ ‡å‡†åŒ–å™¨
# ============================================================================

class EventNormalizer:
    """äº‹ä»¶æ•°æ®æ ‡å‡†åŒ–å™¨ - å°†ä¸åŒæ ¼å¼çš„äº‹ä»¶æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€çš„ Falco å­—æ®µæ ¼å¼"""
    
    @staticmethod
    def normalize_event_data(event: Dict[str, Any]) -> Dict[str, Any]:
        """å°† sysdig äº‹ä»¶æ•°æ®æ ‡å‡†åŒ–ä¸º Falco å­—æ®µæ ¼å¼ï¼Œé€‚é… SysArmor æ•°æ®ç»“æ„"""
        message = event.get('message', {})
        
        # æ„å»ºæ ‡å‡†åŒ–çš„äº‹ä»¶æ•°æ®ç»“æ„
        normalized = {
            # äº‹ä»¶åŸºç¡€ä¿¡æ¯
            'evt.type': message.get('evt.type', event.get('event_type', '')),
            'evt.time': message.get('evt.time', event.get('timestamp', '')),
            'evt.num': message.get('evt.num', 0),
            'evt.category': message.get('evt.category', event.get('event_category', '')),
            'evt.dir': message.get('evt.dir', '>'),
            'evt.args': message.get('evt.args', ''),
            
            # è¿›ç¨‹ä¿¡æ¯
            'proc.name': message.get('proc.name', ''),
            'proc.exe': message.get('proc.exe', ''),
            'proc.exepath': message.get('proc.exe', ''),
            'proc.cmdline': message.get('proc.cmdline', ''),
            'proc.pname': message.get('proc.pname', ''),  # çˆ¶è¿›ç¨‹åç§°
            'proc.pcmdline': message.get('proc.pcmdline', ''),
            'proc.pid': message.get('proc.pid', 0),
            'proc.ppid': message.get('proc.ppid', 0),
            'proc.uid': message.get('proc.uid', 0),
            'proc.gid': message.get('proc.gid', 0),
            
            # æ–‡ä»¶æè¿°ç¬¦ä¿¡æ¯
            'fd.name': message.get('fd.name', ''),
            'fd.nameraw': message.get('fd.name', ''),
            
            # ç”¨æˆ·ä¿¡æ¯
            'user.name': EventNormalizer._get_user_name(message.get('proc.uid', 0)),
            'user.uid': message.get('proc.uid', 0),
            
            # å®¹å™¨ä¿¡æ¯
            'container.id': message.get('container.id', 'host'),
            'container.name': message.get('container.name', ''),
            
            # åŸå§‹äº‹ä»¶æ•°æ®
            'message': message,
            'event': event
        }
        
        # æå–æ–‡ä»¶ç›®å½•å’Œæ–‡ä»¶åä¿¡æ¯
        fd_name = normalized.get('fd.name', '')
        if fd_name:
            directory, filename = EventNormalizer._extract_file_info(fd_name)
            normalized['fd.directory'] = directory
            normalized['fd.filename'] = filename
        
        return normalized
    
    @staticmethod
    def _get_user_name(uid: int) -> str:
        """æ ¹æ® UID è·å–ç”¨æˆ·å"""
        system_users = {
            0: 'root',
            1: 'daemon',
            2: 'bin',
            65534: 'nobody'
        }
        return system_users.get(uid, f'user_{uid}')
    
    @staticmethod
    def _extract_file_info(fd_name: str) -> tuple:
        """ä»æ–‡ä»¶æè¿°ç¬¦åç§°ä¸­æå–ç›®å½•å’Œæ–‡ä»¶å"""
        if not fd_name or '->' in fd_name:
            return '', ''
        
        import os
        directory = os.path.dirname(fd_name)
        filename = os.path.basename(fd_name)
        return directory, filename


# ============================================================================
# å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“ï¼ˆä¸»ç±»ï¼‰
# ============================================================================

class ThreatDetectionRules:
    """å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“
    åŸºäº Falco è§„åˆ™è®¾è®¡ï¼Œæ”¯æŒæ¡ä»¶å­—ç¬¦ä¸²è§£æ
    """
    
    def __init__(self, 
                 rules_file: str = "/opt/flink/configs/rules/threat_detection_rules.yaml",
                 enable_index: bool = True,
                 enable_stats: bool = True,
                 enable_rate_limit: bool = True,
                 max_alerts_per_minute: int = 100):
        """åˆå§‹åŒ–è§„åˆ™å¼•æ“
        
        Args:
            rules_file: è§„åˆ™æ–‡ä»¶è·¯å¾„
            enable_index: æ˜¯å¦å¯ç”¨äº‹ä»¶ç±»å‹ç´¢å¼•ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            enable_stats: æ˜¯å¦å¯ç”¨ç»Ÿè®¡ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            enable_rate_limit: æ˜¯å¦å¯ç”¨é¢‘ç‡é™åˆ¶ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            max_alerts_per_minute: æ¯è§„åˆ™æ¯åˆ†é’Ÿæœ€å¤§å‘Šè­¦æ•°
        """
        self.rules = {}
        self.compiled_conditions = {}  # å­˜å‚¨ç¼–è¯‘åçš„ AST
        self.rule_groups = {}
        self.global_settings = {}
        self.compiler = ConditionCompiler()
        self.event_normalizer = EventNormalizer()
        
        # ä¼˜åŒ–ç‰¹æ€§å¼€å…³
        self.enable_index = enable_index
        self.enable_stats = enable_stats
        self.enable_rate_limit = enable_rate_limit
        
        # äº‹ä»¶ç±»å‹ç´¢å¼•
        self.rules_by_event_type: Dict[str, Set[str]] = defaultdict(set)
        self.wildcard_rules: Set[str] = set()
        self.rule_priorities: Dict[str, int] = {}
        
        # ç»Ÿè®¡å’Œé™æµ
        self.stats_manager = StatsManager() if enable_stats else None
        self.rate_limiter = RateLimiter(max_alerts_per_minute) if enable_rate_limit else None
        
        # åŠ è½½è§„åˆ™
        self.load_rules(rules_file)
        
        # æ„å»ºç´¢å¼•
        if self.enable_index:
            self._build_event_type_index()
        
    def load_rules(self, rules_file: str):
        """åŠ è½½å¨èƒæ£€æµ‹è§„åˆ™"""
        try:
            if os.path.exists(rules_file):
                with open(rules_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                # 1. åŠ è½½åˆ—è¡¨
                for list_def in config.get('lists', []):
                    self.compiler.add_list(list_def['list'], list_def['items'])
                
                # 2. åŠ è½½å®
                for macro_def in config.get('macros', []):
                    self.compiler.add_macro(macro_def['macro'], macro_def['condition'])
                
                # 3. åŠ è½½è§„åˆ™ï¼ˆæ”¯æŒ condition å­—ç¬¦ä¸²æ ¼å¼ï¼‰
                for rule in config.get('rules', []):
                    if rule.get('enabled', True):
                        rule_id = rule['id']
                        self.rules[rule_id] = rule
                        
                        # ç¼–è¯‘ condition å­—ç¬¦ä¸²ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if 'condition' in rule and isinstance(rule['condition'], str):
                            try:
                                ast = self.compiler.compile(rule['condition'])
                                self.compiled_conditions[rule_id] = ast
                                logger.debug(f"è§„åˆ™ {rule_id} ç¼–è¯‘æˆåŠŸ: {ast}")
                            except Exception as e:
                                logger.error(f"è§„åˆ™ {rule_id} ç¼–è¯‘å¤±è´¥: {e}")
                        # å…¼å®¹æ—§çš„å­—å…¸æ ¼å¼
                        elif 'condition' in rule and isinstance(rule['condition'], dict):
                            # ä¿æŒåŸæœ‰çš„å­—å…¸æ ¼å¼æ”¯æŒ
                            pass
                
                # åŠ è½½è§„åˆ™ç»„
                self.rule_groups = config.get('rule_groups', {})
                
                # åŠ è½½å…¨å±€è®¾ç½®
                self.global_settings = config.get('global_settings', {})
                
                logger.info(f"âœ… åŠ è½½äº† {len(self.rules)} ä¸ªå¨èƒæ£€æµ‹è§„åˆ™")
                logger.info(f"ğŸ“‹ åˆ—è¡¨: {len(self.compiler.list_manager.lists)} ä¸ª")
                logger.info(f"ğŸ”§ å®: {len(self.compiler.macro_manager.macros)} ä¸ª")
                logger.info(f"ğŸ“‹ è§„åˆ™ç»„: {list(self.rule_groups.keys())}")
            else:
                logger.warning(f"è§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨: {rules_file}ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
                self._load_default_rules()
                
        except Exception as e:
            logger.error(f"åŠ è½½è§„åˆ™å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
            self._load_default_rules()
    
    def _load_default_rules(self):
        """åŠ è½½é»˜è®¤è§„åˆ™ - Falco æ ·å¼æ¡ä»¶å­—ç¬¦ä¸²"""
        # æ·»åŠ é»˜è®¤åˆ—è¡¨
        self.compiler.add_list('sensitive_files', [
            '/etc/passwd', '/etc/shadow', '/etc/sudoers'
        ])
        self.compiler.add_list('shell_binaries', [
            'bash', 'sh', 'zsh', 'fish'
        ])
        
        # æ·»åŠ é»˜è®¤å®
        self.compiler.add_macro('open_read', 'evt.type in (open, openat, openat2)')
        self.compiler.add_macro('open_write', 'evt.type in (open, openat) and fd.name contains "w"')
        
        # å®šä¹‰è§„åˆ™
        self.rules = {
            "suspicious_tmp_execution": {
                "id": "suspicious_tmp_execution",
                "name": "å¯ç–‘ä¸´æ—¶ç›®å½•ç¨‹åºæ‰§è¡Œ",
                "category": "suspicious_activity",
                "severity": "high",
                "base_score": 85,
                "condition": 'evt.type in (execve, execveat) and (proc.exe startswith "/tmp/" or proc.exe startswith "/dev/shm/")'
            },
            "sensitive_file_access": {
                "id": "sensitive_file_access",
                "name": "æ•æ„Ÿæ–‡ä»¶è®¿é—®æ£€æµ‹",
                "category": "file_access",
                "severity": "medium",
                "base_score": 70,
                "condition": 'open_read and fd.name in (sensitive_files)'
            }
        }
        
        # ç¼–è¯‘æ‰€æœ‰è§„åˆ™
        for rule_id, rule in self.rules.items():
            if 'condition' in rule and isinstance(rule['condition'], str):
                try:
                    ast = self.compiler.compile(rule['condition'])
                    self.compiled_conditions[rule_id] = ast
                except Exception as e:
                    logger.error(f"é»˜è®¤è§„åˆ™ {rule_id} ç¼–è¯‘å¤±è´¥: {e}")
        
        logger.info("âœ… åŠ è½½äº†é»˜è®¤å¨èƒæ£€æµ‹è§„åˆ™")
    
    def _build_event_type_index(self):
        """æ„å»ºäº‹ä»¶ç±»å‹ç´¢å¼•"""
        logger.info("ğŸ”¨ å¼€å§‹æ„å»ºäº‹ä»¶ç±»å‹ç´¢å¼•...")
        
        for rule_id, rule in self.rules.items():
            # æå–è§„åˆ™ä¼˜å…ˆçº§
            priority = self._get_rule_priority(rule)
            self.rule_priorities[rule_id] = priority
            
            # åˆ†æè§„åˆ™æ¡ä»¶ï¼Œæå–äº‹ä»¶ç±»å‹
            event_types = self._extract_event_types(rule_id)
            
            if not event_types:
                # æ— æ³•ç¡®å®šäº‹ä»¶ç±»å‹ï¼ŒåŠ å…¥é€šé…è§„åˆ™
                self.wildcard_rules.add(rule_id)
                logger.debug(f"  è§„åˆ™ {rule_id} -> é€šé…è§„åˆ™")
            else:
                # ä¸ºæ¯ä¸ªäº‹ä»¶ç±»å‹æ·»åŠ è§„åˆ™ç´¢å¼•
                for evt_type in event_types:
                    self.rules_by_event_type[evt_type].add(rule_id)
                logger.debug(f"  è§„åˆ™ {rule_id} -> äº‹ä»¶ç±»å‹ {event_types}")
        
        logger.info("âœ… äº‹ä»¶ç±»å‹ç´¢å¼•æ„å»ºå®Œæˆ:")
        logger.info(f"  - æ€»è§„åˆ™æ•°: {len(self.rules)}")
        logger.info(f"  - äº‹ä»¶ç±»å‹æ•°: {len(self.rules_by_event_type)}")
        logger.info(f"  - é€šé…è§„åˆ™æ•°: {len(self.wildcard_rules)}")
        
        # æ‰“å°æ¯ä¸ªäº‹ä»¶ç±»å‹çš„è§„åˆ™æ•°é‡
        for evt_type in sorted(self.rules_by_event_type.keys()):
            rule_count = len(self.rules_by_event_type[evt_type])
            logger.info(f"  - {evt_type}: {rule_count} ä¸ªè§„åˆ™")
    
    def _get_rule_priority(self, rule: Dict) -> int:
        """è·å–è§„åˆ™ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰"""
        severity_to_priority = {
            'critical': 1,
            'high': 2,
            'medium': 3,
            'low': 4,
            'info': 5
        }
        severity = rule.get('severity', 'medium')
        return severity_to_priority.get(severity, 3)
    
    def _extract_event_types(self, rule_id: str) -> Set[str]:
        """ä»è§„åˆ™ AST ä¸­æå–äº‹ä»¶ç±»å‹"""
        event_types = set()
        
        if rule_id not in self.compiled_conditions:
            return event_types
        
        ast = self.compiled_conditions[rule_id]
        self._traverse_ast_for_event_types(ast, event_types)
        
        return event_types
    
    def _traverse_ast_for_event_types(self, node: ASTNode, event_types: Set[str]):
        """é€’å½’éå† AST æå–äº‹ä»¶ç±»å‹"""
        if isinstance(node, ComparisonNode):
            # æ£€æŸ¥æ˜¯å¦ä¸ºäº‹ä»¶ç±»å‹æ¡ä»¶
            if node.field in ('evt.type', 'event_type', 'evt.category'):
                if node.operator in ('=', '=='):
                    event_types.add(str(node.value))
                elif node.operator == 'in':
                    if isinstance(node.value, (list, tuple)):
                        event_types.update(str(v) for v in node.value)
        
        elif isinstance(node, AndNode):
            for child in node.children:
                self._traverse_ast_for_event_types(child, event_types)
        
        elif isinstance(node, OrNode):
            for child in node.children:
                self._traverse_ast_for_event_types(child, event_types)
        
        elif isinstance(node, NotNode):
            # NOT: æ— æ³•ä¼˜åŒ–ï¼Œä¸æå–äº‹ä»¶ç±»å‹
            pass
        
        elif isinstance(node, MacroNode):
            if node.expanded:
                self._traverse_ast_for_event_types(node.expanded, event_types)
    
    def evaluate_event(
        self, 
        event: Dict[str, Any],
        strategy: RuleMatchStrategy = RuleMatchStrategy.ALL
    ) -> List[Dict[str, Any]]:
        """è¯„ä¼°äº‹ä»¶æ˜¯å¦è§¦å‘å¨èƒæ£€æµ‹è§„åˆ™
        
        Args:
            event: åŸå§‹äº‹ä»¶æ•°æ®
            strategy: è§„åˆ™åŒ¹é…ç­–ç•¥
                - ALL: åŒ¹é…æ‰€æœ‰è§„åˆ™ï¼ˆé»˜è®¤ï¼‰
                - FIRST: åŒ¹é…ç¬¬ä¸€ä¸ªè§„åˆ™å³åœæ­¢
                - HIGHEST: åªè¿”å›æœ€é«˜ä¼˜å…ˆçº§çš„è§„åˆ™
        
        Returns:
            å‘Šè­¦åˆ—è¡¨
        """
        start_time = time.time()
        
        # æ ‡å‡†åŒ–äº‹ä»¶æ•°æ®ç»“æ„
        normalized_event = self.event_normalizer.normalize_event_data(event)
        
        # ä½¿ç”¨ç¼“å­˜åŒ…è£…
        cached_event = CachedEventData(normalized_event)
        
        # è·å–éœ€è¦æ£€æŸ¥çš„è§„åˆ™
        if self.enable_index:
            rules_to_check = self._get_indexed_rules(normalized_event)
        else:
            rules_to_check = list(self.rules.keys())
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºè§„åˆ™
        sorted_rules = sorted(
            rules_to_check,
            key=lambda rid: self.rule_priorities.get(rid, 999)
        )
        
        logger.debug(f"ğŸ¯ æ£€æŸ¥ {len(sorted_rules)}/{len(self.rules)} ä¸ªè§„åˆ™")
        
        # æ ¹æ®ç­–ç•¥æ‰§è¡ŒåŒ¹é…
        if strategy == RuleMatchStrategy.ALL:
            alerts = self._match_all_rules(sorted_rules, cached_event, event)
        elif strategy == RuleMatchStrategy.FIRST:
            alerts = self._match_first_rule(sorted_rules, cached_event, event)
        elif strategy == RuleMatchStrategy.HIGHEST:
            alerts = self._match_highest_priority(sorted_rules, cached_event, event)
        else:
            alerts = []
        
        # è®°å½•ç»Ÿè®¡
        if self.enable_stats:
            elapsed_ms = (time.time() - start_time) * 1000
            self.stats_manager.record_event(len(alerts))
            logger.debug(f"â±ï¸  äº‹ä»¶è¯„ä¼°è€—æ—¶: {elapsed_ms:.2f}ms")
        
        return alerts
    
    def _get_indexed_rules(self, normalized_event: Dict) -> List[str]:
        """è·å–éœ€è¦æ£€æŸ¥çš„è§„åˆ™ ID åˆ—è¡¨"""
        # è·å–äº‹ä»¶ç±»å‹
        event_type = normalized_event.get('evt.type') or \
                     normalized_event.get('event_type', 'unknown')
        
        # æ”¶é›†éœ€è¦æ£€æŸ¥çš„è§„åˆ™
        rules_to_check = set(self.wildcard_rules)  # å§‹ç»ˆåŒ…å«é€šé…è§„åˆ™
        
        # æ·»åŠ è¯¥äº‹ä»¶ç±»å‹çš„ä¸“å±è§„åˆ™
        if event_type in self.rules_by_event_type:
            rules_to_check.update(self.rules_by_event_type[event_type])
        
        # ä¹Ÿæ£€æŸ¥äº‹ä»¶ç±»åˆ«
        event_category = self._get_event_category(event_type)
        if event_category and event_category in self.rules_by_event_type:
            rules_to_check.update(self.rules_by_event_type[event_category])
        
        return list(rules_to_check)
    
    def _get_event_category(self, event_type: str) -> Optional[str]:
        """æ ¹æ®äº‹ä»¶ç±»å‹æ¨æ–­äº‹ä»¶ç±»åˆ«"""
        file_events = {'open', 'openat', 'openat2', 'read', 'write', 'close', 'unlink'}
        process_events = {'execve', 'execveat', 'fork', 'clone', 'exit'}
        network_events = {'socket', 'connect', 'bind', 'listen', 'accept', 'send', 'recv'}
        
        if event_type in file_events:
            return 'file'
        elif event_type in process_events:
            return 'process'
        elif event_type in network_events:
            return 'network'
        
        return None
    
    def _match_all_rules(
        self, 
        rule_ids: List[str], 
        cached_event: CachedEventData, 
        original_event: Dict
    ) -> List[Dict[str, Any]]:
        """åŒ¹é…æ‰€æœ‰è§„åˆ™"""
        alerts = []
        for rule_id in rule_ids:
            rule = self.rules[rule_id]
            matched, eval_time = self._match_rule_timed(rule_id, cached_event, rule)
            
            if self.enable_stats:
                self.stats_manager.record_evaluation(rule_id, matched, eval_time)
            
            if matched:
                # æ£€æŸ¥é¢‘ç‡é™åˆ¶
                if self.enable_rate_limit and self.rate_limiter.should_drop_alert(rule_id):
                    continue
                
                alert = self._create_alert(original_event, rule)
                alerts.append(alert)
        
        return alerts
    
    def _match_first_rule(
        self, 
        rule_ids: List[str], 
        cached_event: CachedEventData, 
        original_event: Dict
    ) -> List[Dict[str, Any]]:
        """åŒ¹é…ç¬¬ä¸€ä¸ªè§„åˆ™å³åœæ­¢ï¼ˆçŸ­è·¯è¯„ä¼°ï¼‰"""
        for rule_id in rule_ids:
            rule = self.rules[rule_id]
            matched, eval_time = self._match_rule_timed(rule_id, cached_event, rule)
            
            if self.enable_stats:
                self.stats_manager.record_evaluation(rule_id, matched, eval_time)
            
            if matched:
                # æ£€æŸ¥é¢‘ç‡é™åˆ¶
                if self.enable_rate_limit and self.rate_limiter.should_drop_alert(rule_id):
                    continue
                
                alert = self._create_alert(original_event, rule)
                return [alert]
        
        return []
    
    def _match_highest_priority(
        self, 
        rule_ids: List[str], 
        cached_event: CachedEventData, 
        original_event: Dict
    ) -> List[Dict[str, Any]]:
        """åªè¿”å›æœ€é«˜ä¼˜å…ˆçº§çš„è§„åˆ™"""
        alerts = []
        highest_priority = None
        
        for rule_id in rule_ids:
            rule = self.rules[rule_id]
            priority = self.rule_priorities.get(rule_id, 999)
            
            # å¦‚æœå·²ç»æ‰¾åˆ°æ›´é«˜ä¼˜å…ˆçº§çš„è§„åˆ™ï¼Œè·³è¿‡å½“å‰è§„åˆ™
            if highest_priority is not None and priority > highest_priority:
                continue
            
            matched, eval_time = self._match_rule_timed(rule_id, cached_event, rule)
            
            if self.enable_stats:
                self.stats_manager.record_evaluation(rule_id, matched, eval_time)
            
            if matched:
                # æ£€æŸ¥é¢‘ç‡é™åˆ¶
                if self.enable_rate_limit and self.rate_limiter.should_drop_alert(rule_id):
                    continue
                
                alert = self._create_alert(original_event, rule)
                
                # å¦‚æœæ˜¯æ›´é«˜ä¼˜å…ˆçº§ï¼Œæ¸…ç©ºä¹‹å‰çš„å‘Šè­¦
                if highest_priority is None or priority < highest_priority:
                    alerts = [alert]
                    highest_priority = priority
                # å¦‚æœæ˜¯ç›¸åŒä¼˜å…ˆçº§ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                elif priority == highest_priority:
                    alerts.append(alert)
        
        return alerts
    
    def _match_rule_timed(
        self, 
        rule_id: str, 
        event_data: Union[Dict, CachedEventData], 
        rule: Dict
    ) -> tuple:
        """åŒ¹é…è§„åˆ™å¹¶è®¡æ—¶
        
        Returns:
            (matched: bool, eval_time_ms: float)
        """
        start = time.time()
        matched = self._match_rule(rule_id, event_data, rule)
        eval_time_ms = (time.time() - start) * 1000
        return matched, eval_time_ms
    
    def _match_rule(self, rule_id: str, event_data: Dict, rule: Dict) -> bool:
        """æ£€æŸ¥äº‹ä»¶æ˜¯å¦åŒ¹é…è§„åˆ™"""
        try:
            # ä¼˜å…ˆä½¿ç”¨ç¼–è¯‘åçš„ ASTï¼ˆFalco é£æ ¼ï¼‰
            if rule_id in self.compiled_conditions:
                ast = self.compiled_conditions[rule_id]
                return ast.evaluate(event_data)
            
            # å…¼å®¹æ—§çš„å­—å…¸æ ¼å¼æ¡ä»¶
            elif 'condition' in rule and isinstance(rule['condition'], dict):
                return self._evaluate_dict_condition(rule['condition'], event_data)
            
            # å…¼å®¹æ—§çš„å…³é”®è¯å’Œæ­£åˆ™æ ¼å¼
            event_str = json.dumps(event_data, ensure_ascii=False)
            
            keywords = rule.get('keywords', [])
            for keyword in keywords:
                if keyword in event_str:
                    return True
            
            patterns = rule.get('patterns', [])
            for pattern in patterns:
                if re.search(pattern, event_str, re.IGNORECASE):
                    return True
            
            return False
            
        except Exception as e:
            logger.debug(f"è§„åˆ™åŒ¹é…å¼‚å¸¸ {rule_id}: {e}")
            return False
    
    def _evaluate_dict_condition(self, condition: Dict, event_data: Dict) -> bool:
        """è¯„ä¼°å­—å…¸æ ¼å¼çš„æ¡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰"""
        try:
            if 'and' in condition:
                return all(self._evaluate_dict_condition(sub_cond, event_data) for sub_cond in condition['and'])
            elif 'or' in condition:
                return any(self._evaluate_dict_condition(sub_cond, event_data) for sub_cond in condition['or'])
            elif 'not' in condition:
                return not self._evaluate_dict_condition(condition['not'], event_data)
            elif 'field' in condition:
                field_path = condition['field']
                operator = condition['operator']
                expected_value = condition.get('value', condition.get('values'))
                
                # åˆ›å»ºä¸´æ—¶æ¯”è¾ƒèŠ‚ç‚¹è¯„ä¼°
                comp_node = ComparisonNode(field_path, operator, expected_value)
                return comp_node.evaluate(event_data)
            
            return False
        except Exception as e:
            logger.debug(f"å­—å…¸æ¡ä»¶è¯„ä¼°å¼‚å¸¸: {e}")
            return False
    
    def _create_alert(self, event: Dict, rule: Dict) -> Dict[str, Any]:
        """åˆ›å»ºå‘Šè­¦äº‹ä»¶"""
        now = datetime.utcnow()
        
        # è®¡ç®—é£é™©è¯„åˆ†
        base_score = rule.get('base_score', 50)
        score_multiplier = rule.get('score_multiplier', 1.0)
        final_score = min(100, int(base_score * score_multiplier))
        
        # ç¡®å®šä¸¥é‡ç¨‹åº¦
        severity = rule.get('severity', 'medium')
        if final_score >= 90:
            severity = 'critical'
        elif final_score >= 70:
            severity = 'high'
        elif final_score >= 50:
            severity = 'medium'
        else:
            severity = 'low'
        
        alert = {
            "@timestamp": now.isoformat() + 'Z',
            "alert": {
                "id": str(uuid.uuid4()),
                "type": "rule_based_detection",
                "category": rule.get('category', 'unknown'),
                "severity": severity,
                "risk_score": final_score,
                "confidence": 0.8,
                "rule": {
                    "id": rule['id'],
                    "name": rule.get('name', ''),
                    "description": rule.get('description', ''),
                    "title": f"{rule.get('name', 'Unknown Threat')}: {event.get('event_type', 'unknown')}",
                    "mitigation": f"æ£€æŸ¥ {rule.get('category', 'unknown')} ç›¸å…³æ´»åŠ¨",
                    "references": [f"SysArmor Rule: {rule['id']}"]
                },
                "evidence": {
                    "event_type": event.get('event_type', ''),
                    "process_name": event.get('message', {}).get('proc.name', ''),
                    "process_cmdline": event.get('message', {}).get('proc.cmdline', ''),
                    "file_path": event.get('message', {}).get('fd.name', ''),
                    "network_info": event.get('message', {}).get('net.sockaddr', {})
                }
            },
            "event": {
                "raw": {
                    "event_id": event.get('event_id', ''),
                    "timestamp": event.get('timestamp', ''),
                    "source": event.get('source', 'auditd'),
                    "message": event.get('message', {})
                }
            },
            "timing": {
                "created_at": now.isoformat() + 'Z',
                "processed_at": now.isoformat() + 'Z'
            },
            "metadata": {
                "collector_id": event.get('collector_id', ''),
                "host": event.get('host', 'unknown'),
                "source": "sysarmor-threat-detector",
                "processor": "flink-events-to-alerts"
            }
        }
        
        return alert
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if self.enable_stats:
            self.stats_manager.print_stats()
        else:
            logger.warning("ç»Ÿè®¡åŠŸèƒ½æœªå¯ç”¨")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if self.enable_stats:
            return self.stats_manager.get_stats()
        return {}
    
    def print_index_stats(self):
        """æ‰“å°ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        if not self.enable_index:
            logger.warning("ç´¢å¼•åŠŸèƒ½æœªå¯ç”¨")
            return
        
        print("\n" + "="*80)
        print("äº‹ä»¶ç±»å‹ç´¢å¼•ç»Ÿè®¡")
        print("="*80)
        print(f"æ€»è§„åˆ™æ•°:                {len(self.rules)}")
        print(f"ç´¢å¼•çš„äº‹ä»¶ç±»å‹æ•°:        {len(self.rules_by_event_type)}")
        print(f"é€šé…è§„åˆ™æ•°:              {len(self.wildcard_rules)}")
        
        if self.rules_by_event_type:
            total_indexed = sum(len(rules) for rules in self.rules_by_event_type.values())
            avg_per_type = total_indexed / len(self.rules_by_event_type)
            print(f"å¹³å‡æ¯äº‹ä»¶ç±»å‹è§„åˆ™æ•°:    {avg_per_type:.2f}")
        
        print("="*80)
        
        # è®¡ç®—é¢„ä¼°æ€§èƒ½æå‡
        if len(self.wildcard_rules) > 0 and self.rules_by_event_type:
            avg_check = len(self.wildcard_rules) + avg_per_type
            speedup = len(self.rules) / avg_check if avg_check > 0 else 1
            print(f"é¢„ä¼°æ€§èƒ½æå‡:            {speedup:.1f}x")
        
        print("="*80 + "\n")

ThreatDetectionEngine = ThreatDetectionRules

# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸš€ æµ‹è¯•å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“ - ä½¿ç”¨çœŸå®è§„åˆ™å’Œæ•°æ®")
    print("=" * 100)
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ„å»ºè§„åˆ™æ–‡ä»¶å’Œæ•°æ®æ–‡ä»¶çš„è·¯å¾„
    rules_file = os.path.join(script_dir, "../configs/rules/threat_detection_rules.yaml")
    data_file = os.path.join(
        script_dir, 
        "../../../data/kafka-exports/sysarmor.events.audit_20251023_203740/sysarmor.events.audit_20251023_203740.jsonl"
    )
    
    print(f"ğŸ“‹ è§„åˆ™æ–‡ä»¶: {rules_file}")
    print(f"ğŸ“„ æ•°æ®æ–‡ä»¶: {data_file}")
    print("=" * 100)
    
    # åˆ›å»ºå¼•æ“ï¼ˆå¯ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼‰
    print("\nâš™ï¸  åˆå§‹åŒ–å¨èƒæ£€æµ‹å¼•æ“...")
    engine = ThreatDetectionRules(
        rules_file=rules_file,
        enable_index=True,
        enable_stats=True,
        enable_rate_limit=True,
        max_alerts_per_minute=100
    )
    
    # æ‰“å°ç´¢å¼•ç»Ÿè®¡
    engine.print_index_stats()
    
    # åŠ è½½æµ‹è¯•äº‹ä»¶æ•°æ®
    print("\nğŸ“¥ åŠ è½½æµ‹è¯•äº‹ä»¶æ•°æ®...")
    test_events = []
    
    if os.path.exists(data_file):
        with open(data_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line:
                    try:
                        event = json.loads(line)
                        test_events.append(event)
                    except json.JSONDecodeError as e:
                        logger.warning(f"è·³è¿‡æ— æ•ˆJSON (è¡Œ {line_num}): {e}")
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(test_events)} ä¸ªäº‹ä»¶")
    else:
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("ä½¿ç”¨é»˜è®¤æµ‹è¯•äº‹ä»¶...")
        test_events = [
            {
                "event_id": "test-1",
                "timestamp": "2025-10-22T10:00:00Z",
                "event_type": "execve",
                "message": {
                    "evt.type": "execve",
                    "proc.name": "bash",
                    "proc.exe": "/tmp/malicious.sh",
                    "proc.cmdline": "/tmp/malicious.sh --payload",
                    "proc.pid": 12345
                }
            }
        ]
    
    # æµ‹è¯•ä¸åŒåŒ¹é…ç­–ç•¥
    print("\n" + "=" * 100)
    print("ğŸ§ª æµ‹è¯•ä¸åŒåŒ¹é…ç­–ç•¥")
    print("=" * 100)
    
    strategies_results = {}
    
    for strategy in RuleMatchStrategy:
        print(f"\n{'='*40} ç­–ç•¥: {strategy.value.upper()} {'='*40}")
        
        total_alerts = 0
        alert_by_severity = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'info': 0}
        alert_by_category = {}
        matched_events = 0
        
        start_time = time.time()
        
        for idx, event in enumerate(test_events):
            alerts = engine.evaluate_event(event, strategy=strategy)
            
            if alerts:
                matched_events += 1
                total_alerts += len(alerts)
                
                # ç»Ÿè®¡å‘Šè­¦
                for alert in alerts:
                    severity = alert['alert']['severity']
                    category = alert['alert']['category']
                    
                    if severity in alert_by_severity:
                        alert_by_severity[severity] += 1
                    
                    alert_by_category[category] = alert_by_category.get(category, 0) + 1
                
                # æ˜¾ç¤ºå‰5ä¸ªåŒ¹é…äº‹ä»¶çš„è¯¦æƒ…
                if matched_events <= 5:
                    print(f"\n  äº‹ä»¶ #{idx+1}: {event.get('event_id')} ({event.get('event_type')})")
                    for alert in alerts:
                        rule = alert['alert']['rule']
                        severity = alert['alert']['severity']
                        score = alert['alert']['risk_score']
                        print(f"    ğŸš¨ [{severity.upper():8s}] {rule['name']} (è¯„åˆ†: {score})")
        
        elapsed_time = time.time() - start_time
        
        # ä¿å­˜ç»“æœ
        strategies_results[strategy.value] = {
            'total_events': len(test_events),
            'matched_events': matched_events,
            'total_alerts': total_alerts,
            'alerts_by_severity': alert_by_severity,
            'alerts_by_category': alert_by_category,
            'elapsed_time': elapsed_time
        }
        
        # æ‰“å°ç­–ç•¥ç»Ÿè®¡
        print(f"\n  ğŸ“Š ç­–ç•¥ç»Ÿè®¡:")
        print(f"     æ€»äº‹ä»¶æ•°:        {len(test_events)}")
        print(f"     åŒ¹é…äº‹ä»¶æ•°:      {matched_events} ({matched_events/len(test_events)*100:.1f}%)")
        print(f"     æ€»å‘Šè­¦æ•°:        {total_alerts}")
        print(f"     å¤„ç†è€—æ—¶:        {elapsed_time:.2f}s")
        print(f"     å¹³å‡è€—æ—¶/äº‹ä»¶:   {elapsed_time/len(test_events)*1000:.2f}ms")
        
        print(f"\n  æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:")
        for severity in ['critical', 'high', 'medium', 'low', 'info']:
            count = alert_by_severity.get(severity, 0)
            if count > 0:
                print(f"     {severity.upper():8s}: {count}")
        
        if alert_by_category:
            print(f"\n  æŒ‰ç±»åˆ«åˆ†å¸ƒ:")
            for category, count in sorted(alert_by_category.items(), key=lambda x: x[1], reverse=True):
                print(f"     {category:25s}: {count}")
    
    # ç­–ç•¥å¯¹æ¯”
    print("\n" + "=" * 100)
    print("ğŸ“Š ç­–ç•¥æ€§èƒ½å¯¹æ¯”")
    print("=" * 100)
    print(f"\n{'ç­–ç•¥':<10s} | {'åŒ¹é…äº‹ä»¶':<10s} | {'æ€»å‘Šè­¦':<10s} | {'è€—æ—¶(s)':<10s} | {'ms/äº‹ä»¶':<10s}")
    print("-" * 100)
    
    for strategy_name, results in strategies_results.items():
        matched = results['matched_events']
        alerts = results['total_alerts']
        elapsed = results['elapsed_time']
        ms_per_event = elapsed / results['total_events'] * 1000
        
        print(f"{strategy_name:<10s} | {matched:<10d} | {alerts:<10d} | {elapsed:<10.2f} | {ms_per_event:<10.2f}")
    
    # æ‰“å°è§„åˆ™å¼•æ“ç»Ÿè®¡
    print("\n" + "=" * 100)
    print("ï¿½ è§„åˆ™å¼•æ“æ€§èƒ½ç»Ÿè®¡")
    print("=" * 100)
    engine.print_stats()
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print("\n" + "=" * 100)
    print("ğŸ“ æµ‹è¯•æ€»ç»“")
    print("=" * 100)
    print(f"âœ… æµ‹è¯•å®Œæˆï¼")
    print(f"   - åŠ è½½è§„åˆ™æ•°:     {len(engine.rules)}")
    print(f"   - æµ‹è¯•äº‹ä»¶æ•°:     {len(test_events)}")
    print(f"   - æµ‹è¯•ç­–ç•¥æ•°:     {len(RuleMatchStrategy)}")
    
    # æ¨èç­–ç•¥
    print(f"\nğŸ’¡ ç­–ç•¥æ¨è:")
    all_result = strategies_results.get('all', {})
    first_result = strategies_results.get('first', {})
    highest_result = strategies_results.get('highest', {})
    
    print(f"   - å®Œæ•´åˆ†æ(ALL):      {all_result.get('total_alerts', 0)} ä¸ªå‘Šè­¦, "
          f"{all_result.get('elapsed_time', 0):.2f}s")
    print(f"   - å¿«é€Ÿå“åº”(FIRST):    {first_result.get('total_alerts', 0)} ä¸ªå‘Šè­¦, "
          f"{first_result.get('elapsed_time', 0):.2f}s (æ¨èç”Ÿäº§ç¯å¢ƒ)")
    print(f"   - é™å™ªè¿‡æ»¤(HIGHEST):  {highest_result.get('total_alerts', 0)} ä¸ªå‘Šè­¦, "
          f"{highest_result.get('elapsed_time', 0):.2f}s")
    
    print("\n" + "=" * 100)

