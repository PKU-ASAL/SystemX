#!/usr/bin/env python3
"""
SysArmor Threat Detection Engine
å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“
åŸºäº Falco/Sysdig è§„åˆ™å¼•æ“è®¾è®¡
æ”¯æŒ Falco é£æ ¼çš„æ¡ä»¶å­—ç¬¦ä¸²è§£æã€åˆ—è¡¨å’Œå®
"""

import os
import json
import logging
import re
import yaml
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


# ============================================================================
# AST èŠ‚ç‚¹å®šä¹‰
# ============================================================================

class ASTNode(ABC):
    """AST èŠ‚ç‚¹åŸºç±»"""
    
    @abstractmethod
    def evaluate(self, event_data: Dict) -> bool:
        """è¯„ä¼°èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        pass


class AndNode(ASTNode):
    """é€»è¾‘ä¸èŠ‚ç‚¹"""
    def __init__(self, children: List[ASTNode]):
        self.children = children
    
    def evaluate(self, event_data: Dict) -> bool:
        # çŸ­è·¯è¯„ä¼°ï¼šæ‰€æœ‰å­èŠ‚ç‚¹éƒ½å¿…é¡»ä¸º true
        for child in self.children:
            if not child.evaluate(event_data):
                return False
        return True
    
    def __str__(self) -> str:
        return f"({' and '.join(str(c) for c in self.children)})"


class OrNode(ASTNode):
    """é€»è¾‘æˆ–èŠ‚ç‚¹"""
    def __init__(self, children: List[ASTNode]):
        self.children = children
    
    def evaluate(self, event_data: Dict) -> bool:
        # çŸ­è·¯è¯„ä¼°ï¼šä»»ä¸€å­èŠ‚ç‚¹ä¸º true å³å¯
        for child in self.children:
            if child.evaluate(event_data):
                return True
        return False
    
    def __str__(self) -> str:
        return f"({' or '.join(str(c) for c in self.children)})"


class NotNode(ASTNode):
    """é€»è¾‘éèŠ‚ç‚¹"""
    def __init__(self, child: ASTNode):
        self.child = child
    
    def evaluate(self, event_data: Dict) -> bool:
        return not self.child.evaluate(event_data)
    
    def __str__(self) -> str:
        return f"not {self.child}"


class ComparisonNode(ASTNode):
    """æ¯”è¾ƒèŠ‚ç‚¹"""
    def __init__(self, field: str, operator: str, value: Any):
        self.field = field
        self.operator = operator
        self.value = value
    
    def evaluate(self, event_data: Dict) -> bool:
        # ä»äº‹ä»¶ä¸­æå–å­—æ®µå€¼
        field_value = self._get_field_value(self.field, event_data)
        
        if field_value is None:
            logger.debug(f"å­—æ®µ {self.field} å€¼ä¸º None")
            return False
        
        # æ‰§è¡Œæ¯”è¾ƒ
        result = self._compare(field_value, self.operator, self.value)
        logger.debug(f"æ¯”è¾ƒ: {self.field}='{field_value}' {self.operator} {self.value} => {result}")
        return result
    
    def _get_field_value(self, field_path: str, event_data: Dict):
        """æ ¹æ®å­—æ®µè·¯å¾„è·å–å€¼ï¼Œæ”¯æŒåµŒå¥—è®¿é—®å’Œç›´æ¥é”®ååŒ¹é…"""
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è®¿é—®å®Œæ•´å­—æ®µåï¼ˆé€‚é… sysdig æ ¼å¼ï¼‰
            if field_path in event_data:
                return event_data[field_path]
            
            # å¦‚æœç›´æ¥è®¿é—®å¤±è´¥ï¼Œå°è¯•åˆ†å±‚è®¿é—®
            parts = field_path.split('.')
            current = event_data
            
            for part in parts:
                if isinstance(current, dict):
                    # å¤„ç†æ•°ç»„ç´¢å¼•ï¼Œå¦‚ proc.aname[1]
                    if '[' in part and ']' in part:
                        field_name = part.split('[')[0]
                        index_str = part.split('[')[1].split(']')[0]
                        try:
                            index = int(index_str)
                            if field_name in current and isinstance(current[field_name], list):
                                if 0 <= index < len(current[field_name]):
                                    current = current[field_name][index]
                                else:
                                    return None
                            else:
                                return None
                        except (ValueError, IndexError):
                            return None
                    else:
                        current = current.get(part)
                else:
                    return None
                
                if current is None:
                    return None
            
            return current
        except Exception as e:
            logger.debug(f"è·å–å­—æ®µå€¼å¤±è´¥: {field_path}, {e}")
            return None
    
    def _compare(self, left: Any, op: str, right: Any) -> bool:
        """æ‰§è¡Œæ¯”è¾ƒæ“ä½œ"""
        try:
            if op == '=' or op == '==':
                return str(left) == str(right)
            elif op == '!=' or op == '<>':
                return str(left) != str(right)
            elif op == '<':
                return left < right
            elif op == '>':
                return left > right
            elif op == '<=':
                return left <= right
            elif op == '>=':
                return left >= right
            elif op == 'contains':
                return str(right) in str(left)
            elif op == 'icontains':
                return str(right).lower() in str(left).lower()
            elif op == 'startswith':
                return str(left).startswith(str(right))
            elif op == 'endswith':
                return str(left).endswith(str(right))
            elif op == 'in':
                if isinstance(right, (list, tuple, set)):
                    result = left in right
                    return result
                return False
            elif op == 'pmatch':  # glob pattern match
                import fnmatch
                return fnmatch.fnmatch(str(left), str(right))
            elif op == 'regex':
                pattern = str(right)
                text = str(left)
                # å¤„ç†è½¬ä¹‰åºåˆ—ï¼šYAMLä¸­çš„åŒåæ–œæ éœ€è¦è½¬æ¢ä¸ºå•åæ–œæ 
                try:
                    pattern = pattern.encode().decode('unicode_escape')
                except Exception:
                    pass  # å¦‚æœè§£ç å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¨¡å¼
                result = re.search(pattern, text, re.IGNORECASE) is not None
                logger.debug(f"regex æ“ä½œ: pattern={repr(pattern)} text={repr(text)} result={result}")
                return result
            else:
                logger.warning(f"æœªçŸ¥æ“ä½œç¬¦: {op}")
                return False
        except Exception as e:
            logger.debug(f"æ¯”è¾ƒå¼‚å¸¸: {e}")
            return False
    
    def __str__(self) -> str:
        if isinstance(self.value, (list, tuple)):
            value_str = f"({', '.join(map(str, self.value))})"
        else:
            value_str = f'"{self.value}"' if isinstance(self.value, str) else str(self.value)
        return f"{self.field} {self.operator} {value_str}"


class MacroNode(ASTNode):
    """å®å¼•ç”¨èŠ‚ç‚¹"""
    def __init__(self, name: str):
        self.name = name
        self.expanded = None
    
    def evaluate(self, event_data: Dict) -> bool:
        if self.expanded:
            return self.expanded.evaluate(event_data)
        raise RuntimeError(f"å® '{self.name}' æœªå±•å¼€")
    
    def __str__(self) -> str:
        return f"<macro:{self.name}>"


# ============================================================================
# è¯æ³•åˆ†æå™¨å’Œè§£æå™¨
# ============================================================================

class Token:
    """è¯æ³•å•å…ƒ"""
    def __init__(self, type: str, value: str, pos: int):
        self.type = type
        self.value = value
        self.pos = pos
    
    def __repr__(self):
        return f"Token({self.type}, '{self.value}', {self.pos})"


class Lexer:
    """è¯æ³•åˆ†æå™¨"""
    
    # è¿ç®—ç¬¦å…³é”®å­—
    OPERATORS = {
        '=', '==', '!=', '<>', '<', '>', '<=', '>=',
        'contains', 'icontains', 'startswith', 'endswith',
        'in', 'pmatch', 'regex'
    }
    
    LOGICAL = {'and', 'or', 'not'}
    
    def __init__(self, text: str):
        self.text = text
        self.pos = 0
        self.tokens = []
    
    def tokenize(self) -> List[Token]:
        """å°†è¾“å…¥æ–‡æœ¬åˆ†è¯"""
        self.tokens = []
        
        while self.pos < len(self.text):
            # è·³è¿‡ç©ºç™½å­—ç¬¦
            if self.text[self.pos].isspace():
                self.pos += 1
                continue
            
            # æ‹¬å·
            if self.text[self.pos] in '()':
                self.tokens.append(Token('PAREN', self.text[self.pos], self.pos))
                self.pos += 1
                continue
            
            # é€—å·
            if self.text[self.pos] == ',':
                self.tokens.append(Token('COMMA', ',', self.pos))
                self.pos += 1
                continue
            
            # å­—ç¬¦ä¸²ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰
            if self.text[self.pos] in '"\'':
                string_val = self._read_string()
                self.tokens.append(Token('STRING', string_val, self.pos))
                continue
            
            # è¿ç®—ç¬¦ï¼ˆå…ˆå°è¯•å¤šå­—ç¬¦è¿ç®—ç¬¦ï¼‰
            if self._try_operator():
                continue
            
            # æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
            word = self._read_word()
            if word:
                word_lower = word.lower()
                if word_lower in self.LOGICAL:
                    self.tokens.append(Token('LOGICAL', word_lower, self.pos))
                elif word_lower in self.OPERATORS:
                    self.tokens.append(Token('OPERATOR', word_lower, self.pos))
                else:
                    # å­—æ®µåæˆ–æ ‡è¯†ç¬¦
                    self.tokens.append(Token('IDENTIFIER', word, self.pos))
        
        return self.tokens
    
    def _try_operator(self) -> bool:
        """åŒ¹é…å¤šå­—ç¬¦è¿ç®—ç¬¦"""
        if self.pos + 1 < len(self.text):
            two_char = self.text[self.pos:self.pos+2]
            if two_char in ['==', '!=', '<=', '>=', '<>']:
                self.tokens.append(Token('OPERATOR', two_char, self.pos))
                self.pos += 2
                return True
        
        # å•å­—ç¬¦è¿ç®—ç¬¦
        if self.text[self.pos] in '=<>':
            self.tokens.append(Token('OPERATOR', self.text[self.pos], self.pos))
            self.pos += 1
            return True
        
        return False
    
    def _read_string(self) -> str:
        """è¯»å–å­—ç¬¦ä¸²å­—é¢é‡ï¼Œå¤„ç†è½¬ä¹‰åºåˆ—"""
        quote = self.text[self.pos]
        self.pos += 1
        result = []
        
        while self.pos < len(self.text) and self.text[self.pos] != quote:
            if self.text[self.pos] == '\\' and self.pos + 1 < len(self.text):
                # å¤„ç†è½¬ä¹‰å­—ç¬¦ - ä¸è¿›è¡Œä»»ä½•è½¬æ¢ï¼Œç›´æ¥ä¿ç•™
                # å› ä¸º YAML å·²ç»å¤„ç†è¿‡ä¸€æ¬¡è½¬ä¹‰äº†
                result.append(self.text[self.pos])  # æ·»åŠ åæ–œæ 
                self.pos += 1
                if self.pos < len(self.text):
                    result.append(self.text[self.pos])  # æ·»åŠ ä¸‹ä¸€ä¸ªå­—ç¬¦
                    self.pos += 1
            else:
                result.append(self.text[self.pos])
                self.pos += 1
        
        if self.pos < len(self.text):
            self.pos += 1  # è·³è¿‡ç»“æŸå¼•å·
        return ''.join(result)
    
    def _read_word(self) -> str:
        """è¯»å–å•è¯ï¼ˆæ ‡è¯†ç¬¦æˆ–è¿ç®—ç¬¦ï¼‰"""
        start = self.pos
        
        # è¯»å–å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€ç‚¹å·
        while self.pos < len(self.text) and (
            self.text[self.pos].isalnum() or 
            self.text[self.pos] in '._'
        ):
            self.pos += 1
        
        return self.text[start:self.pos]


class FalcoConditionParser:
    """Falco æ¡ä»¶è§£æå™¨ - é€’å½’ä¸‹é™è§£æ"""
    
    def __init__(self, text: str):
        self.lexer = Lexer(text)
        self.tokens = self.lexer.tokenize()
        self.pos = 0
    
    def parse(self) -> ASTNode:
        """è§£ææ¡ä»¶è¡¨è¾¾å¼"""
        if not self.tokens:
            raise ValueError("ç©ºæ¡ä»¶è¡¨è¾¾å¼")
        
        result = self._parse_or_expression()
        
        if self.pos < len(self.tokens):
            raise ValueError(f"ä½ç½® {self.pos} å­˜åœ¨æ„å¤–çš„ token: {self.tokens[self.pos]}")
        
        return result
    
    def _current_token(self) -> Optional[Token]:
        """è·å–å½“å‰ token"""
        if self.pos < len(self.tokens):
            return self.tokens[self.pos]
        return None
    
    def _consume(self, expected_type: Optional[str] = None) -> Token:
        """æ¶ˆè´¹å½“å‰ token"""
        token = self._current_token()
        if token is None:
            raise ValueError("æ„å¤–çš„è¡¨è¾¾å¼ç»“æŸ")
        
        if expected_type and token.type != expected_type:
            raise ValueError(f"æœŸæœ› {expected_type}ï¼Œå¾—åˆ° {token.type}")
        
        self.pos += 1
        return token
    
    def _parse_or_expression(self) -> ASTNode:
        """è§£æ OR è¡¨è¾¾å¼ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰"""
        left = self._parse_and_expression()
        
        while self._current_token() and \
              self._current_token().type == 'LOGICAL' and \
              self._current_token().value == 'or':
            self._consume()  # æ¶ˆè´¹ 'or'
            right = self._parse_and_expression()
            left = OrNode([left, right])
        
        return left
    
    def _parse_and_expression(self) -> ASTNode:
        """è§£æ AND è¡¨è¾¾å¼"""
        left = self._parse_not_expression()
        
        while self._current_token() and \
              self._current_token().type == 'LOGICAL' and \
              self._current_token().value == 'and':
            self._consume()  # æ¶ˆè´¹ 'and'
            right = self._parse_not_expression()
            left = AndNode([left, right])
        
        return left
    
    def _parse_not_expression(self) -> ASTNode:
        """è§£æ NOT è¡¨è¾¾å¼"""
        if self._current_token() and \
           self._current_token().type == 'LOGICAL' and \
           self._current_token().value == 'not':
            self._consume()  # æ¶ˆè´¹ 'not'
            child = self._parse_not_expression()
            return NotNode(child)
        
        return self._parse_comparison()
    
    def _parse_comparison(self) -> ASTNode:
        """è§£ææ¯”è¾ƒè¡¨è¾¾å¼"""
        # æ‹¬å·è¡¨è¾¾å¼
        if self._current_token() and \
           self._current_token().type == 'PAREN' and \
           self._current_token().value == '(':
            self._consume()  # æ¶ˆè´¹ '('
            expr = self._parse_or_expression()
            if self._current_token() and self._current_token().type == 'PAREN':
                self._consume()  # æ¶ˆè´¹ ')'
            return expr
        
        # å­—æ®µæˆ–å®
        field_token = self._consume('IDENTIFIER')
        field_or_macro = field_token.value
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå®å¼•ç”¨ï¼ˆæ²¡æœ‰åç»­æ“ä½œç¬¦ï¼‰
        if not self._current_token() or \
           (self._current_token().type == 'LOGICAL') or \
           (self._current_token().type == 'PAREN' and self._current_token().value == ')'):
            # å¯èƒ½æ˜¯å®å¼•ç”¨
            return MacroNode(field_or_macro)
        
        # è¿ç®—ç¬¦
        op_token = self._consume('OPERATOR')
        operator = op_token.value
        
        # å€¼
        value = self._parse_value()
        
        return ComparisonNode(field_or_macro, operator, value)
    
    def _parse_value(self):
        """è§£æå€¼ï¼ˆå­—ç¬¦ä¸²ã€æ•°å­—æˆ–åˆ—è¡¨ï¼‰"""
        token = self._current_token()
        
        if not token:
            raise ValueError("æœŸæœ›å€¼")
        
        # å­—ç¬¦ä¸²
        if token.type == 'STRING':
            self._consume()
            return token.value
        
        # åˆ—è¡¨ (val1, val2, ...)
        if token.type == 'PAREN' and token.value == '(':
            self._consume()  # æ¶ˆè´¹ '('
            values = []
            
            while True:
                val_token = self._consume()
                if val_token.type == 'STRING':
                    values.append(val_token.value)
                elif val_token.type == 'IDENTIFIER':
                    # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                    try:
                        values.append(int(val_token.value))
                    except ValueError:
                        try:
                            values.append(float(val_token.value))
                        except ValueError:
                            values.append(val_token.value)
                
                # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                next_token = self._current_token()
                if next_token and next_token.type == 'PAREN' and next_token.value == ')':
                    self._consume()  # æ¶ˆè´¹ ')'
                    break
                elif next_token and next_token.type == 'COMMA':
                    self._consume()  # æ¶ˆè´¹ ','
                else:
                    raise ValueError("åˆ—è¡¨ä¸­æœŸæœ› ',' æˆ– ')'")
            
            return values
        
        # æ ‡è¯†ç¬¦ï¼ˆå¯èƒ½æ˜¯æ•°å­—ï¼‰
        if token.type == 'IDENTIFIER':
            self._consume()
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—
            try:
                return int(token.value)
            except ValueError:
                try:
                    return float(token.value)
                except ValueError:
                    return token.value
        
        raise ValueError(f"æ„å¤–çš„å€¼ token: {token}")


# ============================================================================
# åˆ—è¡¨å’Œå®ç®¡ç†å™¨
# ============================================================================

class ListManager:
    """åˆ—è¡¨ç®¡ç†å™¨"""
    def __init__(self):
        self.lists: Dict[str, List[str]] = {}
    
    def add_list(self, name: str, items: List[str]):
        """æ·»åŠ åˆ—è¡¨"""
        self.lists[name] = items
        logger.debug(f"æ·»åŠ åˆ—è¡¨: {name} ({len(items)} é¡¹)")
    
    def resolve(self, condition: str) -> str:
        """åœ¨æ¡ä»¶ä¸­æ›¿æ¢åˆ—è¡¨å¼•ç”¨"""
        for name, items in self.lists.items():
            # æŸ¥æ‰¾åˆ—è¡¨å¼•ç”¨ï¼Œä¾‹å¦‚: (list_name)
            pattern = rf'\({name}\)'
            if re.search(pattern, condition):
                # æ›¿æ¢ä¸ºå®é™…å€¼ï¼Œæ•°å­—ä¸åŠ å¼•å·ï¼Œå­—ç¬¦ä¸²åŠ å¼•å·
                formatted_items = []
                for item in items:
                    # å¦‚æœæ˜¯æ•°å­—ï¼Œä¸åŠ å¼•å·
                    if isinstance(item, (int, float)):
                        formatted_items.append(str(item))
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ä½†å†…å®¹æ˜¯æ•°å­—ï¼Œä¹Ÿä¸åŠ å¼•å·
                    elif isinstance(item, str) and item.isdigit():
                        formatted_items.append(item)
                    # å¦åˆ™åŠ å¼•å·
                    else:
                        formatted_items.append(f'"{item}"')
                
                replacement = '(' + ', '.join(formatted_items) + ')'
                condition = re.sub(pattern, replacement, condition)
                logger.debug(f"æ›¿æ¢åˆ—è¡¨ {name}: {pattern} -> {replacement}")
        
        return condition


class MacroManager:
    """å®ç®¡ç†å™¨"""
    def __init__(self):
        self.macros: Dict[str, ASTNode] = {}
    
    def add_macro(self, name: str, ast: ASTNode):
        """æ·»åŠ å®"""
        self.macros[name] = ast
        logger.debug(f"æ·»åŠ å®: {name}")
    
    def expand(self, ast: ASTNode) -> ASTNode:
        """å±•å¼€ AST ä¸­çš„å®å¼•ç”¨"""
        if isinstance(ast, MacroNode):
            # å±•å¼€å®
            if ast.name in self.macros:
                expanded = self.expand(self.macros[ast.name])
                ast.expanded = expanded
                return expanded
            else:
                # ä¸æ˜¯å®ï¼Œå¯èƒ½æ˜¯å­—æ®µå¼•ç”¨ï¼Œä¿æŒåŸæ ·
                logger.debug(f"æœªæ‰¾åˆ°å®: {ast.name}ï¼Œä¿æŒä¸ºæ ‡è¯†ç¬¦")
                return ast
        
        elif isinstance(ast, AndNode):
            ast.children = [self.expand(child) for child in ast.children]
            return ast
        
        elif isinstance(ast, OrNode):
            ast.children = [self.expand(child) for child in ast.children]
            return ast
        
        elif isinstance(ast, NotNode):
            ast.child = self.expand(ast.child)
            return ast
        
        else:
            # æ¯”è¾ƒèŠ‚ç‚¹ï¼Œä¸éœ€è¦å±•å¼€
            return ast


# ============================================================================
# æ¡ä»¶ç¼–è¯‘å™¨ï¼ˆæ•´åˆåˆ—è¡¨ã€å®ã€è§£æï¼‰
# ============================================================================

class ConditionCompiler:
    """æ¡ä»¶ç¼–è¯‘å™¨ - Falco é£æ ¼"""
    def __init__(self):
        self.list_manager = ListManager()
        self.macro_manager = MacroManager()
    
    def add_list(self, name: str, items: List[str]):
        """æ·»åŠ åˆ—è¡¨å®šä¹‰"""
        self.list_manager.add_list(name, items)
    
    def add_macro(self, name: str, condition: str):
        """æ·»åŠ å®å®šä¹‰"""
        # è§£æå®çš„æ¡ä»¶
        resolved_condition = self.list_manager.resolve(condition)
        parser = FalcoConditionParser(resolved_condition)
        ast = parser.parse()
        self.macro_manager.add_macro(name, ast)
    
    def compile(self, condition: str) -> ASTNode:
        """ç¼–è¯‘æ¡ä»¶ä¸º AST"""
        logger.debug(f"ç¼–è¯‘æ¡ä»¶: {condition}")
        
        # 1. æ›¿æ¢åˆ—è¡¨
        resolved_condition = self.list_manager.resolve(condition)
        logger.debug(f"åˆ—è¡¨æ›¿æ¢å: {resolved_condition}")
        
        # 2. è§£æä¸º AST
        parser = FalcoConditionParser(resolved_condition)
        ast = parser.parse()
        logger.debug(f"è§£æ AST: {ast}")
        
        # 3. å±•å¼€å®
        ast = self.macro_manager.expand(ast)
        logger.debug(f"å®å±•å¼€å: {ast}")
        
        return ast


# ============================================================================
# äº‹ä»¶æ ‡å‡†åŒ–å™¨
# ============================================================================

class EventNormalizer:
    """äº‹ä»¶æ•°æ®æ ‡å‡†åŒ–å™¨ - å°†ä¸åŒæ ¼å¼çš„äº‹ä»¶æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€çš„ Falco å­—æ®µæ ¼å¼"""
    
    @staticmethod
    def normalize_event_data(event: Dict[str, Any]) -> Dict[str, Any]:
        """å°† sysdig äº‹ä»¶æ•°æ®æ ‡å‡†åŒ–ä¸º Falco å­—æ®µæ ¼å¼ï¼Œé€‚é… SysArmor æ•°æ®ç»“æ„"""
        message = event.get('message', {})
        
        # æ„å»ºæ ‡å‡†åŒ–çš„äº‹ä»¶æ•°æ®ç»“æ„
        normalized = {
            # äº‹ä»¶åŸºç¡€ä¿¡æ¯
            'evt.type': message.get('evt.type', event.get('event_type', '')),
            'evt.time': message.get('evt.time', event.get('timestamp', '')),
            'evt.num': message.get('evt.num', 0),
            'evt.category': message.get('evt.category', event.get('event_category', '')),
            'evt.dir': message.get('evt.dir', '>'),
            'evt.args': message.get('evt.args', ''),
            
            # è¿›ç¨‹ä¿¡æ¯
            'proc.name': message.get('proc.name', ''),
            'proc.exe': message.get('proc.exe', ''),
            'proc.exepath': message.get('proc.exe', ''),
            'proc.cmdline': message.get('proc.cmdline', ''),
            'proc.pname': message.get('proc.pname', ''),  # çˆ¶è¿›ç¨‹åç§°
            'proc.pcmdline': message.get('proc.pcmdline', ''),
            'proc.pid': message.get('proc.pid', 0),
            'proc.ppid': message.get('proc.ppid', 0),
            'proc.uid': message.get('proc.uid', 0),
            'proc.gid': message.get('proc.gid', 0),
            
            # æ–‡ä»¶æè¿°ç¬¦ä¿¡æ¯
            'fd.name': message.get('fd.name', ''),
            'fd.nameraw': message.get('fd.name', ''),
            
            # ç”¨æˆ·ä¿¡æ¯
            'user.name': EventNormalizer._get_user_name(message.get('proc.uid', 0)),
            'user.uid': message.get('proc.uid', 0),
            
            # å®¹å™¨ä¿¡æ¯
            'container.id': message.get('container.id', 'host'),
            'container.name': message.get('container.name', ''),
            
            # åŸå§‹äº‹ä»¶æ•°æ®
            'message': message,
            'event': event
        }
        
        # æå–æ–‡ä»¶ç›®å½•å’Œæ–‡ä»¶åä¿¡æ¯
        fd_name = normalized.get('fd.name', '')
        if fd_name:
            directory, filename = EventNormalizer._extract_file_info(fd_name)
            normalized['fd.directory'] = directory
            normalized['fd.filename'] = filename
        
        return normalized
    
    @staticmethod
    def _get_user_name(uid: int) -> str:
        """æ ¹æ® UID è·å–ç”¨æˆ·å"""
        system_users = {
            0: 'root',
            1: 'daemon',
            2: 'bin',
            65534: 'nobody'
        }
        return system_users.get(uid, f'user_{uid}')
    
    @staticmethod
    def _extract_file_info(fd_name: str) -> tuple:
        """ä»æ–‡ä»¶æè¿°ç¬¦åç§°ä¸­æå–ç›®å½•å’Œæ–‡ä»¶å"""
        if not fd_name or '->' in fd_name:
            return '', ''
        
        import os
        directory = os.path.dirname(fd_name)
        filename = os.path.basename(fd_name)
        return directory, filename


# ============================================================================
# å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“ï¼ˆä¸»ç±»ï¼‰
# ============================================================================

class ThreatDetectionRules:
    """å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“ - åŸºäº Falco è§„åˆ™è®¾è®¡ï¼Œæ”¯æŒæ¡ä»¶å­—ç¬¦ä¸²è§£æ"""
    
    def __init__(self, rules_file: str = "/opt/flink/configs/rules/threat_detection_rules.yaml"):
        self.rules = {}
        self.compiled_conditions = {}  # å­˜å‚¨ç¼–è¯‘åçš„ AST
        self.rule_groups = {}
        self.global_settings = {}
        self.compiler = ConditionCompiler()
        self.event_normalizer = EventNormalizer()
        self.load_rules(rules_file)
        
    def load_rules(self, rules_file: str):
        """åŠ è½½å¨èƒæ£€æµ‹è§„åˆ™"""
        try:
            if os.path.exists(rules_file):
                with open(rules_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                # 1. åŠ è½½åˆ—è¡¨
                for list_def in config.get('lists', []):
                    self.compiler.add_list(list_def['list'], list_def['items'])
                
                # 2. åŠ è½½å®
                for macro_def in config.get('macros', []):
                    self.compiler.add_macro(macro_def['macro'], macro_def['condition'])
                
                # 3. åŠ è½½è§„åˆ™ï¼ˆæ”¯æŒ condition å­—ç¬¦ä¸²æ ¼å¼ï¼‰
                for rule in config.get('rules', []):
                    if rule.get('enabled', True):
                        rule_id = rule['id']
                        self.rules[rule_id] = rule
                        
                        # ç¼–è¯‘ condition å­—ç¬¦ä¸²ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if 'condition' in rule and isinstance(rule['condition'], str):
                            try:
                                ast = self.compiler.compile(rule['condition'])
                                self.compiled_conditions[rule_id] = ast
                                logger.debug(f"è§„åˆ™ {rule_id} ç¼–è¯‘æˆåŠŸ: {ast}")
                            except Exception as e:
                                logger.error(f"è§„åˆ™ {rule_id} ç¼–è¯‘å¤±è´¥: {e}")
                        # å…¼å®¹æ—§çš„å­—å…¸æ ¼å¼
                        elif 'condition' in rule and isinstance(rule['condition'], dict):
                            # ä¿æŒåŸæœ‰çš„å­—å…¸æ ¼å¼æ”¯æŒ
                            pass
                
                # åŠ è½½è§„åˆ™ç»„
                self.rule_groups = config.get('rule_groups', {})
                
                # åŠ è½½å…¨å±€è®¾ç½®
                self.global_settings = config.get('global_settings', {})
                
                logger.info(f"âœ… åŠ è½½äº† {len(self.rules)} ä¸ªå¨èƒæ£€æµ‹è§„åˆ™")
                logger.info(f"ğŸ“‹ åˆ—è¡¨: {len(self.compiler.list_manager.lists)} ä¸ª")
                logger.info(f"ğŸ”§ å®: {len(self.compiler.macro_manager.macros)} ä¸ª")
                logger.info(f"ğŸ“‹ è§„åˆ™ç»„: {list(self.rule_groups.keys())}")
            else:
                logger.warning(f"è§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨: {rules_file}ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
                self._load_default_rules()
                
        except Exception as e:
            logger.error(f"åŠ è½½è§„åˆ™å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
            self._load_default_rules()
    
    def _load_default_rules(self):
        """åŠ è½½é»˜è®¤è§„åˆ™ - Falco æ ·å¼æ¡ä»¶å­—ç¬¦ä¸²"""
        # æ·»åŠ é»˜è®¤åˆ—è¡¨
        self.compiler.add_list('sensitive_files', [
            '/etc/passwd', '/etc/shadow', '/etc/sudoers'
        ])
        self.compiler.add_list('shell_binaries', [
            'bash', 'sh', 'zsh', 'fish'
        ])
        
        # æ·»åŠ é»˜è®¤å®
        self.compiler.add_macro('open_read', 'evt.type in (open, openat, openat2)')
        self.compiler.add_macro('open_write', 'evt.type in (open, openat) and fd.name contains "w"')
        
        # å®šä¹‰è§„åˆ™
        self.rules = {
            "suspicious_tmp_execution": {
                "id": "suspicious_tmp_execution",
                "name": "å¯ç–‘ä¸´æ—¶ç›®å½•ç¨‹åºæ‰§è¡Œ",
                "category": "suspicious_activity",
                "severity": "high",
                "base_score": 85,
                "condition": 'evt.type in (execve, execveat) and (proc.exe startswith "/tmp/" or proc.exe startswith "/dev/shm/")'
            },
            "sensitive_file_access": {
                "id": "sensitive_file_access",
                "name": "æ•æ„Ÿæ–‡ä»¶è®¿é—®æ£€æµ‹",
                "category": "file_access",
                "severity": "medium",
                "base_score": 70,
                "condition": 'open_read and fd.name in (sensitive_files)'
            }
        }
        
        # ç¼–è¯‘æ‰€æœ‰è§„åˆ™
        for rule_id, rule in self.rules.items():
            if 'condition' in rule and isinstance(rule['condition'], str):
                try:
                    ast = self.compiler.compile(rule['condition'])
                    self.compiled_conditions[rule_id] = ast
                except Exception as e:
                    logger.error(f"é»˜è®¤è§„åˆ™ {rule_id} ç¼–è¯‘å¤±è´¥: {e}")
        
        logger.info("âœ… åŠ è½½äº†é»˜è®¤å¨èƒæ£€æµ‹è§„åˆ™")
    
    def evaluate_event(self, event: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è¯„ä¼°äº‹ä»¶æ˜¯å¦è§¦å‘å¨èƒæ£€æµ‹è§„åˆ™"""
        alerts = []
        
        # æ ‡å‡†åŒ–äº‹ä»¶æ•°æ®ç»“æ„
        normalized_event = self.event_normalizer.normalize_event_data(event)
        
        for rule_id, rule in self.rules.items():
            if self._match_rule(rule_id, normalized_event, rule):
                alert = self._create_alert(event, rule)
                alerts.append(alert)
        
        return alerts
    
    def _match_rule(self, rule_id: str, event_data: Dict, rule: Dict) -> bool:
        """æ£€æŸ¥äº‹ä»¶æ˜¯å¦åŒ¹é…è§„åˆ™"""
        try:
            # ä¼˜å…ˆä½¿ç”¨ç¼–è¯‘åçš„ ASTï¼ˆFalco é£æ ¼ï¼‰
            if rule_id in self.compiled_conditions:
                ast = self.compiled_conditions[rule_id]
                return ast.evaluate(event_data)
            
            # å…¼å®¹æ—§çš„å­—å…¸æ ¼å¼æ¡ä»¶
            elif 'condition' in rule and isinstance(rule['condition'], dict):
                return self._evaluate_dict_condition(rule['condition'], event_data)
            
            # å…¼å®¹æ—§çš„å…³é”®è¯å’Œæ­£åˆ™æ ¼å¼
            event_str = json.dumps(event_data, ensure_ascii=False)
            
            keywords = rule.get('keywords', [])
            for keyword in keywords:
                if keyword in event_str:
                    return True
            
            patterns = rule.get('patterns', [])
            for pattern in patterns:
                if re.search(pattern, event_str, re.IGNORECASE):
                    return True
            
            return False
            
        except Exception as e:
            logger.debug(f"è§„åˆ™åŒ¹é…å¼‚å¸¸ {rule_id}: {e}")
            return False
    
    def _evaluate_dict_condition(self, condition: Dict, event_data: Dict) -> bool:
        """è¯„ä¼°å­—å…¸æ ¼å¼çš„æ¡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰"""
        try:
            if 'and' in condition:
                return all(self._evaluate_dict_condition(sub_cond, event_data) for sub_cond in condition['and'])
            elif 'or' in condition:
                return any(self._evaluate_dict_condition(sub_cond, event_data) for sub_cond in condition['or'])
            elif 'not' in condition:
                return not self._evaluate_dict_condition(condition['not'], event_data)
            elif 'field' in condition:
                field_path = condition['field']
                operator = condition['operator']
                expected_value = condition.get('value', condition.get('values'))
                
                # åˆ›å»ºä¸´æ—¶æ¯”è¾ƒèŠ‚ç‚¹è¯„ä¼°
                comp_node = ComparisonNode(field_path, operator, expected_value)
                return comp_node.evaluate(event_data)
            
            return False
        except Exception as e:
            logger.debug(f"å­—å…¸æ¡ä»¶è¯„ä¼°å¼‚å¸¸: {e}")
            return False
    
    def _create_alert(self, event: Dict, rule: Dict) -> Dict[str, Any]:
        """åˆ›å»ºå‘Šè­¦äº‹ä»¶"""
        now = datetime.utcnow()
        
        # è®¡ç®—é£é™©è¯„åˆ†
        base_score = rule.get('base_score', 50)
        score_multiplier = rule.get('score_multiplier', 1.0)
        final_score = min(100, int(base_score * score_multiplier))
        
        # ç¡®å®šä¸¥é‡ç¨‹åº¦
        severity = rule.get('severity', 'medium')
        if final_score >= 90:
            severity = 'critical'
        elif final_score >= 70:
            severity = 'high'
        elif final_score >= 50:
            severity = 'medium'
        else:
            severity = 'low'
        
        alert = {
            "@timestamp": now.isoformat() + 'Z',
            "alert": {
                "id": str(uuid.uuid4()),
                "type": "rule_based_detection",
                "category": rule.get('category', 'unknown'),
                "severity": severity,
                "risk_score": final_score,
                "confidence": 0.8,
                "rule": {
                    "id": rule['id'],
                    "name": rule.get('name', ''),
                    "description": rule.get('description', ''),
                    "title": f"{rule.get('name', 'Unknown Threat')}: {event.get('event_type', 'unknown')}",
                    "mitigation": f"æ£€æŸ¥ {rule.get('category', 'unknown')} ç›¸å…³æ´»åŠ¨",
                    "references": [f"SysArmor Rule: {rule['id']}"]
                },
                "evidence": {
                    "event_type": event.get('event_type', ''),
                    "process_name": event.get('message', {}).get('proc.name', ''),
                    "process_cmdline": event.get('message', {}).get('proc.cmdline', ''),
                    "file_path": event.get('message', {}).get('fd.name', ''),
                    "network_info": event.get('message', {}).get('net.sockaddr', {})
                }
            },
            "event": {
                "raw": {
                    "event_id": event.get('event_id', ''),
                    "timestamp": event.get('timestamp', ''),
                    "source": event.get('source', 'auditd'),
                    "message": event.get('message', {})
                }
            },
            "timing": {
                "created_at": now.isoformat() + 'Z',
                "processed_at": now.isoformat() + 'Z'
            },
            "metadata": {
                "collector_id": event.get('collector_id', ''),
                "host": event.get('host', 'unknown'),
                "source": "sysarmor-threat-detector",
                "processor": "flink-events-to-alerts"
            }
        }
        
        return alert
