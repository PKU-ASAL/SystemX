#!/usr/bin/env python3
"""
SysArmor Processor - Auditd to Sysdig Console Test Job
æ¶ˆè´¹ sysarmor-events-test topicï¼Œå°† auditd æ•°æ®è½¬æ¢ä¸º sysdig æ ¼å¼å¹¶è¾“å‡ºåˆ°æ§åˆ¶å°
åŸºäº NODLINK ç®¡é“çš„å¤„ç†é€»è¾‘å®ç°
"""

import os
import json
import logging
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
from pyflink.datastream import StreamExecutionEnvironment, CheckpointingMode
from pyflink.datastream.connectors.kafka import FlinkKafkaConsumer
from pyflink.common.serialization import SimpleStringSchema
from pyflink.common.typeinfo import Types
from pyflink.datastream.functions import MapFunction, FilterFunction

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AuditdSysdigParser:
    """åŸºäº NODLINK ç®¡é“é€»è¾‘çš„ Auditd åˆ° Sysdig è½¬æ¢å™¨"""
    
    # ç³»ç»Ÿè°ƒç”¨å·åˆ°äº‹ä»¶ç±»å‹çš„æ˜ å°„ (åŸºäº NODLINK æ”¯æŒçš„äº‹ä»¶ç±»å‹)
    SYSCALL_MAP = {
        0: "read", 1: "write", 2: "open", 3: "close", 4: "stat", 5: "fstat",
        6: "lstat", 7: "poll", 8: "lseek", 9: "mmap", 10: "mprotect", 11: "munmap",
        12: "brk", 13: "rt_sigaction", 14: "rt_sigprocmask", 15: "rt_sigreturn",
        16: "ioctl", 17: "pread64", 18: "pwrite64", 19: "readv", 20: "writev",
        21: "access", 22: "pipe", 23: "select", 24: "sched_yield", 25: "mremap",
        26: "msync", 27: "mincore", 28: "madvise", 29: "shmget", 30: "shmat",
        31: "shmctl", 32: "dup", 33: "dup2", 34: "pause", 35: "nanosleep",
        36: "getitimer", 37: "alarm", 38: "setitimer", 39: "getpid", 40: "sendfile",
        41: "socket", 42: "connect", 43: "accept", 44: "sendto", 45: "recvfrom",
        46: "sendmsg", 47: "recvmsg", 48: "shutdown", 49: "bind", 50: "listen",
        51: "getsockname", 52: "getpeername", 53: "socketpair", 54: "setsockopt",
        55: "getsockopt", 56: "clone", 57: "fork", 58: "vfork", 59: "execve",
        60: "exit", 61: "wait4", 62: "kill", 63: "uname", 64: "semget",
        65: "semop", 66: "semctl", 67: "shmdt", 68: "msgget", 69: "msgsnd",
        70: "msgrcv", 71: "msgctl", 72: "fcntl", 73: "flock", 74: "fsync",
        75: "fdatasync", 76: "truncate", 77: "ftruncate", 78: "getdents",
        79: "getcwd", 80: "chdir", 81: "fchdir", 82: "rename", 83: "mkdir",
        84: "rmdir", 85: "creat", 86: "link", 87: "unlink", 88: "symlink",
        89: "readlink", 90: "chmod", 91: "fchmod", 92: "chown", 93: "fchown",
        94: "lchown", 95: "umask", 96: "gettimeofday", 97: "getrlimit",
        98: "getrusage", 99: "sysinfo", 100: "times", 257: "openat"
    }
    
    # NODLINK æ ‡å‡†æ”¯æŒçš„äº‹ä»¶ç±»å‹ (åŸºäº NODLINK ç®¡é“æ–‡æ¡£)
    NODLINK_SUPPORTED_EVENTS = {
        "read", "readv", "write", "writev", "fcntl", "rmdir", "rename", "chmod",
        "execve", "clone", "pipe", "fork", "accept", "sendmsg", "recvmsg", 
        "recvfrom", "send", "sendto", "open", "openat", "socket", "connect"
    }
    
    def __init__(self):
        self.process_cache = {}  # è¿›ç¨‹ç¼“å­˜ï¼Œç”¨äºè¿›ç¨‹æ ‘é‡å»º
        self.message_count = 0
        
    def parse_auditd_message(self, message: str) -> Optional[Dict[str, Any]]:
        """è§£æ auditd æ¶ˆæ¯ï¼Œæå–å…³é”®ä¿¡æ¯"""
        try:
            # åŒ¹é… auditd æ ¼å¼: type=SYSCALL msg=audit(timestamp:id): fields...
            match = re.match(r'type=([^ ]+) msg=audit\(([\d.]+):(\d+)\): (.*)', message)
            if not match:
                return None
                
            record_type, timestamp, event_id, fields_str = match.groups()
            
            # è§£æå­—æ®µ
            fields = {}
            field_pattern = r'(\w+)=("[^"]*"|\S+)'
            for field_match in re.finditer(field_pattern, fields_str):
                key, value = field_match.groups()
                # å»é™¤å¼•å·
                if value.startswith('"') and value.endswith('"'):
                    value = value[1:-1]
                fields[key] = value
            
            return {
                'type': record_type,
                'timestamp': float(timestamp),
                'event_id': event_id,
                'fields': fields
            }
        except Exception as e:
            logger.debug(f"Failed to parse auditd message: {message[:100]}..., error: {e}")
            return None
    
    def decode_hex_cmdline(self, hex_str: str) -> str:
        """è§£ç åå…­è¿›åˆ¶ç¼–ç çš„å‘½ä»¤è¡Œ (åŸºäº NODLINK ç®¡é“é€»è¾‘)"""
        if not hex_str:
            return ""
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåå…­è¿›åˆ¶å­—ç¬¦ä¸²
        if not all(c in '0123456789abcdefABCDEF' for c in hex_str):
            return hex_str
        
        if len(hex_str) % 2 != 0:
            return hex_str
        
        try:
            hex_bytes = bytes.fromhex(hex_str)
            # æŒ‰ null å­—èŠ‚åˆ†å‰²ï¼Œé‡å»ºå‘½ä»¤è¡Œå‚æ•°
            parts = hex_bytes.split(b'\x00')
            return ' '.join(part.decode('utf-8', errors='replace') for part in parts if part).strip()
        except:
            return hex_str
    
    def convert_to_sysdig_format(self, audit_data: Dict[str, Any], host: str) -> Optional[Dict[str, Any]]:
        """å°† auditd æ•°æ®è½¬æ¢ä¸º sysdig æ ¼å¼ (åŸºäº NODLINK æ ‡å‡†)"""
        try:
            if audit_data['type'] != 'SYSCALL':
                return None
            
            fields = audit_data['fields']
            
            # è·å–ç³»ç»Ÿè°ƒç”¨ç±»å‹
            syscall_num = int(fields.get('syscall', '0'))
            evt_type = self.SYSCALL_MAP.get(syscall_num, f"syscall_{syscall_num}")
            
            # åªå¤„ç† NODLINK æ”¯æŒçš„äº‹ä»¶ç±»å‹
            if evt_type not in self.NODLINK_SUPPORTED_EVENTS:
                return None
            
            # æ„å»º sysdig æ ¼å¼äº‹ä»¶ (ç¬¦åˆ NODLINK æ ‡å‡†)
            sysdig_event = {
                "evt.num": int(audit_data['event_id']),
                "evt.time": audit_data['timestamp'],
                "evt.type": evt_type,
                "evt.category": self._get_event_category(evt_type),
                "proc.name": fields.get('comm', '').strip('"'),
                "proc.exe": fields.get('exe', '').strip('"'),
                "proc.pid": int(fields.get('pid', '0')),
                "proc.ppid": int(fields.get('ppid', '0')),
                "proc.uid": int(fields.get('uid', '0')),
                "proc.gid": int(fields.get('gid', '0')),
                "host": host,
                "is_warn": False
            }
            
            # å¤„ç†å‘½ä»¤è¡Œ (æ”¯æŒåå…­è¿›åˆ¶è§£ç )
            if 'proctitle' in fields:
                cmdline = self.decode_hex_cmdline(fields['proctitle'])
                sysdig_event["proc.cmdline"] = cmdline if cmdline else sysdig_event["proc.name"]
            else:
                sysdig_event["proc.cmdline"] = sysdig_event["proc.name"]
            
            # å¤„ç†æ–‡ä»¶è·¯å¾„ (å¯¹äºæ–‡ä»¶æ“ä½œ)
            if evt_type in ['open', 'openat', 'read', 'write', 'chmod', 'rename']:
                if 'name' in fields:
                    fd_name = fields['name'].strip('"')
                    if fd_name and fd_name != '(null)':
                        sysdig_event["fd.name"] = fd_name
            
            # å¤„ç†ç½‘ç»œäº‹ä»¶
            if evt_type in ['socket', 'connect', 'accept', 'sendto', 'recvfrom', 'sendmsg', 'recvmsg']:
                self._add_network_fields(sysdig_event, fields)
            
            # æ›´æ–°è¿›ç¨‹ç¼“å­˜ (ç”¨äºè¿›ç¨‹æ ‘é‡å»º)
            self._update_process_cache(sysdig_event)
            
            # æ·»åŠ çˆ¶è¿›ç¨‹å‘½ä»¤è¡Œ (åŸºäºç¼“å­˜é‡å»º)
            parent_cmdline = self._get_parent_cmdline(
                sysdig_event["proc.ppid"], 
                sysdig_event["evt.time"]
            )
            sysdig_event["proc.pcmdline"] = parent_cmdline
            
            return sysdig_event
            
        except Exception as e:
            logger.error(f"Failed to convert audit data to sysdig: {e}")
            return None
    
    def _get_event_category(self, evt_type: str) -> str:
        """è·å–äº‹ä»¶ç±»åˆ« (åŸºäº NODLINK åˆ†ç±»)"""
        file_events = {"read", "readv", "write", "writev", "open", "openat", "fcntl", "chmod", "rename", "rmdir"}
        process_events = {"execve", "clone", "fork", "exit"}
        network_events = {"socket", "connect", "accept", "sendto", "recvfrom", "sendmsg", "recvmsg"}
        ipc_events = {"pipe"}
        
        if evt_type in file_events:
            return "file"
        elif evt_type in process_events:
            return "process"
        elif evt_type in network_events:
            return "net"
        elif evt_type in ipc_events:
            return "ipc"
        else:
            return "other"
    
    def _add_network_fields(self, event: Dict[str, Any], fields: Dict[str, str]):
        """æ·»åŠ ç½‘ç»œç›¸å…³å­—æ®µ"""
        # ç½‘ç»œåœ°å€å’Œç«¯å£ä¿¡æ¯
        if 'saddr' in fields:
            event["fd.sip"] = fields['saddr']
        if 'daddr' in fields:
            event["fd.dip"] = fields['daddr']
        if 'sport' in fields:
            try:
                event["fd.sport"] = int(fields['sport'])
            except:
                pass
        if 'dport' in fields:
            try:
                event["fd.dport"] = int(fields['dport'])
            except:
                pass
    
    def _update_process_cache(self, event: Dict[str, Any]):
        """æ›´æ–°è¿›ç¨‹ç¼“å­˜ (ç”¨äºè¿›ç¨‹æ ‘é‡å»º)"""
        pid = event["proc.pid"]
        self.process_cache[pid] = {
            'cmdline': event["proc.cmdline"],
            'timestamp': event["evt.time"],
            'name': event["proc.name"]
        }
        
        # é™åˆ¶ç¼“å­˜å¤§å°ï¼Œé¿å…å†…å­˜æ³„æ¼
        if len(self.process_cache) > 10000:
            # åˆ é™¤æœ€æ—§çš„ 1000 ä¸ªæ¡ç›®
            oldest_pids = sorted(self.process_cache.keys(), 
                               key=lambda pid: self.process_cache[pid]['timestamp'])[:1000]
            for pid in oldest_pids:
                del self.process_cache[pid]
    
    def _get_parent_cmdline(self, ppid: int, event_time: float) -> str:
        """è·å–çˆ¶è¿›ç¨‹å‘½ä»¤è¡Œ (åŸºäºç¼“å­˜å’Œç³»ç»Ÿè¿›ç¨‹æ˜ å°„)"""
        if not ppid:
            return ""
        
        # ç³»ç»Ÿè¿›ç¨‹æ˜ å°„ (åŸºäº NODLINK ç®¡é“é€»è¾‘)
        system_processes = {
            1: 'systemd --system --deserialize',
            2: '[kthreadd]',
            0: ''
        }
        
        if ppid in system_processes:
            return system_processes[ppid]
        
        # ä»ç¼“å­˜ä¸­æŸ¥æ‰¾ (æ—¶é—´çª—å£ Â±60ç§’)
        if ppid in self.process_cache:
            cached_info = self.process_cache[ppid]
            if abs(cached_info['timestamp'] - event_time) <= 60:
                return cached_info['cmdline']
        
        return ""  # æ— æ³•é‡å»ºçˆ¶è¿›ç¨‹ä¿¡æ¯


class AuditdToSysdigConsoleConverter(MapFunction):
    """Auditd åˆ° Sysdig æ ¼å¼è½¬æ¢å™¨ (æ§åˆ¶å°è¾“å‡º)"""
    
    def __init__(self):
        self.parser = AuditdSysdigParser()
        self.message_count = 0
        
    def map(self, value):
        try:
            if not value:
                return None
                
            # è§£æè¾“å…¥çš„ JSON æ¶ˆæ¯
            data = json.loads(value)
            message = data.get('message', '')
            host = data.get('host', 'unknown')
            collector_id = data.get('collector_id', 'unknown')
            timestamp = data.get('timestamp', '')
            
            # è§£æ auditd æ¶ˆæ¯
            audit_data = self.parser.parse_auditd_message(message)
            if not audit_data:
                return None
            
            # è½¬æ¢ä¸º sysdig æ ¼å¼
            sysdig_event = self.parser.convert_to_sysdig_format(audit_data, host)
            if not sysdig_event:
                return None
            
            self.message_count += 1
            
            # åŒæ—¶è¾“å‡ºæ ¼å¼åŒ–çš„æ§åˆ¶å°æ˜¾ç¤ºå’Œå®Œæ•´çš„ JSON æ•°æ®
            console_output = self._format_console_output(
                sysdig_event, host, collector_id[:8], timestamp, self.message_count
            )
            
            # è¾“å‡ºå®Œæ•´çš„ sysdig JSON æ•°æ®ç»“æ„
            json_output = json.dumps(sysdig_event, ensure_ascii=False, indent=2)
            
            # ç»„åˆè¾“å‡ºï¼šæ§åˆ¶å°æ ¼å¼ + JSON æ•°æ®
            combined_output = f"{console_output}\nğŸ“Š SYSDIG JSON #{self.message_count}:\n{json_output}\n" + "="*80
            
            return combined_output
            
        except Exception as e:
            logger.error(f"Error in AuditdToSysdigConsoleConverter: {e}")
            return None
    
    def _format_console_output(self, sysdig_event: Dict[str, Any], host: str, 
                             collector_id: str, timestamp: str, count: int) -> str:
        """æ ¼å¼åŒ–æ§åˆ¶å°è¾“å‡º"""
        try:
            # æå–å…³é”®ä¿¡æ¯
            evt_type = sysdig_event.get("evt.type", "unknown")
            evt_category = sysdig_event.get("evt.category", "other")
            proc_name = sysdig_event.get("proc.name", "unknown")
            proc_pid = sysdig_event.get("proc.pid", 0)
            proc_cmdline = sysdig_event.get("proc.cmdline", "")
            fd_name = sysdig_event.get("fd.name", "")
            
            # æ„å»ºè¾“å‡ºè¡Œ
            time_str = timestamp[:19] if timestamp else "unknown"
            
            # åŸºæœ¬ä¿¡æ¯
            output_parts = [
                f"ğŸ”„ SYSDIG #{count}",
                f"{time_str}",
                f"{host}",
                f"{collector_id}",
                f"[{evt_category.upper()}]",
                f"{evt_type}",
                f"pid={proc_pid}",
                f"proc={proc_name}"
            ]
            
            # æ·»åŠ å‘½ä»¤è¡Œ (æˆªæ–­æ˜¾ç¤º)
            if proc_cmdline and proc_cmdline != proc_name:
                cmdline_short = proc_cmdline[:50] + "..." if len(proc_cmdline) > 50 else proc_cmdline
                output_parts.append(f"cmd='{cmdline_short}'")
            
            # æ·»åŠ æ–‡ä»¶è·¯å¾„
            if fd_name:
                fd_short = fd_name[:30] + "..." if len(fd_name) > 30 else fd_name
                output_parts.append(f"file='{fd_short}'")
            
            # æ·»åŠ ç½‘ç»œä¿¡æ¯
            if "fd.dip" in sysdig_event:
                output_parts.append(f"net={sysdig_event.get('fd.sip', '')}â†’{sysdig_event.get('fd.dip', '')}")
            
            return " | ".join(output_parts)
            
        except Exception as e:
            logger.error(f"Error formatting console output: {e}")
            return f"ğŸ”„ SYSDIG #{count} | ERROR | {str(e)}"


class SysdigEventFilter(FilterFunction):
    """è¿‡æ»¤æœ‰æ•ˆçš„ Sysdig äº‹ä»¶"""
    
    def filter(self, value):
        return value is not None and len(value.strip()) > 0


def main():
    """ä¸»å‡½æ•°ï¼šåˆ›å»º Auditd åˆ° Sysdig æ§åˆ¶å°æµ‹è¯•ä½œä¸š"""
    
    logger.info("ğŸš€ Starting SysArmor Auditd to Sysdig Console Test Job")
    logger.info("ğŸ“‹ Based on NODLINK pipeline processing logic")
    
    # ç¯å¢ƒå˜é‡é…ç½®
    kafka_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', '49.232.13.155:9094')
    input_topic = 'sysarmor-events-test'  # å›ºå®šæ¶ˆè´¹æµ‹è¯• topic
    kafka_group_id = 'sysarmor-auditd-sysdig-console-test-group'
    
    logger.info(f"ğŸ“¡ Kafka Servers: {kafka_servers}")
    logger.info(f"ğŸ“¥ Input Topic: {input_topic}")
    logger.info(f"ğŸ‘¥ Consumer Group: {kafka_group_id}")
    logger.info(f"ğŸ¯ Output: Console (TaskManager logs)")
    
    # åˆ›å»ºæµå¤„ç†ç¯å¢ƒ
    env = StreamExecutionEnvironment.get_execution_environment()
    
    # é…ç½®ç¯å¢ƒ
    env.set_parallelism(1)  # å•å¹¶è¡Œåº¦ï¼Œä¾¿äºè§‚å¯Ÿè¾“å‡º
    env.enable_checkpointing(60000)  # 60ç§’ checkpoint
    env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)
    
    try:
        # æ·»åŠ  JAR ä¾èµ–
        env.add_jars("file:///opt/flink/lib/flink-sql-connector-kafka-3.1.0-1.18.jar")
        
        # åˆ›å»º Kafka Consumer
        kafka_props = {
            'bootstrap.servers': kafka_servers,
            'group.id': kafka_group_id,
            'auto.offset.reset': 'latest',
            'client.dns.lookup': 'use_all_dns_ips',
            'session.timeout.ms': '30000',
            'heartbeat.interval.ms': '10000',
            'max.poll.interval.ms': '300000',
            'connections.max.idle.ms': '540000',
            'request.timeout.ms': '30000'
        }
        
        kafka_consumer = FlinkKafkaConsumer(
            topics=[input_topic],
            deserialization_schema=SimpleStringSchema(),
            properties=kafka_props
        )
        
        logger.info("ğŸ“‹ Creating Auditd to Sysdig conversion pipeline...")
        
        # æ„å»ºæ•°æ®æµå¤„ç†ç®¡é“
        converted_stream = env.add_source(kafka_consumer) \
            .map(AuditdToSysdigConsoleConverter(), output_type=Types.STRING()) \
            .filter(SysdigEventFilter())
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        converted_stream.print()
        
        logger.info("ğŸ”„ Auditd to Sysdig conversion pipeline created:")
        logger.info("   Kafka Source (auditd) -> Auditd Parser -> Sysdig Converter -> Console Output")
        logger.info("ğŸ¯ NODLINK supported event types:")
        for evt_type in sorted(AuditdSysdigParser.NODLINK_SUPPORTED_EVENTS):
            logger.info(f"   - {evt_type}")
        
        logger.info("ğŸ›¡ï¸ Features:")
        logger.info("   - Real-time auditd to sysdig conversion")
        logger.info("   - Process tree reconstruction (Â±60s window)")
        logger.info("   - Hex command line decoding")
        logger.info("   - NODLINK standard event filtering")
        logger.info("   - Console output with formatted display")
        
        # æ‰§è¡Œä½œä¸š
        logger.info("âœ… Starting Auditd to Sysdig console test job...")
        
        job_client = env.execute_async("SysArmor-Auditd-Sysdig-Console-Test")
        job_id = job_client.get_job_id()
        
        logger.info(f"ğŸ¯ Auditd to Sysdig console test job submitted successfully!")
        logger.info(f"ğŸ“‹ Job ID: {job_id}")
        logger.info(f"ğŸŒ Monitor at: http://localhost:8081")
        logger.info(f"ğŸ“Š Converting auditd from {input_topic} to sysdig format")
        logger.info(f"ğŸ” View output: make processor logs-taskmanager")
        
        return job_id
        
    except Exception as e:
        logger.error(f"âŒ Auditd to Sysdig console test job failed: {e}")
        raise


if __name__ == "__main__":
    main()
