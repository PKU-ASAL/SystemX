#!/usr/bin/env python3
"""
SysArmor Processor - Events to Alerts Job
æ¶ˆè´¹ sysarmor.events.audit topicï¼ŒåŸºäºå¨èƒæ£€æµ‹è§„åˆ™è¿‡æ»¤å‡ºå‘Šè­¦äº‹ä»¶
è¾“å‡ºåˆ° sysarmor.alerts å’Œ sysarmor.alerts.high topics
åŸºäº Falco/Sysdig è§„åˆ™å¼•æ“è®¾è®¡
"""

import os
import json
import logging
import re
import yaml
import requests
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from collections import defaultdict, deque
from pyflink.datastream import StreamExecutionEnvironment, CheckpointingMode
from pyflink.datastream.connectors.kafka import FlinkKafkaConsumer, FlinkKafkaProducer
# ç§»é™¤ä¸å…¼å®¹çš„ ElasticsearchSink å¯¼å…¥
from pyflink.common.serialization import SimpleStringSchema
from pyflink.common.typeinfo import Types
from pyflink.datastream.functions import MapFunction, FilterFunction
from pyflink.datastream.state import ValueStateDescriptor
from pyflink.datastream.functions import KeyedProcessFunction, ProcessFunction
from pyflink.common import Time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FalcoConditionEvaluator:
    """Falco æ¡ä»¶è¡¨è¾¾å¼è¯„ä¼°å™¨"""
    
    def __init__(self):
        self.operators = {
            'equals': self._op_equals,
            'not_equals': self._op_not_equals,
            'in': self._op_in,
            'not_in': self._op_not_in,
            'contains': self._op_contains,
            'not_contains': self._op_not_contains,
            'startswith': self._op_startswith,
            'endswith': self._op_endswith,
            'regex': self._op_regex,
            'gt': self._op_gt,
            'gte': self._op_gte,
            'lt': self._op_lt,
            'lte': self._op_lte
        }
    
    def evaluate_condition(self, condition: Dict, event_data: Dict) -> bool:
        """è¯„ä¼°æ¡ä»¶è¡¨è¾¾å¼"""
        try:
            if 'and' in condition:
                return all(self.evaluate_condition(sub_cond, event_data) for sub_cond in condition['and'])
            elif 'or' in condition:
                return any(self.evaluate_condition(sub_cond, event_data) for sub_cond in condition['or'])
            elif 'not' in condition:
                return not self.evaluate_condition(condition['not'], event_data)
            elif 'field' in condition:
                return self._evaluate_field_condition(condition, event_data)
            else:
                logger.warning(f"æœªçŸ¥æ¡ä»¶ç±»å‹: {condition}")
                return False
        except Exception as e:
            logger.debug(f"æ¡ä»¶è¯„ä¼°å¼‚å¸¸: {e}")
            return False
    
    def _evaluate_field_condition(self, condition: Dict, event_data: Dict) -> bool:
        """è¯„ä¼°å­—æ®µæ¡ä»¶"""
        field_path = condition['field']
        operator = condition['operator']
        expected_value = condition.get('value', condition.get('values'))
        
        # è·å–å­—æ®µå€¼
        actual_value = self._get_field_value(field_path, event_data)
        
        if actual_value is None:
            return False
        
        # æ‰§è¡Œæ“ä½œç¬¦æ¯”è¾ƒ
        op_func = self.operators.get(operator)
        if op_func:
            return op_func(actual_value, expected_value)
        else:
            logger.warning(f"æœªçŸ¥æ“ä½œç¬¦: {operator}")
            return False
    
    def _get_field_value(self, field_path: str, event_data: Dict):
        """æ ¹æ®å­—æ®µè·¯å¾„è·å–å€¼ï¼Œæ”¯æŒåµŒå¥—è®¿é—®å’Œç›´æ¥é”®ååŒ¹é…"""
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è®¿é—®å®Œæ•´å­—æ®µåï¼ˆé€‚é… sysdig æ ¼å¼ï¼‰
            if field_path in event_data:
                return event_data[field_path]
            
            # å¦‚æœç›´æ¥è®¿é—®å¤±è´¥ï¼Œå°è¯•åˆ†å±‚è®¿é—®
            parts = field_path.split('.')
            current = event_data
            
            for part in parts:
                if isinstance(current, dict):
                    # å¤„ç†æ•°ç»„ç´¢å¼•ï¼Œå¦‚ proc.aname[1]
                    if '[' in part and ']' in part:
                        field_name = part.split('[')[0]
                        index_str = part.split('[')[1].split(']')[0]
                        try:
                            index = int(index_str)
                            if field_name in current and isinstance(current[field_name], list):
                                if 0 <= index < len(current[field_name]):
                                    current = current[field_name][index]
                                else:
                                    return None
                            else:
                                return None
                        except (ValueError, IndexError):
                            return None
                    else:
                        current = current.get(part)
                else:
                    return None
                
                if current is None:
                    return None
            
            return current
        except Exception as e:
            logger.debug(f"è·å–å­—æ®µå€¼å¤±è´¥: {field_path}, {e}")
            return None
    
    # æ“ä½œç¬¦å®ç°
    def _op_equals(self, actual, expected):
        return actual == expected
    
    def _op_not_equals(self, actual, expected):
        return actual != expected
    
    def _op_in(self, actual, expected):
        return actual in expected if isinstance(expected, (list, tuple)) else False
    
    def _op_not_in(self, actual, expected):
        return actual not in expected if isinstance(expected, (list, tuple)) else True
    
    def _op_contains(self, actual, expected):
        return str(expected) in str(actual) if actual is not None else False
    
    def _op_not_contains(self, actual, expected):
        return str(expected) not in str(actual) if actual is not None else True
    
    def _op_startswith(self, actual, expected):
        return str(actual).startswith(str(expected)) if actual is not None else False
    
    def _op_endswith(self, actual, expected):
        return str(actual).endswith(str(expected)) if actual is not None else False
    
    def _op_regex(self, actual, expected):
        try:
            return re.search(str(expected), str(actual), re.IGNORECASE) is not None if actual is not None else False
        except re.error:
            return False
    
    def _op_gt(self, actual, expected):
        try:
            return float(actual) > float(expected)
        except (ValueError, TypeError):
            return False
    
    def _op_gte(self, actual, expected):
        try:
            return float(actual) >= float(expected)
        except (ValueError, TypeError):
            return False
    
    def _op_lt(self, actual, expected):
        try:
            return float(actual) < float(expected)
        except (ValueError, TypeError):
            return False
    
    def _op_lte(self, actual, expected):
        try:
            return float(actual) <= float(expected)
        except (ValueError, TypeError):
            return False

class ThreatDetectionRules:
    """å¨èƒæ£€æµ‹è§„åˆ™å¼•æ“ - åŸºäº Falco è§„åˆ™è®¾è®¡"""
    
    def __init__(self, rules_file: str = "/opt/flink/configs/rules/threat_detection_rules.yaml"):
        self.rules = {}
        self.rule_groups = {}
        self.global_settings = {}
        self.condition_evaluator = FalcoConditionEvaluator()
        self.load_rules(rules_file)
        
    def load_rules(self, rules_file: str):
        """åŠ è½½å¨èƒæ£€æµ‹è§„åˆ™"""
        try:
            if os.path.exists(rules_file):
                with open(rules_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                # åŠ è½½æ—§æ ¼å¼è§„åˆ™
                for rule in config.get('rules', []):
                    if rule.get('enabled', True):
                        self.rules[rule['id']] = rule
                
                # åŠ è½½æ–°æ ¼å¼ Falco æ¡ä»¶è§„åˆ™
                for rule in config.get('falco_condition_rules', []):
                    if rule.get('enabled', True):
                        self.rules[rule['id']] = rule
                
                # åŠ è½½è§„åˆ™ç»„
                self.rule_groups = config.get('rule_groups', {})
                
                # åŠ è½½å…¨å±€è®¾ç½®
                self.global_settings = config.get('global_settings', {})
                
                logger.info(f"âœ… åŠ è½½äº† {len(self.rules)} ä¸ªå¨èƒæ£€æµ‹è§„åˆ™")
                logger.info(f"ğŸ“‹ è§„åˆ™ç»„: {list(self.rule_groups.keys())}")
            else:
                logger.warning(f"è§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨: {rules_file}ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
                self._load_default_rules()
                
        except Exception as e:
            logger.error(f"åŠ è½½è§„åˆ™å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
            self._load_default_rules()
    
    def _load_default_rules(self):
        """åŠ è½½é»˜è®¤è§„åˆ™ - Falco æ ·å¼æ¡ä»¶"""
        self.rules = {
            "suspicious_tmp_execution": {
                "id": "suspicious_tmp_execution",
                "name": "å¯ç–‘ä¸´æ—¶ç›®å½•ç¨‹åºæ‰§è¡Œ",
                "category": "suspicious_activity",
                "severity": "high",
                "base_score": 85,
                "condition": {
                    "and": [
                        {
                            "field": "evt.type",
                            "operator": "in",
                            "values": ["execve", "execveat"]
                        },
                        {
                            "or": [
                                {
                                    "field": "proc.exe", 
                                    "operator": "startswith",
                                    "value": "/tmp/"
                                },
                                {
                                    "field": "proc.exe",
                                    "operator": "startswith", 
                                    "value": "/dev/shm/"
                                },
                                {
                                    "field": "proc.exe",
                                    "operator": "startswith", 
                                    "value": "/var/tmp/"
                                }
                            ]
                        }
                    ]
                }
            },
            "sensitive_file_access": {
                "id": "sensitive_file_access",
                "name": "æ•æ„Ÿæ–‡ä»¶è®¿é—®æ£€æµ‹",
                "category": "file_access",
                "severity": "medium",
                "base_score": 70,
                "condition": {
                    "and": [
                        {
                            "field": "evt.type",
                            "operator": "in",
                            "values": ["open", "openat", "openat2"]
                        },
                        {
                            "field": "fd.name",
                            "operator": "in",
                            "values": ["/etc/shadow", "/etc/passwd", "/etc/sudoers"]
                        }
                    ]
                }
            }
        }
        logger.info("âœ… åŠ è½½äº†é»˜è®¤å¨èƒæ£€æµ‹è§„åˆ™")
    
    def evaluate_event(self, event: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è¯„ä¼°äº‹ä»¶æ˜¯å¦è§¦å‘å¨èƒæ£€æµ‹è§„åˆ™"""
        alerts = []
        
        # æ ‡å‡†åŒ–äº‹ä»¶æ•°æ®ç»“æ„ï¼Œé€‚é… Falco å­—æ®µæ ¼å¼
        normalized_event = self._normalize_event_data(event)
        
        for rule_id, rule in self.rules.items():
            if self._match_rule(rule_id, normalized_event, rule):
                alert = self._create_alert(event, rule)
                alerts.append(alert)
        
        return alerts
    
    def _normalize_event_data(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """å°† sysdig äº‹ä»¶æ•°æ®æ ‡å‡†åŒ–ä¸º Falco å­—æ®µæ ¼å¼ï¼Œé€‚é… SysArmor æ•°æ®ç»“æ„"""
        message = event.get('message', {})
        
        # æ„å»ºæ ‡å‡†åŒ–çš„äº‹ä»¶æ•°æ®ç»“æ„ï¼Œæ·»åŠ å¯¹ç°æœ‰æ•°æ®ç»“æ„çš„é€‚é…
        normalized = {
            # äº‹ä»¶åŸºç¡€ä¿¡æ¯ - é€‚é… SysArmor æ•°æ®ç»“æ„
            'evt.type': message.get('evt.type', event.get('event_type', '')),
            'evt.time': message.get('evt.time', event.get('timestamp', '')),
            'evt.num': message.get('evt.num', 0),
            'evt.category': message.get('evt.category', event.get('event_category', '')),
            'evt.dir': message.get('evt.dir', '>'),
            'evt.args': message.get('evt.args', ''),
            
            # æ¨¡æ‹Ÿç¼ºå¤±çš„äº‹ä»¶å­—æ®µ
            'evt.rawres': message.get('evt.res', 0),
            'evt.is_open_read': self._infer_open_read(message.get('evt.type', '')),
            'evt.is_open_write': self._infer_open_write(message.get('evt.type', '')),
            'evt.arg.request': self._extract_arg_request(message.get('evt.args', '')),
            'evt.arg.target': self._extract_arg_target(message.get('evt.args', '')),
            'evt.arg.oldpath': self._extract_arg_oldpath(message.get('evt.args', '')),
            'evt.arg.family': self._extract_arg_family(message.get('evt.args', '')),
            
            # è¿›ç¨‹ä¿¡æ¯ - ç›´æ¥æ˜ å°„ç°æœ‰å­—æ®µ
            'proc.name': message.get('proc.name', ''),
            'proc.exe': message.get('proc.exe', ''),
            'proc.exepath': message.get('proc.exe', ''),  # ä½¿ç”¨ proc.exe ä½œä¸º exepath
            'proc.cmdline': message.get('proc.cmdline', ''),
            'proc.pcmdline': message.get('proc.pcmdline', ''),
            'proc.pid': message.get('proc.pid', 0),
            'proc.ppid': message.get('proc.ppid', 0),
            'proc.uid': message.get('proc.uid', 0),
            'proc.gid': message.get('proc.gid', 0),
            
            # æ¨¡æ‹Ÿç¼ºå¤±çš„è¿›ç¨‹å­—æ®µ
            'proc.pname': self._extract_parent_name(message.get('proc.pcmdline', '')),
            'proc.tty': self._extract_tty_from_args(message.get('evt.args', '')),
            'proc.pexe': '',  # æš‚æ—¶ä¸ºç©º
            'proc.pexepath': '',  # æš‚æ—¶ä¸ºç©º
            'proc.duration': 0,  # æš‚æ—¶ä¸º0
            
            # æ¨¡æ‹Ÿç¥–å…ˆè¿›ç¨‹ä¿¡æ¯
            'proc.aname': self._build_ancestor_names(message),
            
            # æ–‡ä»¶æè¿°ç¬¦ä¿¡æ¯ - é€‚é…ç°æœ‰æ•°æ®å¹¶æå–ç¼ºå¤±å­—æ®µ
            'fd.name': message.get('fd.name', ''),
            'fd.nameraw': message.get('fd.name', ''),  # ä½¿ç”¨ fd.name ä½œä¸º nameraw
            'fd.type': self._infer_fd_type(message.get('net.sockaddr', {})),
            'fd.typechar': '',  # æš‚æ—¶ä¸ºç©º
            'fd.num': -1,  # æš‚æ—¶ä¸º-1
            
            # ç”¨æˆ·ä¿¡æ¯ - ä»ç°æœ‰å­—æ®µæ¨å¯¼
            'user.name': self._get_user_name(message.get('proc.uid', 0)),
            'user.uid': message.get('proc.uid', 0),
            'user.loginuid': 0,  # æš‚æ—¶ä¸º0
            
            # ç½‘ç»œä¿¡æ¯ - ä»ç°æœ‰æ•°æ®ä¸­è§£æ
            'net.sockaddr': message.get('net.sockaddr', {}),
            
            # å®¹å™¨ä¿¡æ¯ - é»˜è®¤ä¸ºä¸»æœº
            'container.id': 'host',  # æ‚¨çš„æ•°æ®ç»“æ„ä¸­ä¼¼ä¹æ²¡æœ‰å®¹å™¨ä¿¡æ¯
            'container.privileged': False,  # é»˜è®¤ä¸ºéç‰¹æƒ
            'container.image.repository': '',
            
            # åŸå§‹äº‹ä»¶æ•°æ® (ç”¨äºå…¼å®¹)
            'message': message,
            'event': event
        }
        
        # æå–æ–‡ä»¶ç›®å½•å’Œæ–‡ä»¶åä¿¡æ¯
        fd_name = normalized.get('fd.name', '')
        if fd_name:
            directory, filename = self._extract_file_info(fd_name)
            normalized['fd.directory'] = directory
            normalized['fd.filename'] = filename
        else:
            normalized['fd.directory'] = ''
            normalized['fd.filename'] = ''
        
        # è§£æç½‘ç»œè¿æ¥ä¿¡æ¯
        network_info = self._parse_network_info(
            message.get('net.sockaddr', {}), 
            fd_name
        )
        normalized.update(network_info)
        
        return normalized
    
    def _match_rule(self, rule_id: str, event_data: Dict, rule: Dict) -> bool:
        """æ£€æŸ¥äº‹ä»¶æ˜¯å¦åŒ¹é…è§„åˆ™ - ä½¿ç”¨ Falco æ¡ä»¶è¡¨è¾¾å¼"""
        try:
            # ä¼˜å…ˆä½¿ç”¨æ–°çš„ Falco æ¡ä»¶æ ¼å¼
            if 'condition' in rule:
                return self.condition_evaluator.evaluate_condition(rule['condition'], event_data)
            
            # å…¼å®¹æ—§çš„å…³é”®è¯å’Œæ­£åˆ™æ ¼å¼
            event_str = json.dumps(event_data, ensure_ascii=False)
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            keywords = rule.get('keywords', [])
            for keyword in keywords:
                if keyword in event_str:
                    return True
            
            # æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
            patterns = rule.get('patterns', [])
            for pattern in patterns:
                if re.search(pattern, event_str, re.IGNORECASE):
                    return True
            
            # æ£€æŸ¥ç®€å•å­—æ®µæ¡ä»¶åŒ¹é…
            conditions = rule.get('conditions', {})
            if conditions:
                for field, expected_value in conditions.items():
                    actual_value = self.condition_evaluator._get_field_value(field, event_data)
                    if actual_value == expected_value:
                        return True
            
            return False
            
        except Exception as e:
            logger.debug(f"è§„åˆ™åŒ¹é…å¼‚å¸¸ {rule_id}: {e}")
            return False
    
    def _infer_open_read(self, evt_type: str) -> bool:
        """æ ¹æ®äº‹ä»¶ç±»å‹æ¨æ–­æ˜¯å¦ä¸ºè¯»å–æ“ä½œ"""
        read_types = ['open', 'openat', 'openat2', 'read', 'pread', 'readv', 'preadv']
        return evt_type in read_types
    
    def _infer_open_write(self, evt_type: str) -> bool:
        """æ ¹æ®äº‹ä»¶ç±»å‹æ¨æ–­æ˜¯å¦ä¸ºå†™å…¥æ“ä½œ"""
        write_types = ['write', 'pwrite', 'writev', 'pwritev', 'truncate', 'ftruncate']
        return evt_type in write_types
    
    def _extract_arg_request(self, evt_args: str) -> str:
        """ä» evt.args ä¸­æå– ptrace è¯·æ±‚ç±»å‹"""
        if 'PTRACE_ATTACH' in evt_args:
            return 'PTRACE_ATTACH'
        elif 'PTRACE_TRACEME' in evt_args:
            return 'PTRACE_TRACEME'
        elif 'PTRACE_POKETEXT' in evt_args:
            return 'PTRACE_POKETEXT'
        elif 'PTRACE_POKEDATA' in evt_args:
            return 'PTRACE_POKEDATA'
        return ''
    
    def _extract_arg_target(self, evt_args: str) -> str:
        """ä» evt.args ä¸­æå–ç›®æ ‡è·¯å¾„"""
        # ç®€å•å®ç°ï¼Œå¯æ ¹æ®éœ€è¦æ‰©å±•
        return ''
    
    def _extract_arg_oldpath(self, evt_args: str) -> str:
        """ä» evt.args ä¸­æå–æ—§è·¯å¾„"""
        # ç®€å•å®ç°ï¼Œå¯æ ¹æ®éœ€è¦æ‰©å±•
        return ''
    
    def _extract_arg_family(self, evt_args: str) -> str:
        """ä» evt.args ä¸­æå–åœ°å€æ—"""
        if 'AF_PACKET' in evt_args:
            return 'AF_PACKET'
        elif 'AF_UNIX' in evt_args:
            return 'AF_UNIX'
        elif 'AF_INET' in evt_args:
            return 'AF_INET'
        return ''
    
    def _extract_parent_name(self, pcmdline: str) -> str:
        """ä»çˆ¶è¿›ç¨‹å‘½ä»¤è¡Œä¸­æå–çˆ¶è¿›ç¨‹åç§°"""
        if not pcmdline:
            return ''
        parts = pcmdline.split()
        if parts:
            return parts[0].split('/')[-1]  # å–è·¯å¾„çš„æœ€åéƒ¨åˆ†
        return ''
    
    def _extract_tty_from_args(self, evt_args: str) -> int:
        """ä» evt.args ä¸­æå– tty ä¿¡æ¯"""
        import re
        match = re.search(r'tty=(\w+)', evt_args)
        if match and match.group(1) != 'pts0':
            return 1  # éæ ‡å‡†ttyè¿”å›1
        return 0  # æ ‡å‡†ttyæˆ–æ— ttyè¿”å›0
    
    def _build_ancestor_names(self, message: dict) -> list:
        """æ„å»ºç¥–å…ˆè¿›ç¨‹åç§°åˆ—è¡¨"""
        ancestors = []
        pcmdline = message.get('proc.pcmdline', '')
        if pcmdline:
            pname = self._extract_parent_name(pcmdline)
            if pname:
                ancestors.append(pname)
        return ancestors
    
    def _infer_fd_type(self, net_sockaddr: dict) -> str:
        """æ ¹æ®ç½‘ç»œä¿¡æ¯æ¨æ–­æ–‡ä»¶æè¿°ç¬¦ç±»å‹"""
        if isinstance(net_sockaddr, dict):
            family = net_sockaddr.get('family', '')
            if family == 'AF_UNIX':
                return 'unix'
            elif family in ['AF_INET', 'AF_INET6']:
                socket_type = net_sockaddr.get('type', '')
                if 'tcp' in socket_type.lower():
                    return 'ipv4'
                elif 'udp' in socket_type.lower():
                    return 'ipv4'
        return 'file'
    
    def _get_user_name(self, uid: int) -> str:
        """æ ¹æ® UID è·å–ç”¨æˆ·å"""
        # å¸¸è§çš„ç³»ç»Ÿç”¨æˆ·æ˜ å°„
        system_users = {
            0: 'root',
            1: 'daemon', 
            2: 'bin',
            65534: 'nobody'
        }
        return system_users.get(uid, f'user_{uid}')
    
    def _extract_file_info(self, fd_name: str) -> tuple:
        """ä»æ–‡ä»¶æè¿°ç¬¦åç§°ä¸­æå–ç›®å½•å’Œæ–‡ä»¶å"""
        if not fd_name or '->' in fd_name:
            return '', ''
        
        import os
        directory = os.path.dirname(fd_name)
        filename = os.path.basename(fd_name)
        return directory, filename
    
    def _parse_network_info(self, net_sockaddr: dict, fd_name: str) -> dict:
        """è§£æç½‘ç»œè¿æ¥ä¿¡æ¯"""
        network_info = {
            'fd.sip': '',
            'fd.sport': 0,
            'fd.dip': '',
            'fd.dport': 0,
            'fd.sip.name': ''
        }
        
        # å¤„ç† Unix socket
        if isinstance(net_sockaddr, dict):
            if net_sockaddr.get('family') == 'AF_UNIX':
                address = net_sockaddr.get('address', '')
                if address:
                    network_info['fd.sip.name'] = address
        
        # ä» fd.name ä¸­è§£æç½‘ç»œä¿¡æ¯ (æ ¼å¼: IP:port->dest)
        if '->' in fd_name:
            parts = fd_name.split('->')
            if len(parts) == 2:
                src = parts[0].strip()
                dst = parts[1].strip()
                
                # è§£ææºåœ°å€
                if ':' in src:
                    src_parts = src.rsplit(':', 1)
                    network_info['fd.sip'] = src_parts[0]
                    try:
                        network_info['fd.sport'] = int(src_parts[1])
                    except ValueError:
                        pass
                
                # è§£æç›®æ ‡åœ°å€
                if ':' in dst and not dst.startswith('/'):
                    dst_parts = dst.rsplit(':', 1)
                    network_info['fd.dip'] = dst_parts[0]
                    try:
                        network_info['fd.dport'] = int(dst_parts[1])
                    except ValueError:
                        pass
                else:
                    # å¯èƒ½æ˜¯ Unix socket è·¯å¾„æˆ–æœåŠ¡å
                    if not network_info['fd.sip.name']:
                        network_info['fd.sip.name'] = dst
        
        return network_info

    def _create_alert(self, event: Dict, rule: Dict) -> Dict[str, Any]:
        """åˆ›å»ºå‘Šè­¦äº‹ä»¶"""
        now = datetime.utcnow()
        
        # è®¡ç®—é£é™©è¯„åˆ†
        base_score = rule.get('base_score', 50)
        score_multiplier = rule.get('score_multiplier', 1.0)
        final_score = min(100, int(base_score * score_multiplier))
        
        # ç¡®å®šä¸¥é‡ç¨‹åº¦
        severity = rule.get('severity', 'medium')
        if final_score >= 90:
            severity = 'critical'
        elif final_score >= 70:
            severity = 'high'
        elif final_score >= 50:
            severity = 'medium'
        else:
            severity = 'low'
        
        alert = {
            # OpenSearch æ ‡å‡†ä¸»æ—¶é—´å­—æ®µ
            "@timestamp": now.isoformat() + 'Z',
            
            # å‘Šè­¦æ ¸å¿ƒä¿¡æ¯
            "alert": {
                "id": str(uuid.uuid4()),
                "type": "rule_based_detection",
                "category": rule.get('category', 'unknown'),
                "severity": severity,
                "risk_score": final_score,
                "confidence": 0.8,
                "rule": {
                    "id": rule['id'],
                    "name": rule.get('name', ''),
                    "description": rule.get('description', ''),
                    "title": f"{rule.get('name', 'Unknown Threat')}: {event.get('event_type', 'unknown')}",
                    "mitigation": f"æ£€æŸ¥ {rule.get('category', 'unknown')} ç›¸å…³æ´»åŠ¨",
                    "references": [f"SysArmor Rule: {rule['id']}"]
                },
                "evidence": {
                    "event_type": event.get('event_type', ''),
                    "process_name": event.get('message', {}).get('proc.name', ''),
                    "process_cmdline": event.get('message', {}).get('proc.cmdline', ''),
                    "file_path": event.get('message', {}).get('fd.name', ''),
                    "network_info": event.get('message', {}).get('net.sockaddr', {})
                }
            },
            
            # åŸå§‹äº‹ä»¶æ•°æ®
            "event": {
                "raw": {
                    "event_id": event.get('event_id', ''),
                    "timestamp": event.get('timestamp', ''),
                    "source": event.get('source', 'auditd'),
                    "message": event.get('message', {})  # å®Œæ•´çš„ sysdig æ•°æ®ï¼ŒåŒ…å« evt.time
                }
            },
            
            # æ—¶é—´ä¿¡æ¯
            "timing": {
                "created_at": now.isoformat() + 'Z',
                "processed_at": now.isoformat() + 'Z'
            },
            
            # å…ƒæ•°æ®ä¿¡æ¯
            "metadata": {
                "collector_id": event.get('collector_id', ''),
                "host": event.get('host', 'unknown'),
                "source": "sysarmor-threat-detector",
                "processor": "flink-events-to-alerts"
            }
        }
        
        return alert

class EventToAlertsProcessor(MapFunction):
    """äº‹ä»¶åˆ°å‘Šè­¦å¤„ç†å™¨ - ç®€åŒ–ç‰ˆæœ¬ï¼Œå…ˆæµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    
    def __init__(self):
        self.rules_engine = ThreatDetectionRules()
        
    def map(self, value):
        try:
            event = json.loads(value)
            logger.info(f"ğŸ” å¤„ç†äº‹ä»¶: {event.get('event_type', 'unknown')} from {event.get('collector_id', 'unknown')[:8]}")
            
            # åŸºç¡€è§„åˆ™åŒ¹é…
            alerts = self.rules_engine.evaluate_event(event)
            
            if alerts:
                logger.info(f"ğŸš¨ åŒ¹é…åˆ° {len(alerts)} ä¸ªå‘Šè­¦è§„åˆ™")
                # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„å‘Šè­¦
                alert = alerts[0]
                logger.info(f"ğŸš¨ ç”Ÿæˆå‘Šè­¦: {alert['alert']['id']} - {alert['alert']['rule']['name']}")
                return json.dumps(alert, ensure_ascii=False)
            
            return None
                
        except Exception as e:
            logger.error(f"å¤„ç†äº‹ä»¶å¼‚å¸¸: {e}")
            return None

class AlertSeverityRouter(FilterFunction):
    """å‘Šè­¦ä¸¥é‡ç¨‹åº¦è·¯ç”±å™¨"""
    
    def __init__(self, target_severity: str = "high"):
        self.target_severity = target_severity
    
    def filter(self, value):
        try:
            alert = json.loads(value)
            severity = alert.get('alert', {}).get('severity', 'low')
            
            if self.target_severity == "high":
                return severity in ['high', 'critical']
            else:
                return severity in ['low', 'medium']
                
        except Exception:
            return False

def main():
    """ä¸»å‡½æ•°ï¼šåˆ›å»ºäº‹ä»¶åˆ°å‘Šè­¦çš„å¤„ç†ä½œä¸š"""
    
    logger.info("ğŸš€ Starting SysArmor Audit Events to Alerts Job")
    logger.info("ğŸ“‹ Based on Falco-style rule engine")
    logger.info("ğŸ“Š Processing: sysarmor.events.audit â†’ sysarmor.alerts.audit")
    
    # ç¯å¢ƒå˜é‡é…ç½®
    kafka_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'middleware-kafka:9092')
    input_topic = 'sysarmor.events.audit'
    output_topic = 'sysarmor.alerts.audit'  # ç®€åŒ–ä¸ºå•ä¸€å‘Šè­¦topic
    kafka_group_id = 'sysarmor-audit-events-to-alerts-processor'  # æ›´æ–°Consumer Groupåç§°
    
    logger.info(f"ğŸ“¡ Kafka Servers: {kafka_servers}")
    logger.info(f"ğŸ“¥ Input Topic: {input_topic}")
    logger.info(f"ğŸ“¤ Output Topic: {output_topic}")
    logger.info(f"ğŸ‘¥ Consumer Group: {kafka_group_id}")
    
    # åˆ›å»ºæµå¤„ç†ç¯å¢ƒ
    env = StreamExecutionEnvironment.get_execution_environment()
    
    # é…ç½®ç¯å¢ƒ
    env.set_parallelism(2)  # 2ä¸ªå¹¶è¡Œåº¦
    env.enable_checkpointing(30000)  # 30ç§’ checkpoint
    env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)
    
    try:
        # æ·»åŠ  JAR ä¾èµ–
        env.add_jars("file:///opt/flink/lib/flink-sql-connector-kafka-3.1.0-1.18.jar")
        
        # åˆ›å»º Kafka Consumer
        consumer_props = {
            'bootstrap.servers': kafka_servers,
            'group.id': kafka_group_id,
            'auto.offset.reset': 'earliest',  # å¤„ç†æ‰€æœ‰äº‹ä»¶ï¼ŒåŒ…æ‹¬å†å²äº‹ä»¶
            'session.timeout.ms': '30000',
            'heartbeat.interval.ms': '10000',
            'max.poll.interval.ms': '300000'
        }
        
        kafka_consumer = FlinkKafkaConsumer(
            topics=[input_topic],
            deserialization_schema=SimpleStringSchema(),
            properties=consumer_props
        )
        
        # åˆ›å»º Kafka Producer (ç®€åŒ–ä¸ºå•ä¸€å‘Šè­¦æµ)
        producer_props = {
            'bootstrap.servers': kafka_servers,
            'transaction.timeout.ms': '900000',
            'batch.size': '16384',
            'linger.ms': '5',
            'compression.type': 'snappy'
        }
        
        kafka_producer = FlinkKafkaProducer(
            topic=output_topic,
            serialization_schema=SimpleStringSchema(),
            producer_config=producer_props
        )
        
        logger.info("ğŸ“‹ Creating Falco-style threat detection pipeline...")
        
        # æ„å»ºæ•°æ®æµå¤„ç†ç®¡é“
        events_stream = env.add_source(kafka_consumer)
        
        # æŒ‰ collector_id åˆ†ç»„ï¼Œæ”¯æŒé¢‘ç‡æ£€æµ‹
        keyed_stream = events_stream.key_by(
            lambda event: json.loads(event).get('collector_id', 'unknown')
        )
        
        # å¨èƒæ£€æµ‹å¤„ç† (ç®€åŒ–ç‰ˆæœ¬)
        alerts_stream = events_stream.map(
            EventToAlertsProcessor(),
            output_type=Types.STRING()
        ).filter(lambda x: x is not None)
        
        # é…ç½® OpenSearch sink
        opensearch_url = os.getenv('OPENSEARCH_URL', 'http://opensearch:9200')
        opensearch_username = os.getenv('OPENSEARCH_USERNAME', 'admin')
        opensearch_password = os.getenv('OPENSEARCH_PASSWORD', 'admin')
        
        logger.info(f"ğŸ” OpenSearch URL: {opensearch_url}")
        
        # åˆ›å»º OpenSearch HTTP Sink (å€Ÿé‰´å·¥ä½œç‰ˆæœ¬çš„æ–¹æ¡ˆ)
        class OpenSearchHttpSink(MapFunction):
            """OpenSearch HTTP Sink - ä½¿ç”¨ HTTP è¯·æ±‚å†™å…¥"""
            
            def __init__(self):
                self.opensearch_url = opensearch_url
                self.opensearch_username = opensearch_username
                self.opensearch_password = opensearch_password
                self.index_url = f"{opensearch_url}/sysarmor-alerts-audit/_doc"
                
            def map(self, value):
                try:
                    if not value:
                        return value
                    
                    alert_data = json.loads(value)
                    
                    headers = {'Content-Type': 'application/json'}
                    auth = (self.opensearch_username, self.opensearch_password)
                    
                    response = requests.post(
                        self.index_url,
                        json=alert_data,
                        headers=headers,
                        auth=auth,
                        timeout=10,
                        verify=False
                    )
                    
                    if response.status_code in [200, 201]:
                        logger.info(f"âœ… å‘Šè­¦å†™å…¥ OpenSearch: {alert_data.get('alert', {}).get('id', 'unknown')}")
                    else:
                        logger.error(f"âŒ OpenSearch å†™å…¥å¤±è´¥: {response.status_code}")
                        
                except Exception as e:
                    logger.error(f"âŒ OpenSearch HTTP Sink é”™è¯¯: {e}")
                
                return value
        
        opensearch_http_sink = OpenSearchHttpSink()
        logger.info("âœ… OpenSearch HTTP sink å·²é…ç½®: sysarmor-alerts-audit")
        
        # ç®€åŒ–çš„å‘Šè­¦è¾“å‡º (å•ä¸€å‘Šè­¦æµ)
        alerts_stream.add_sink(kafka_producer)
        
        # æ‰€æœ‰å‘Šè­¦å†™å…¥ OpenSearch (ä½¿ç”¨ HTTP æ–¹å¼)
        alerts_stream.map(opensearch_http_sink, output_type=Types.STRING())
        logger.info("âœ… æ‰€æœ‰å‘Šè­¦å°†å†™å…¥ OpenSearch: sysarmor-alerts-audit")
        
        logger.info("âœ… å‘Šè­¦å°†å†™å…¥ Kafka Topic + OpenSearch")
        
        # ç›‘æ§è¾“å‡º
        alerts_stream.map(
            lambda x: f"ğŸš¨ Alert: {json.loads(x).get('alert', {}).get('severity', 'unknown')} - {json.loads(x).get('alert', {}).get('rule', {}).get('name', 'unknown')} from {json.loads(x).get('metadata', {}).get('collector_id', 'unknown')[:8]}",
            output_type=Types.STRING()
        ).print()
        
        logger.info("ğŸ”„ Falco-style threat detection pipeline created:")
        logger.info(f"   {input_topic} -> Rule Engine -> Threat Detection -> {output_topic}")
        
        # æ˜¾ç¤ºåŠ è½½çš„è§„åˆ™
        rules_engine = ThreatDetectionRules()
        logger.info("ğŸ›¡ï¸ åŠ è½½çš„å¨èƒæ£€æµ‹è§„åˆ™:")
        for rule_id, rule in rules_engine.rules.items():
            logger.info(f"   - {rule_id}: {rule.get('name', '')} ({rule.get('severity', 'unknown')})")
        
        logger.info("ğŸ¯ å‘Šè­¦è¾“å‡º:")
        logger.info(f"   - Kafka Topic: {output_topic}")
        logger.info(f"   - OpenSearchç´¢å¼•: sysarmor-alerts-audit")
        
        # æ‰§è¡Œä½œä¸š
        logger.info("âœ… Starting audit threat detection job...")
        
        job_client = env.execute_async("SysArmor-Audit-Events-to-Alerts-Processor")
        
        logger.info(f"ğŸ¯ Audit Events to Alerts job submitted successfully!")
        logger.info(f"ğŸ“‹ Job submitted with async execution")
        logger.info(f"ğŸŒ Monitor at: http://localhost:8081")
        logger.info(f"ğŸ“Š Processing: {input_topic} â†’ {output_topic}")
        logger.info(f"ğŸ” View logs: docker logs -f sysarmor-flink-taskmanager-1")
        
        return "async-job-submitted"
        
    except Exception as e:
        logger.error(f"âŒ Events to Alerts job failed: {e}")
        raise

if __name__ == "__main__":
    main()
