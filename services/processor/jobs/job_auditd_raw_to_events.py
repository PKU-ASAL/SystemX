#!/usr/bin/env python3
"""
SysArmor Processor - Auditd Raw to Events Job
æ¶ˆè´¹ sysarmor.raw.audit topicï¼Œå°† auditd åŸå§‹æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–äº‹ä»¶å¹¶è¾“å‡ºåˆ° sysarmor.events.audit
åŸºäºçœŸå®çš„ NODLINK ç®¡é“å¤„ç†é€»è¾‘å®ç°
"""

import os
import json
import logging
import re
import socket
from datetime import datetime
from typing import Dict, List, Optional, Any
from collections import defaultdict
from pyflink.datastream import StreamExecutionEnvironment, CheckpointingMode
from pyflink.datastream.connectors.kafka import FlinkKafkaConsumer, FlinkKafkaProducer
from pyflink.common.serialization import SimpleStringSchema
from pyflink.common.typeinfo import Types
from pyflink.datastream.functions import MapFunction, FilterFunction

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŸºäºNODLINKç®¡é“çš„ç³»ç»Ÿè°ƒç”¨æ˜ å°„è¡¨ (x86_64)
SYSCALL_MAP = {
    # æ–‡ä»¶æ“ä½œ
    0: "read", 1: "write", 2: "open", 3: "close", 4: "stat", 5: "fstat", 6: "lstat",
    8: "lseek", 9: "mmap", 10: "mprotect", 11: "munmap", 12: "brk", 
    21: "access", 22: "pipe", 32: "dup", 33: "dup2", 85: "creat", 87: "unlink",
    89: "readlink", 257: "openat", 262: "newfstatat", 
    
    # è¿›ç¨‹ç®¡ç†
    39: "getpid", 56: "clone", 57: "fork", 58: "vfork", 59: "execve", 
    60: "exit", 61: "wait4", 231: "exit_group",
    
    # ä¿¡å·å¤„ç†
    13: "rt_sigaction", 14: "rt_sigprocmask", 15: "rt_sigreturn",
    
    # ç½‘ç»œæ“ä½œ
    41: "socket", 42: "connect", 43: "accept", 44: "sendto", 45: "recvfrom",
    46: "sendmsg", 47: "recvmsg", 48: "shutdown", 49: "bind", 50: "listen",
    
    # å†…å­˜ç®¡ç†
    28: "madvise", 25: "mremap", 73: "munlock", 149: "mlock",
    
    # æ—¶é—´ç›¸å…³
    96: "gettimeofday", 201: "time", 228: "clock_gettime",
    
    # æƒé™ç›¸å…³
    105: "setuid", 106: "setgid", 107: "geteuid", 108: "getegid",
    113: "setreuid", 114: "setregid", 117: "setresuid", 119: "setresgid",
    
    # æ–‡ä»¶ç³»ç»Ÿ
    78: "getcwd", 79: "chdir", 80: "fchdir", 83: "mkdir", 84: "rmdir",
    90: "chmod", 91: "fchmod", 92: "chown", 93: "fchown", 94: "lchown",
    
    # å…¶ä»–å¸¸ç”¨ç³»ç»Ÿè°ƒç”¨
    63: "uname", 97: "getrlimit", 158: "arch_prctl", 218: "set_tid_address",
    186: "gettid", 272: "unshare", 273: "set_robust_list",
}

# NODLINKæ ‡å‡†äº‹ä»¶ç±»å‹ï¼ˆåŸºäºåŸå§‹è®ºæ–‡å®ç°ï¼‰
NODLINK_SUPPORTED_EVENTS = {
    "read", "readv", "write", "writev", "fcntl", "rmdir", "rename", "chmod",
    "execve", "clone", "pipe", "fork", "accept", "sendmsg", "recvmsg", 
    "recvfrom", "send", "sendto", "open", "openat", "socket", "connect"
}

# äº‹ä»¶ç±»åˆ«æ˜ å°„
EVENT_CATEGORIES = {
    # æ–‡ä»¶æ“ä½œ
    "read": "file", "readv": "file", "write": "file", "writev": "file",
    "open": "file", "openat": "file", "fcntl": "file", "rmdir": "file",
    "rename": "file", "chmod": "file",
    # è¿›ç¨‹æ“ä½œ
    "execve": "process", "fork": "process", "clone": "process", "pipe": "process",
    # ç½‘ç»œæ“ä½œ
    "socket": "net", "connect": "net", "accept": "net", "sendto": "net",
    "recvfrom": "net", "sendmsg": "net", "recvmsg": "net", "send": "net",
}

class ProcessTreeBuilder:
    """è¿›ç¨‹æ ‘é‡å»ºå™¨ï¼Œç”¨äºé‡å»ºçˆ¶è¿›ç¨‹å‘½ä»¤è¡Œä¿¡æ¯"""
    
    def __init__(self, time_window: int = 60):
        self.time_window = time_window
        self.process_cache = {}
        self.system_processes = {
            1: 'systemd --system --deserialize',
            24710: '/usr/sbin/sshd -D',
        }
    
    def add_process(self, pid: int, ppid: int, cmdline: str, timestamp: float):
        """æ·»åŠ è¿›ç¨‹ä¿¡æ¯åˆ°ç¼“å­˜"""
        if pid and cmdline:
            self.process_cache[pid] = {
                'cmdline': cmdline,
                'ppid': ppid,
                'timestamp': timestamp
            }
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.process_cache) > 10000:
                oldest_pids = sorted(self.process_cache.keys(), 
                                   key=lambda pid: self.process_cache[pid]['timestamp'])[:1000]
                for pid in oldest_pids:
                    del self.process_cache[pid]
    
    def get_parent_cmdline(self, ppid: int, event_time: float) -> str:
        """è·å–çˆ¶è¿›ç¨‹å‘½ä»¤è¡Œ"""
        if not ppid:
            return ""
        
        # 1. æ—¶é—´çª—å£æŸ¥æ‰¾
        for pid, info in self.process_cache.items():
            if (pid == ppid and 
                abs(info['timestamp'] - event_time) <= self.time_window):
                return info['cmdline']
        
        # 2. ç³»ç»Ÿè¿›ç¨‹æ˜ å°„
        if ppid in self.system_processes:
            return self.system_processes[ppid]
        
        return ""

class AuditdLogParser:
    """Auditdæ—¥å¿—è§£æå™¨"""
    
    def parse_audit_log_line(self, line: str) -> Optional[Dict[str, Any]]:
        """è§£æå•è¡Œauditdæ—¥å¿—"""
        line = line.strip()
        if not line:
            return None
        
        # åŒ¹é…auditdæ—¥å¿—æ ¼å¼
        pattern = r'type=([^ ]+) msg=audit\(([\d.]+):(\d+)\): (.*)'
        match = re.match(pattern, line)
        
        if not match:
            return None
        
        log_type, timestamp, event_id, rest = match.groups()
        
        # è§£æå­—æ®µ
        fields = {}
        try:
            for part in re.findall(r'(\w+)=("[^"]*"|\S+)', rest):
                key, val = part
                if val.startswith('"') and val.endswith('"'):
                    val = val[1:-1]
                fields[key] = val
        except Exception:
            return None
        
        return {
            'type': log_type,
            'time': timestamp,
            'event_id': event_id,
            'fields': fields
        }
    
    def decode_cmdline(self, hex_str: str) -> str:
        """è§£ç åå…­è¿›åˆ¶ç¼–ç çš„å‘½ä»¤è¡Œ"""
        if not hex_str:
            return ""
        
        if not all(c in '0123456789abcdefABCDEF' for c in hex_str):
            return hex_str
        
        if len(hex_str) % 2 != 0:
            return hex_str
        
        try:
            hex_bytes = bytes.fromhex(hex_str)
            parts = hex_bytes.split(b'\x00')
            return b' '.join(part for part in parts if part).decode('utf-8', errors='replace').strip()
        except:
            return hex_str
    
    def extract_exe_name(self, exe_path: str) -> str:
        """æå–å¯æ‰§è¡Œæ–‡ä»¶å"""
        if not exe_path:
            return ""
        return os.path.basename(exe_path.strip('"'))

class RawAuditdToEventsConverter(MapFunction):
    """åŸå§‹ Auditd æ•°æ®åˆ°ç»“æ„åŒ–äº‹ä»¶è½¬æ¢å™¨ - åŸºäºNODLINKç®¡é“é€»è¾‘"""
    
    def __init__(self):
        self.parser = AuditdLogParser()
        self.tree_builder = ProcessTreeBuilder()
        self.message_count = 0
        self.event_groups = defaultdict(list)  # æŒ‰event_idåˆ†ç»„
        
    def map(self, value):
        try:
            if not value:
                return None
                
            # è§£æè¾“å…¥çš„åŸå§‹æ•°æ®
            raw_data = json.loads(value)
            message = raw_data.get('message', '')
            
            # è§£æ auditd æ¶ˆæ¯
            audit_data = self.parser.parse_audit_log_line(message)
            if not audit_data:
                return None
            
            # æŒ‰event_idåˆ†ç»„å¤„ç†
            event_id = audit_data['event_id']
            self.event_groups[event_id].append(audit_data)
            
            # è½¬æ¢ä¸ºç»“æ„åŒ–äº‹ä»¶
            structured_event = self._convert_event_group(event_id, self.event_groups[event_id], raw_data)
            if not structured_event:
                return None
            
            self.message_count += 1
            
            # æ›´æ–°è¿›ç¨‹ç¼“å­˜
            sysdig_data = structured_event.get('message', {})
            if sysdig_data.get('proc.pid'):
                self.tree_builder.add_process(
                    sysdig_data['proc.pid'],
                    sysdig_data.get('proc.ppid', 0),
                    sysdig_data.get('proc.cmdline', ''),
                    sysdig_data.get('evt.time', 0)
                )
            
            # é‡å»ºçˆ¶è¿›ç¨‹å‘½ä»¤è¡Œ
            ppid = sysdig_data.get('proc.ppid')
            if ppid:
                pcmdline = self.tree_builder.get_parent_cmdline(
                    ppid, sysdig_data.get('evt.time', 0)
                )
                structured_event['message']['proc.pcmdline'] = pcmdline
            
            # è¿”å›JSONå­—ç¬¦ä¸²
            return json.dumps(structured_event, ensure_ascii=False)
            
        except Exception as e:
            logger.error(f"Error in RawAuditdToEventsConverter: {e}")
            return None
    
    def _convert_event_group(self, event_id: str, entries: List[Dict[str, Any]], 
                           raw_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è½¬æ¢äº‹ä»¶ç»„ä¸ºSysArmoræ‰©å±•æ ¼å¼ - åŒ…è£…sysdigæ•°æ®"""
        if not entries:
            return None
        
        # å…ˆæ„å»ºæ ‡å‡†sysdigæ ¼å¼
        sysdig_event = {
            "evt.num": int(event_id),
            "evt.time": 0,
            "evt.type": "unknown",
            "evt.category": "other",
            "evt.dir": ">",
            "evt.args": "",
            "proc.name": "",
            "proc.exe": "",
            "proc.cmdline": "",
            "proc.pid": None,
            "proc.ppid": None,
            "proc.pcmdline": "",  # çˆ¶è¿›ç¨‹å‘½ä»¤è¡Œï¼Œå°†é€šè¿‡è¿›ç¨‹æ ‘é‡å»º
            "proc.uid": None,
            "proc.gid": None,
            "fd.name": "",
            "net.sockaddr": {},
            "host": raw_data.get('host', 'unknown'),
            "is_warn": False
        }
        
        # å¤„ç†å„ç§ç±»å‹çš„auditè®°å½•
        for entry in entries:
            entry_type = entry['type']
            fields = entry['fields']
            
            if entry_type == 'SYSCALL':
                self._process_syscall_entry(sysdig_event, fields, entry)
            elif entry_type == 'PATH':
                self._process_path_entry(sysdig_event, fields)
            elif entry_type == 'PROCTITLE':
                self._process_proctitle_entry(sysdig_event, fields)
            elif entry_type == 'SOCKADDR':
                self._process_sockaddr_entry(sysdig_event, fields)
        
        # åªå¤„ç†NODLINKæ”¯æŒçš„äº‹ä»¶ç±»å‹
        if sysdig_event["evt.type"] not in NODLINK_SUPPORTED_EVENTS:
            return None
        
        # è®¾ç½®äº‹ä»¶ç±»åˆ«
        if sysdig_event["evt.type"] in EVENT_CATEGORIES:
            sysdig_event["evt.category"] = EVENT_CATEGORIES[sysdig_event["evt.type"]]
        
        # æ„å»ºSysArmoræ‰©å±•æ ¼å¼ - å°†sysdigæ•°æ®åŒ…è£…åœ¨sysdigå­—æ®µä¸­
        result = {
            # SysArmorå…ƒæ•°æ®
            "event_id": event_id,
            "timestamp": datetime.fromtimestamp(sysdig_event["evt.time"]).isoformat() + 'Z',
            "collector_id": raw_data.get('collector_id', ''),
            "host": raw_data.get('host', 'unknown'),
            "source": "auditd",
            "processor": "flink-nodlink-converter",
            "processed_at": datetime.utcnow().isoformat() + 'Z',
            
            # äº‹ä»¶åˆ†ç±»
            "event_type": sysdig_event["evt.type"],
            "event_category": sysdig_event["evt.category"],
            "severity": "low",  # é»˜è®¤ä¸¥é‡ç¨‹åº¦
            
            # å®Œæ•´çš„sysdigæ ¼å¼æ•°æ® (æ”¹åä¸ºmessageä»¥ä¿æŒAPIå…¼å®¹æ€§)
            "message": sysdig_event
        }
        
        return result
    
    def _process_syscall_entry(self, result: Dict[str, Any], fields: Dict[str, str], entry: Dict[str, Any]):
        """å¤„ç†SYSCALLç±»å‹çš„è®°å½• - sysdigæ ¼å¼"""
        # æ—¶é—´æˆ³
        result["evt.time"] = float(entry['time'])
        
        # ç³»ç»Ÿè°ƒç”¨ä¿¡æ¯
        if 'syscall' in fields:
            try:
                syscall_num = int(fields['syscall'])
                result['evt.type'] = SYSCALL_MAP.get(syscall_num, f"syscall_{syscall_num}")
            except ValueError:
                result['evt.type'] = f"syscall_{fields['syscall']}"
        
        # è¿›ç¨‹ä¿¡æ¯ - sysdigæ ¼å¼
        if 'exe' in fields:
            result['proc.exe'] = fields['exe'].strip('"')
            result['proc.name'] = self.parser.extract_exe_name(fields['exe'])
        
        if 'pid' in fields:
            try:
                result['proc.pid'] = int(fields['pid'])
            except ValueError:
                pass
        
        if 'ppid' in fields:
            try:
                result['proc.ppid'] = int(fields['ppid'])
            except ValueError:
                pass
        
        # ç”¨æˆ·ä¿¡æ¯
        if 'uid' in fields:
            try:
                result['proc.uid'] = int(fields['uid'])
            except ValueError:
                pass
        
        if 'gid' in fields:
            try:
                result['proc.gid'] = int(fields['gid'])
            except ValueError:
                pass
        
        # is_warnå­—æ®µ - åœ¨NODLINKä¸­ç”¨äºæ ‡è¯†å¼‚å¸¸äº‹ä»¶ï¼Œå®æ—¶å¤„ç†æ—¶é»˜è®¤ä¸ºFalse
        # æ³¨æ„ï¼šè¿™ä¸æ˜¯ç³»ç»Ÿè°ƒç”¨æˆåŠŸä¸å¦çš„æ ‡è¯†ï¼Œè€Œæ˜¯NODLINKç®—æ³•çš„æ ‡ç­¾å­—æ®µ
        # åœ¨åç»­çš„å¼‚å¸¸æ£€æµ‹é˜¶æ®µä¼šæ ¹æ®å¯ç–‘è¿›ç¨‹ç­‰è§„åˆ™æ¥è®¾ç½®è¿™ä¸ªå­—æ®µ
        result['is_warn'] = False
        
        # æ„å»ºå‚æ•°å­—ç¬¦ä¸²
        excluded_keys = {'key', 'syscall', 'exe', 'pid', 'ppid', 'uid', 'gid', 'success', 'exit'}
        args = []
        for k, v in fields.items():
            if k not in excluded_keys:
                args.append(f"{k}={v}")
        result['evt.args'] = " ".join(args)
    
    def _process_path_entry(self, result: Dict[str, Any], fields: Dict[str, str]):
        """å¤„ç†PATHç±»å‹çš„è®°å½• - sysdigæ ¼å¼"""
        if 'name' in fields:
            file_path = fields['name'].strip('"')
            if file_path and file_path != '(null)':
                if result['fd.name']:
                    result['fd.name'] += f",{file_path}"
                else:
                    result['fd.name'] = file_path
    
    def _process_proctitle_entry(self, result: Dict[str, Any], fields: Dict[str, str]):
        """å¤„ç†PROCTITLEç±»å‹çš„è®°å½• - sysdigæ ¼å¼"""
        if 'proctitle' in fields:
            cmdline = self.parser.decode_cmdline(fields['proctitle'])
            if cmdline:
                result['proc.cmdline'] = cmdline
    
    def _process_sockaddr_entry(self, result: Dict[str, Any], fields: Dict[str, str]):
        """å¤„ç†SOCKADDRç±»å‹çš„è®°å½• - sysdigæ ¼å¼"""
        if 'saddr' in fields:
            try:
                sockaddr_info = self._parse_sockaddr(fields['saddr'])
                if sockaddr_info:
                    result['net.sockaddr'] = sockaddr_info
            except Exception as e:
                logger.debug(f"Failed to parse sockaddr: {e}")
    
    def _parse_sockaddr(self, hex_str: str) -> Dict[str, Any]:
        """è§£æç½‘ç»œåœ°å€ä¿¡æ¯"""
        try:
            if len(hex_str) < 4:
                return {"family": "unknown", "address": hex_str}
            
            # å‰ä¸¤ä¸ªå­—èŠ‚æ˜¯åè®®æ—ï¼ˆå°ç«¯åºï¼‰
            family_hex = hex_str[:4]
            family = int.from_bytes(bytes.fromhex(family_hex), byteorder="little")
            
            if family == 2:  # AF_INET
                if len(hex_str) >= 16:
                    port_bytes = bytes.fromhex(hex_str[4:8])
                    port = int.from_bytes(port_bytes, byteorder="big")
                    ip_bytes = bytes.fromhex(hex_str[8:16])
                    ip = socket.inet_ntop(socket.AF_INET, ip_bytes)
                    return {
                        "family": "AF_INET",
                        "type": "ipv4",
                        "source_ip": ip,
                        "source_port": port,
                        "address": f"{ip}:{port}"
                    }
            
            return {"family": f"family_{family}", "address": hex_str}
            
        except Exception:
            return {"family": "error", "address": hex_str}

class ValidStructuredEventFilter(FilterFunction):
    """è¿‡æ»¤æœ‰æ•ˆçš„ç»“æ„åŒ–äº‹ä»¶"""
    
    def filter(self, value):
        if not value:
            return False
        
        try:
            event = json.loads(value)
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨ä¸”äº‹ä»¶ç±»å‹è¢«æ”¯æŒ
            required_fields = ["event_id", "timestamp", "collector_id", "event_type"]
            has_required = all(field in event for field in required_fields)
            is_supported = event.get("event_type") in NODLINK_SUPPORTED_EVENTS
            return has_required and is_supported
        except:
            return False

def main():
    """ä¸»å‡½æ•°ï¼šåˆ›å»º Auditd Raw to Events å¤„ç†ä½œä¸š"""
    
    logger.info("ğŸš€ Starting SysArmor Auditd Raw to Events Job")
    logger.info("ğŸ“‹ Based on NODLINK pipeline processing logic")
    logger.info("ğŸ“Š Processing: sysarmor.raw.audit â†’ sysarmor.events.audit")
    
    # ç¯å¢ƒå˜é‡é…ç½®
    kafka_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'middleware-kafka:9092')
    input_topic = 'sysarmor.raw.audit'
    output_topic = 'sysarmor.events.audit'
    kafka_group_id = 'sysarmor-auditd-raw-to-events-processor'
    
    logger.info(f"ğŸ“¡ Kafka Servers: {kafka_servers}")
    logger.info(f"ğŸ“¥ Input Topic: {input_topic}")
    logger.info(f"ğŸ“¤ Output Topic: {output_topic}")
    logger.info(f"ğŸ‘¥ Consumer Group: {kafka_group_id}")
    
    # åˆ›å»ºæµå¤„ç†ç¯å¢ƒ
    env = StreamExecutionEnvironment.get_execution_environment()
    
    # é…ç½®ç¯å¢ƒ
    env.set_parallelism(2)  # 2ä¸ªå¹¶è¡Œåº¦
    env.enable_checkpointing(30000)  # 30ç§’ checkpoint
    env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)
    
    try:
        # æ·»åŠ  JAR ä¾èµ–
        env.add_jars("file:///opt/flink/lib/flink-sql-connector-kafka-3.1.0-1.18.jar")
        
        # åˆ›å»º Kafka Consumer
        consumer_props = {
            'bootstrap.servers': kafka_servers,
            'group.id': kafka_group_id,
            'auto.offset.reset': 'earliest',
            'session.timeout.ms': '30000',
            'heartbeat.interval.ms': '10000',
            'max.poll.interval.ms': '300000'
        }
        
        kafka_consumer = FlinkKafkaConsumer(
            topics=[input_topic],
            deserialization_schema=SimpleStringSchema(),
            properties=consumer_props
        )
        
        # åˆ›å»º Kafka Producer
        producer_props = {
            'bootstrap.servers': kafka_servers,
            'transaction.timeout.ms': '900000',
            'batch.size': '16384',
            'linger.ms': '5',
            'compression.type': 'snappy'
        }
        
        kafka_producer = FlinkKafkaProducer(
            topic=output_topic,
            serialization_schema=SimpleStringSchema(),
            producer_config=producer_props
        )
        
        logger.info("ğŸ“‹ Creating NODLINK-based processing pipeline...")
        
        # æ„å»ºæ•°æ®æµå¤„ç†ç®¡é“
        processed_stream = env.add_source(kafka_consumer) \
            .map(RawAuditdToEventsConverter(), output_type=Types.STRING()) \
            .filter(ValidStructuredEventFilter())
        
        # è¾“å‡ºåˆ°ç›®æ ‡topic
        processed_stream.add_sink(kafka_producer)
        
        # ç›‘æ§è¾“å‡º
        processed_stream.map(
            lambda x: f"âœ… Processed: {json.loads(x).get('event_type', 'unknown')} from {json.loads(x).get('collector_id', 'unknown')[:8]}",
            output_type=Types.STRING()
        ).print()
        
        logger.info("ğŸ”„ NODLINK-based Auditd processing pipeline created:")
        logger.info(f"   {input_topic} -> Auditd Parser -> Event Grouping -> Sysdig Conversion -> Process Tree Rebuild -> {output_topic}")
        logger.info("ğŸ¯ NODLINK supported event types:")
        for evt_type in sorted(NODLINK_SUPPORTED_EVENTS):
            logger.info(f"   - {evt_type}")
        
        logger.info("ğŸ›¡ï¸ Features:")
        logger.info("   - Real-time auditd parsing (SYSCALL/PATH/PROCTITLE/SOCKADDR)")
        logger.info("   - Process tree reconstruction with 60s time window")
        logger.info("   - Hex command line decoding")
        logger.info("   - NODLINK standard event filtering")
        logger.info("   - Network address parsing")
        
        # æ‰§è¡Œä½œä¸š
        logger.info("âœ… Starting NODLINK-based Auditd processing job...")
        
        job_client = env.execute_async("SysArmor-NODLINK-Auditd-Raw-to-Events")
        job_id = job_client.get_job_id()
        
        logger.info(f"ğŸ¯ NODLINK Auditd processing job submitted successfully!")
        logger.info(f"ğŸ“‹ Job ID: {job_id}")
        logger.info(f"ğŸŒ Monitor at: http://localhost:8081")
        logger.info(f"ğŸ“Š Processing: {input_topic} â†’ {output_topic}")
        logger.info(f"ğŸ” View logs: docker logs -f sysarmor-flink-taskmanager-1")
        
        return job_id
        
    except Exception as e:
        logger.error(f"âŒ NODLINK Auditd processing job failed: {e}")
        raise

if __name__ == "__main__":
    main()
