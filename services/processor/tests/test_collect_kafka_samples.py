#!/usr/bin/env python3
"""
Kafka Raw Message Collector
Kafka åŸå§‹æ¶ˆæ¯æ”¶é›†å™¨ - è®¢é˜… sysarmor-agentless-* topics å¹¶ä¿å­˜åŸå§‹æ¶ˆæ¯
"""

import sys
import os
import json
import time
import argparse
from datetime import datetime
from kafka import KafkaConsumer
from typing import List, Dict, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))


class KafkaRawCollector:
    """Kafka åŸå§‹æ¶ˆæ¯æ”¶é›†å™¨"""
    
    def __init__(self, 
                 bootstrap_servers: List[str] = None,
                 max_messages: Optional[int] = None,
                 timeout_seconds: Optional[int] = None,
                 output_file: str = None):
        """
        åˆå§‹åŒ–æ”¶é›†å™¨
        
        Args:
            bootstrap_servers: Kafka æœåŠ¡å™¨åˆ—è¡¨
            max_messages: æœ€å¤§æ¶ˆæ¯æ•°é‡ (ä¸ timeout_seconds äº’æ–¥)
            timeout_seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰(ä¸ max_messages äº’æ–¥)
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        self.bootstrap_servers = bootstrap_servers or ['101.42.117.44:9093']
        self.max_messages = max_messages
        self.timeout_seconds = timeout_seconds
        self.output_file = output_file or self._generate_output_filename()
        self.collected_count = 0
        
        # éªŒè¯å‚æ•°äº’æ–¥æ€§
        if max_messages is not None and timeout_seconds is not None:
            raise ValueError("max_messages å’Œ timeout_seconds å‚æ•°ä¸èƒ½åŒæ—¶æŒ‡å®š")
        
        # è®¾ç½®é»˜è®¤å€¼
        if max_messages is None and timeout_seconds is None:
            self.max_messages = 100  # é»˜è®¤æ”¶é›† 100 æ¡æ¶ˆæ¯
        
    def _generate_output_filename(self) -> str:
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        # ç¡®ä¿ samples ç›®å½•å­˜åœ¨
        samples_dir = "samples"
        os.makedirs(samples_dir, exist_ok=True)
        return f"{samples_dir}/kafka_samples_{timestamp}.jsonl"
    
    def discover_agentless_topics(self) -> List[str]:
        """å‘ç°æ‰€æœ‰ sysarmor-agentless-* topics"""
        try:
            from kafka.admin import KafkaAdminClient
            admin_client = KafkaAdminClient(
                bootstrap_servers=self.bootstrap_servers,
                request_timeout_ms=10000
            )
            
            metadata = admin_client.describe_topics()
            all_topics = list(metadata.keys())
            
            # è¿‡æ»¤åŒ¹é…çš„ topics
            agentless_topics = [
                topic for topic in all_topics 
                if topic.startswith('sysarmor-agentless-')
            ]
            
            admin_client.close()
            return agentless_topics
            
        except Exception as e:
            print(f"âš ï¸  Failed to discover topics: {e}")
            # ä½¿ç”¨é»˜è®¤ topics ä½œä¸ºåå¤‡
            return ['sysarmor-agentless-558c01dd', 'sysarmor-agentless-7bb885a8']
    
    def collect_raw_messages(self, topics: List[str]) -> bool:
        """
        æ”¶é›†åŸå§‹æ¶ˆæ¯å¹¶ä¿å­˜åˆ° jsonl æ–‡ä»¶
        
        Args:
            topics: è¦è®¢é˜…çš„ topic åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ”¶é›†æ¶ˆæ¯
        """
        print(f"ğŸ“¡ Kafka Servers: {self.bootstrap_servers}")
        print(f"ğŸ“‹ Topics: {topics}")
        
        # æ˜¾ç¤ºæ”¶é›†æ¨¡å¼
        if self.max_messages is not None:
            print(f"ğŸ¯ Collection Mode: By message count ({self.max_messages} messages)")
        elif self.timeout_seconds is not None:
            print(f"â° Collection Mode: By time duration ({self.timeout_seconds}s)")
        
        print(f"ğŸ’¾ Output File: {self.output_file}")
        print("-" * 60)
        
        try:
            # è®¾ç½®æ¶ˆè´¹è€…è¶…æ—¶æ—¶é—´
            consumer_timeout = None
            if self.timeout_seconds is not None:
                consumer_timeout = self.timeout_seconds * 1000
            else:
                # å¦‚æœæŒ‰æ¶ˆæ¯æ•°é‡æ”¶é›†ï¼Œè®¾ç½®ä¸€ä¸ªè¾ƒé•¿çš„è¶…æ—¶æ—¶é—´é˜²æ­¢æ— é™ç­‰å¾…
                consumer_timeout = 300 * 1000  # 5 åˆ†é’Ÿ
            
            # åˆ›å»º Kafka æ¶ˆè´¹è€…
            consumer = KafkaConsumer(
                *topics,
                bootstrap_servers=self.bootstrap_servers,
                group_id=f'raw-collector-{int(time.time())}',
                auto_offset_reset='latest',  # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
                enable_auto_commit=True,
                value_deserializer=lambda m: m.decode('utf-8') if m else None,
                consumer_timeout_ms=consumer_timeout,
                max_poll_records=100
            )
            
            print("âœ… Kafka consumer created successfully")
            print("ğŸ” Collecting raw messages...")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.output_file) if os.path.dirname(self.output_file) else '.', exist_ok=True)
            
            start_time = time.time()
            
            with open(self.output_file, 'w', encoding='utf-8') as f:
                for message in consumer:
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ¶ˆæ¯æ•°ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
                    if self.max_messages is not None and self.collected_count >= self.max_messages:
                        print(f"\nğŸ¯ Reached max messages limit: {self.max_messages}")
                        break
                    
                    # æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
                    if self.timeout_seconds is not None:
                        elapsed = time.time() - start_time
                        if elapsed >= self.timeout_seconds:
                            print(f"\nâ° Timeout reached: {self.timeout_seconds}s")
                            break
                    
                    if message.value:
                        # æ„å»ºåŸå§‹æ¶ˆæ¯è®°å½•
                        raw_record = {
                            'topic': message.topic,
                            'partition': message.partition,
                            'offset': message.offset,
                            'key': message.key.decode('utf-8') if message.key else None,
                            'timestamp': message.timestamp,
                            'timestamp_type': message.timestamp_type,
                            'value': message.value,  # ä¿æŒåŸå§‹å­—ç¬¦ä¸²æ ¼å¼
                            'collected_at': datetime.now().isoformat()
                        }
                        
                        # å†™å…¥ jsonl æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰
                        f.write(json.dumps(raw_record, ensure_ascii=False) + '\n')
                        f.flush()  # ç«‹å³åˆ·æ–°åˆ°æ–‡ä»¶
                        
                        self.collected_count += 1
                        
                        # æ˜¾ç¤ºè¿›åº¦
                        if self.collected_count % 10 == 0 or self.collected_count <= 10:
                            print(f"ğŸ“¨ Collected {self.collected_count} messages from {message.topic}")
                        elif self.collected_count % 100 == 0:
                            print(f"ğŸ“¨ Collected {self.collected_count} messages...")
            
            consumer.close()
            
            # æ˜¾ç¤ºæ”¶é›†ç»“æœ
            elapsed_time = time.time() - start_time
            print(f"\nğŸ“Š Collection Summary:")
            print(f"   Total Messages: {self.collected_count}")
            print(f"   Duration: {elapsed_time:.1f}s")
            print(f"   Rate: {self.collected_count/elapsed_time:.1f} msg/s" if elapsed_time > 0 else "   Rate: N/A")
            print(f"   Output File: {self.output_file}")
            
            return self.collected_count > 0
            
        except Exception as e:
            print(f"âŒ Error collecting messages: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run(self) -> bool:
        """è¿è¡Œæ”¶é›†å™¨"""
        print("ğŸš€ SysArmor Kafka Raw Message Collector")
        print("=" * 60)
        
        try:
            # å‘ç° agentless topics
            topics = self.discover_agentless_topics()
            if not topics:
                print("âŒ No sysarmor-agentless-* topics found")
                return False
            
            print(f"ğŸ“‹ Discovered {len(topics)} agentless topics:")
            for topic in topics:
                print(f"   - {topic}")
            print()
            
            # æ”¶é›†åŸå§‹æ¶ˆæ¯
            success = self.collect_raw_messages(topics)
            
            if success:
                print(f"\nâœ… Collection completed successfully!")
                print(f"   File: {self.output_file}")
                print(f"   Messages: {self.collected_count}")
            else:
                print(f"\nâŒ Collection failed or no messages collected")
            
            return success
            
        except Exception as e:
            print(f"âŒ Collection failed: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Collect raw messages from sysarmor-agentless-* Kafka topics',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # æ”¶é›† 100 æ¡æ¶ˆæ¯ï¼ˆé»˜è®¤ï¼‰
  python test_collect_kafka_samples.py

  # æ”¶é›† 500 æ¡æ¶ˆæ¯
  python test_collect_kafka_samples.py -n 500

  # æ”¶é›† 60 ç§’å†…çš„æ‰€æœ‰æ¶ˆæ¯
  python test_collect_kafka_samples.py -t 60

  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python test_collect_kafka_samples.py -n 100 -o my_messages.jsonl

  # æŒ‡å®š Kafka æœåŠ¡å™¨
  python test_collect_kafka_samples.py -s localhost:9092,localhost:9093 -n 200

æ³¨æ„: -n å’Œ -t å‚æ•°ä¸èƒ½åŒæ—¶ä½¿ç”¨
        """
    )
    
    parser.add_argument(
        '-s', '--servers',
        default='101.42.117.44:9093',
        help='Kafka bootstrap servers (comma-separated, default: 101.42.117.44:9093)'
    )
    
    # åˆ›å»ºäº’æ–¥å‚æ•°ç»„
    collection_group = parser.add_mutually_exclusive_group()
    
    collection_group.add_argument(
        '-n', '--max-messages',
        type=int,
        help='Maximum number of messages to collect (mutually exclusive with -t)'
    )
    
    collection_group.add_argument(
        '-t', '--timeout',
        type=int,
        help='Collection timeout in seconds (mutually exclusive with -n)'
    )
    
    parser.add_argument(
        '-o', '--output',
        help='Output file path (default: samples/kafka_samples_TIMESTAMP.jsonl)'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose output'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.max_messages is None and args.timeout is None:
        # å¦‚æœéƒ½æ²¡æœ‰æŒ‡å®šï¼Œé»˜è®¤æ”¶é›† 100 æ¡æ¶ˆæ¯
        max_messages = 100
        timeout_seconds = None
        print("ğŸ“‹ Using default: collect 100 messages")
    else:
        max_messages = args.max_messages
        timeout_seconds = args.timeout
    
    # è§£ææœåŠ¡å™¨åˆ—è¡¨
    bootstrap_servers = [s.strip() for s in args.servers.split(',')]
    
    try:
        # åˆ›å»ºæ”¶é›†å™¨
        collector = KafkaRawCollector(
            bootstrap_servers=bootstrap_servers,
            max_messages=max_messages,
            timeout_seconds=timeout_seconds,
            output_file=args.output
        )
        
        # è¿è¡Œæ”¶é›†
        success = collector.run()
        
        return 0 if success else 1
        
    except ValueError as e:
        print(f"âŒ Parameter error: {e}")
        return 1
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
